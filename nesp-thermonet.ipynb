{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d133d7",
   "metadata": {
    "papermill": {
     "duration": 0.009889,
     "end_time": "2022-10-13T07:46:02.248412",
     "exception": false,
     "start_time": "2022-10-13T07:46:02.238523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size:30px\">\n",
    "üî¨ NESP: ThermoNet\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\" style=\"text-align:center; font-size:20px;\">\n",
    "    ‚ù§Ô∏è Dont forget to ‚ñ≤upvote‚ñ≤ if you find this notebook usefull!  ‚ù§Ô∏è\n",
    "</div>\n",
    "\n",
    "This notebook is largely inspired by the work of Bian Li,Yucheng T. Yang,John A. Capra ,Mark B. Gerstein: [Predicting changes in protein thermodynamic stability upon point mutation with deep 3D convolutional neural networks](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008291) \n",
    "Official ThermoNet repository can be found here: https://github.com/gersteinlab/ThermoNet\n",
    "\n",
    "\n",
    "I made a set of adjustments here to make it work for the NESP challenge:\n",
    "1. Retrained models. Official models are trained in \"unbiased\" mode which is suboptimal in the context of NESP challenge. Unbiased training uses each mutation twice in the training set: forward mutation `wildetype->mutant==ddg` and the reverse mutation `mutant->wildtype==-ddg`. In case of NESP challenge only forward mutations are used in the test set. \n",
    "2. A bit of parameter finetuning. \n",
    "\n",
    "\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "ThermoNet trains 3D CNN with features generated from 3D structures of the wildtype and mutant proteins. This is done in 3 steps: \n",
    "\n",
    "1. We need to generate accurate 3D structures of mutant protein from the wildtype. In the paper authors use Rosetta \"FastRelax\" protocol to generate mutant PDB files. You can find this logic under `if ROSETTA` conditions. I generated all structures on my laptop and uploded them to `../input/thermonet-wildtype-relaxed/wildtypeA`.  It's close to impossible to recreate such PDB files in Kaggle boxes, because:\n",
    "    * It takes a lot of time. I generated test PDBS in ~10 hours on my 16 core laptop. \n",
    "    * Rosetta comes with a license that prohibits its redistribution. So you'll have to download and acquire free academic license by yourself in order to use Rosetta.\n",
    "    \n",
    "2. Now once we have all PDB structures, we can generate voxel features from them. This is done with `Acellera htmd` library. Voxel features include a set of attributes packed into a grid of size (16, 16, 16). 7 used features are: `'hydrophobic', 'aromatic', 'hbond_acceptor', 'hbond_donor', 'positive_ionizable', 'negative_ionizable', 'occupancies'`. For each training sample features come from both wildtype and mutant PDBs, so the final shape of each sample is: (16, 16, 16, 14)\n",
    "\n",
    "<img src=\"https://images2.imgbox.com/7c/5d/9mzuGf8N_o.png\" alt=\"image host\"/>\n",
    "\n",
    "3. Finally a simple VGG-style CNN is used to train the regression model. An ensemble of 10 models is used to predict the score. \n",
    "    * LB: **0.4** is achived by ensemble of ThermoNet models\n",
    "    * LB: **0.48** is achived by combining Thermonet output with best performing public notebooks. \n",
    "\n",
    "<img src=\"https://images2.imgbox.com/d8/b6/E88uVMfL_o.png\" alt=\"image host\"/>\n",
    "    \n",
    "\n",
    "## More Details\n",
    "\n",
    "* **Training PDBs** are collected from the official ThermoNet repository.t Specifically I've used [Q3214](https://github.com/gersteinlab/ThermoNet/blob/master/data/datasets/Q3214.txt) dataset with relaxed PDB stored [here](https://github.com/gersteinlab/ThermoNet/tree/master/data/pdbs/Q3214_Q1744) to generate training features (`../input/thermonet-features/Q3214.npy`) \n",
    "* I generated **test PDB files** (`../input/thermonet-wildtype-relaxed/wildtypeA`) manually on my laptop by following [official instructions](https://github.com/gersteinlab/ThermoNet). Test features were then stored to `../input/thermonet-features/nesp_features.npy`\n",
    "\n",
    "\n",
    "## What didn't quite work\n",
    "\n",
    "I tried the following additional experiments to boost performance of ThermoNet, but they didn't work out:\n",
    "\n",
    "* `GroupKFold`. Splitting folds by protein name rather than by individual mutation. Logic is the following: we get better CV estimates as our test.csv protein doesn't belong to the training set. Additionally we may get better performance, because we early stop using a more relevant criteria (validation performance on never-seen-before proteins). Performance is slightly worse on LB (0.38)\n",
    "* Resnet-style models. I used scaled down models with skip connections. Performance was much worse. \n",
    "* One cycle scheduler. \n",
    "* Adding BatchNormalization/InstanceNOrmalization layers. \n",
    "* Data augmentations. I generated augmentations by randomly rotating protein at PDB->voxel stage. 10 augmentations per mutation were generated. Resulting performance was slightly worse than baseline. \n",
    "\n",
    "## What else could be done here?\n",
    "- Additional hyperparameter optimisation\n",
    "- Exploring TTA\n",
    "- Trying out different resolutions of voxel grids\n",
    "- Trying to include `pH` factor to training instances. `pH` is available in https://github.com/gersteinlab/ThermoNet/blob/master/data/datasets/Q3421.txt dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4ee6e",
   "metadata": {
    "papermill": {
     "duration": 0.006365,
     "end_time": "2022-10-13T07:46:02.261526",
     "exception": false,
     "start_time": "2022-10-13T07:46:02.255161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils, imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106fef92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T07:46:02.276503Z",
     "iopub.status.busy": "2022-10-13T07:46:02.275954Z",
     "iopub.status.idle": "2022-10-13T07:46:02.286710Z",
     "shell.execute_reply": "2022-10-13T07:46:02.285846Z"
    },
    "papermill": {
     "duration": 0.020799,
     "end_time": "2022-10-13T07:46:02.288821",
     "exception": false,
     "start_time": "2022-10-13T07:46:02.268022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLONE_THERMONET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4baf0150",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T07:46:02.304324Z",
     "iopub.status.busy": "2022-10-13T07:46:02.302964Z",
     "iopub.status.idle": "2022-10-13T07:47:32.344992Z",
     "shell.execute_reply": "2022-10-13T07:47:32.343701Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 90.053122,
     "end_time": "2022-10-13T07:47:32.348520",
     "exception": false,
     "start_time": "2022-10-13T07:46:02.295398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ThermoNet'...\r\n",
      "remote: Enumerating objects: 13097, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (149/149), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (132/132), done.\u001b[K\r\n",
      "remote: Total 13097 (delta 61), reused 76 (delta 17), pack-reused 12948\u001b[K\r\n",
      "Receiving objects: 100% (13097/13097), 1.05 GiB | 21.53 MiB/s, done.\r\n",
      "Resolving deltas: 100% (5090/5090), done.\r\n",
      "Updating files: 100% (11991/11991), done.\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "THERMONET_PATH = '.'\n",
    "if CLONE_THERMONET:\n",
    "    THERMONET_PATH = 'ThermoNet'\n",
    "    !git clone https://github.com/gersteinlab/ThermoNet.git\n",
    "    sys.path.append(os.path.abspath('ThermoNet/ThermoNet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0d566d",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T07:47:37.412596Z",
     "iopub.status.busy": "2022-10-13T07:47:37.411602Z",
     "iopub.status.idle": "2022-10-13T07:47:46.021154Z",
     "shell.execute_reply": "2022-10-13T07:47:46.019718Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8.766915,
     "end_time": "2022-10-13T07:47:46.023202",
     "exception": false,
     "start_time": "2022-10-13T07:47:37.256287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.14.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Kaggle\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import Levenshtein\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "import tensorflow as tf\n",
    "from keras import layers, callbacks\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.saving.save import load_model\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "MULTIPROCESSING = False\n",
    "BOXSIZE = 16\n",
    "VOXELSIZE = 1\n",
    "EPOCHS = 200\n",
    "N_FOLDS = 10\n",
    "GROUP_KFOLD = False  # True CV: 39.3, False CV: 39.9\n",
    "ROSETTA = False\n",
    "CLEAN_OUTPUT=True\n",
    "MODELS_PATH = 'models'\n",
    "DEBUG=False\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    EPOCHS = 10\n",
    "    N_FOLDS = 3\n",
    "    CLEAN_OUTPUT=False\n",
    "\n",
    "\n",
    "PARAMS = {\n",
    "    'conv_layer_sizes': (16, 24, 32),\n",
    "    'dense_layer_size': 24,\n",
    "    'dropout_rate': 0.5,\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 8,\n",
    "    'scheduler_patience': 10,\n",
    "    'scheduler_factor': math.sqrt(0.1),\n",
    "    'early_stopping_patience': 20,\n",
    "}\n",
    "\n",
    "try:\n",
    "    import kaggle_secrets\n",
    "    \n",
    "    print('Running in Kaggle')\n",
    "    WILDTYPE_PDB = '../input/novozymes-enzyme-stability-prediction/wildtype_structure_prediction_af2.pdb'\n",
    "    PDB_PATH = '../input/thermonet-wildtype-relaxed'\n",
    "    TRAIN_FEATURES_PATH = '../input/thermonet-features/Q3214.npy'\n",
    "    TRAIN_TARGETS_PATH = 'data/datasets/Q3214_direct.csv'\n",
    "    TEST_CSV='../input/novozymes-enzyme-stability-prediction/test.csv'\n",
    "    TEST_FEATURES_PATH = '../input/thermonet-features/nesp_features.npy'\n",
    "except Exception as ex:\n",
    "    print('Running locally')\n",
    "    WILDTYPE_PDB = 'nesp/thermonet/wildtypeA.pdb'\n",
    "    PDB_PATH = 'nesp/thermonet/'\n",
    "    TRAIN_FEATURES_PATH = 'data/datasets/Q3214.npy'\n",
    "    TRAIN_TARGETS_PATH = 'data/datasets/Q3214_direct.csv'\n",
    "    TEST_FEATURES_PATH = 'nesp/thermonet/nesp_features.npy'\n",
    "    TEST_CSV='nesp/test.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd29ff46",
   "metadata": {
    "papermill": {
     "duration": 0.024167,
     "end_time": "2022-10-13T07:47:46.072494",
     "exception": false,
     "start_time": "2022-10-13T07:47:46.048327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf38e79",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T07:47:46.123307Z",
     "iopub.status.busy": "2022-10-13T07:47:46.122389Z",
     "iopub.status.idle": "2022-10-13T07:47:46.368270Z",
     "shell.execute_reply": "2022-10-13T07:47:46.367338Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.273512,
     "end_time": "2022-10-13T07:47:46.370401",
     "exception": false,
     "start_time": "2022-10-13T07:47:46.096889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>op</th>\n",
       "      <th>idx</th>\n",
       "      <th>wild</th>\n",
       "      <th>mutant</th>\n",
       "      <th>mut</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31390</td>\n",
       "      <td>VPVNPEPDATSVENVAEKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>17</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>L17E</td>\n",
       "      <td>wildtypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31391</td>\n",
       "      <td>VPVNPEPDATSVENVAKKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>17</td>\n",
       "      <td>L</td>\n",
       "      <td>K</td>\n",
       "      <td>L17K</td>\n",
       "      <td>wildtypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31392</td>\n",
       "      <td>VPVNPEPDATSVENVAKTGSGDSQSDPIKADLEVKGQSALPFDVDC...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>delete</td>\n",
       "      <td>17</td>\n",
       "      <td>L</td>\n",
       "      <td>-</td>\n",
       "      <td>L17-</td>\n",
       "      <td>wildtypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31393</td>\n",
       "      <td>VPVNPEPDATSVENVALCTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>18</td>\n",
       "      <td>K</td>\n",
       "      <td>C</td>\n",
       "      <td>K18C</td>\n",
       "      <td>wildtypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31394</td>\n",
       "      <td>VPVNPEPDATSVENVALFTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>18</td>\n",
       "      <td>K</td>\n",
       "      <td>F</td>\n",
       "      <td>K18F</td>\n",
       "      <td>wildtypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>33798</td>\n",
       "      <td>VPVNPEPDATSVENVILKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A16I</td>\n",
       "      <td>wildtypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>33799</td>\n",
       "      <td>VPVNPEPDATSVENVLLKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>A16L</td>\n",
       "      <td>wildtypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>33800</td>\n",
       "      <td>VPVNPEPDATSVENVNLKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>A16N</td>\n",
       "      <td>wildtypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>33801</td>\n",
       "      <td>VPVNPEPDATSVENVPLKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>A16P</td>\n",
       "      <td>wildtypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>33802</td>\n",
       "      <td>VPVNPEPDATSVENVWLKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>A16W</td>\n",
       "      <td>wildtypeA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2413 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seq_id                                   protein_sequence  pH  \\\n",
       "0      31390  VPVNPEPDATSVENVAEKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "1      31391  VPVNPEPDATSVENVAKKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "2      31392  VPVNPEPDATSVENVAKTGSGDSQSDPIKADLEVKGQSALPFDVDC...   8   \n",
       "3      31393  VPVNPEPDATSVENVALCTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "4      31394  VPVNPEPDATSVENVALFTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "...      ...                                                ...  ..   \n",
       "2408   33798  VPVNPEPDATSVENVILKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "2409   33799  VPVNPEPDATSVENVLLKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "2410   33800  VPVNPEPDATSVENVNLKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "2411   33801  VPVNPEPDATSVENVPLKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "2412   33802  VPVNPEPDATSVENVWLKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "\n",
       "     data_source       op  idx wild mutant   mut       name  \n",
       "0      Novozymes  replace   17    L      E  L17E  wildtypeA  \n",
       "1      Novozymes  replace   17    L      K  L17K  wildtypeA  \n",
       "2      Novozymes   delete   17    L      -  L17-  wildtypeA  \n",
       "3      Novozymes  replace   18    K      C  K18C  wildtypeA  \n",
       "4      Novozymes  replace   18    K      F  K18F  wildtypeA  \n",
       "...          ...      ...  ...  ...    ...   ...        ...  \n",
       "2408   Novozymes  replace   16    A      I  A16I  wildtypeA  \n",
       "2409   Novozymes  replace   16    A      L  A16L  wildtypeA  \n",
       "2410   Novozymes  replace   16    A      N  A16N  wildtypeA  \n",
       "2411   Novozymes  replace   16    A      P  A16P  wildtypeA  \n",
       "2412   Novozymes  replace   16    A      W  A16W  wildtypeA  \n",
       "\n",
       "[2413 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_mutations(name, df,\n",
    "                  wild=\"VPVNPEPDATSVENVALKTGSGDSQSDPIKADLEVKGQSALPFDVDCWAILCKGAPNVLQ\"\"RVNEKTKNSNRDRSGANKGPFKDPQKWGIKALPPKNPSWSAQDFKSPEEYAFASSLQGGT\"\"NAILAPVNLASQNSQGGVLNGFYSANKVAQFDPSKPQQTKGTWFQITKFTGAAGPYCKAL\"\"GSNDKSVCDKNKNIAGDWGFDPAKWAYQYDEKNNKFNYVGK\"):\n",
    "    result = []\n",
    "    for _, r in df.iterrows():\n",
    "        ops = Levenshtein.editops(wild, r.protein_sequence)\n",
    "        assert len(ops) <= 1\n",
    "        if len(ops) > 0 and ops[0][0] == 'replace':\n",
    "            idx = ops[0][1]\n",
    "            result.append([ops[0][0], idx + 1, wild[idx], r.protein_sequence[idx]])\n",
    "        elif len(ops) == 0:\n",
    "            result.append(['same', 0, '', ''])\n",
    "        elif ops[0][0] == 'insert':\n",
    "            assert False, \"Ups\"\n",
    "        elif ops[0][0] == 'delete':\n",
    "            idx = ops[0][1]\n",
    "            result.append(['delete', idx + 1, wild[idx], '-'])\n",
    "        else:\n",
    "            assert False, \"Ups\"\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(data=result, columns=['op', 'idx', 'wild', 'mutant'])], axis=1)\n",
    "    df['mut'] = df[['wild', 'idx', 'mutant']].astype(str).apply(lambda v: ''.join(v), axis=1)\n",
    "    df['name'] = name\n",
    "    return df\n",
    "\n",
    "\n",
    "df_test = gen_mutations('wildtypeA', pd.read_csv(TEST_CSV))\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a2322b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T07:47:46.421267Z",
     "iopub.status.busy": "2022-10-13T07:47:46.420492Z",
     "iopub.status.idle": "2022-10-13T07:47:46.438000Z",
     "shell.execute_reply": "2022-10-13T07:47:46.436799Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.045717,
     "end_time": "2022-10-13T07:47:46.440736",
     "exception": false,
     "start_time": "2022-10-13T07:47:46.395019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>position</th>\n",
       "      <th>wild_type</th>\n",
       "      <th>mutant</th>\n",
       "      <th>ddg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1otrB</td>\n",
       "      <td>34</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1a5eA</td>\n",
       "      <td>121</td>\n",
       "      <td>L</td>\n",
       "      <td>R</td>\n",
       "      <td>-0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1rtbA</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4lyzA</td>\n",
       "      <td>102</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>-0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1thqA</td>\n",
       "      <td>157</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>2lzmA</td>\n",
       "      <td>42</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>1yeaA</td>\n",
       "      <td>76</td>\n",
       "      <td>P</td>\n",
       "      <td>G</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>1stnA</td>\n",
       "      <td>104</td>\n",
       "      <td>V</td>\n",
       "      <td>T</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>2lzmA</td>\n",
       "      <td>71</td>\n",
       "      <td>V</td>\n",
       "      <td>A</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>1vqbA</td>\n",
       "      <td>86</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pdb_id  position wild_type mutant   ddg\n",
       "0     1otrB        34         E      A -0.07\n",
       "1     1a5eA       121         L      R -0.66\n",
       "2     1rtbA         4         A      S  0.47\n",
       "3     4lyzA       102         G      R -0.38\n",
       "4     1thqA       157         M      A  0.77\n",
       "...     ...       ...       ...    ...   ...\n",
       "3209  2lzmA        42         A      K  3.70\n",
       "3210  1yeaA        76         P      G  1.20\n",
       "3211  1stnA       104         V      T  2.50\n",
       "3212  2lzmA        71         V      A  1.50\n",
       "3213  1vqbA        86         A      T  0.70\n",
       "\n",
       "[3214 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'{THERMONET_PATH}/{TRAIN_TARGETS_PATH}')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "373eb499",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T07:47:46.492388Z",
     "iopub.status.busy": "2022-10-13T07:47:46.491715Z",
     "iopub.status.idle": "2022-10-13T07:47:46.519021Z",
     "shell.execute_reply": "2022-10-13T07:47:46.518205Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.055412,
     "end_time": "2022-10-13T07:47:46.521118",
     "exception": false,
     "start_time": "2022-10-13T07:47:46.465706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_features(pdb_chain, pos, wt, mt):\n",
    "    from utils import pdb_utils\n",
    "    \n",
    "    pdb_dir = os.path.abspath(PDB_PATH)\n",
    "    wt_pdb_path = os.path.join(pdb_dir, pdb_chain, pdb_chain + '_relaxed.pdb')\n",
    "    features_wt = pdb_utils.compute_voxel_features(pos, wt_pdb_path, boxsize=BOXSIZE,\n",
    "                                                   voxelsize=VOXELSIZE)\n",
    "    features_wt = np.delete(features_wt, obj=6, axis=0)  # removing 0 'metallic' layer\n",
    "\n",
    "    mt_pdb_path = os.path.join(pdb_dir, pdb_chain, pdb_chain + '_' + wt + str(pos) + mt + '_relaxed.pdb')\n",
    "    features_mt = pdb_utils.compute_voxel_features(pos, mt_pdb_path, boxsize=BOXSIZE,\n",
    "                                                   voxelsize=VOXELSIZE)\n",
    "    features_mt = np.delete(features_mt, obj=6, axis=0)  # removing 0 'metallic' layer\n",
    "    features_combined = np.concatenate((features_wt, features_mt), axis=0)\n",
    "    return features_combined\n",
    "\n",
    "\n",
    "def thermonet_features(df):\n",
    "    install_htmd()\n",
    "    os.environ['HTMD_NONINTERACTIVE'] = '1'\n",
    "    if MULTIPROCESSING:\n",
    "        with multiprocessing.Pool() as pool:\n",
    "            thermonet_features = pool.starmap(gen_features,\n",
    "                                              [[r['name'], r.idx, r.wild, r.mutant] for _, r in df.iterrows()])\n",
    "    else:\n",
    "        thermonet_features = [gen_features(r['name'], r.idx, r.wild, r.mutant) for _, r in\n",
    "                              tqdm(df.iterrows(), total=len(df))]\n",
    "    thermonet_features = np.array(thermonet_features)\n",
    "    return thermonet_features\n",
    "\n",
    "\n",
    "def install_htmd():\n",
    "    try:\n",
    "        os.environ[\"HTMD_NONINTERACTIVE\"] = \"1\"\n",
    "        import htmd\n",
    "        print('htmd already installed')\n",
    "    except Exception as ex:\n",
    "        !conda install -q -y -c acellera  htmd==2.0.5\n",
    "        !mkdir -p /root/.htmd/.registered-htmd\n",
    "        !echo '{\"name\":\"your name\",\"email\":\"youremail@gmail.com\",\"institution\":\".\",\"city\":\"London\",\"country\":\"UK\",\"product\":\"htmd\",\"code\":342455931}' > /root/.htmd/.registered-htmd/registration\n",
    "\n",
    "if not os.path.exists(TRAIN_FEATURES_PATH):    \n",
    "    np.save(thermonet_features(df_train.rename(columns={'pdb_id': 'name', 'position': 'idx', 'wild_type': 'wild'})), 'train_features.npy')\n",
    "    TRAIN_FEATURES_PATH = 'train_features.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1777399",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T07:47:46.573460Z",
     "iopub.status.busy": "2022-10-13T07:47:46.572525Z",
     "iopub.status.idle": "2022-10-13T07:47:57.189372Z",
     "shell.execute_reply": "2022-10-13T07:47:57.188357Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 10.645624,
     "end_time": "2022-10-13T07:47:57.191508",
     "exception": false,
     "start_time": "2022-10-13T07:47:46.545884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214, 16, 16, 16, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load(TRAIN_FEATURES_PATH)\n",
    "X = np.moveaxis(X, 1, -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07715788",
   "metadata": {
    "papermill": {
     "duration": 0.024859,
     "end_time": "2022-10-13T07:47:57.242588",
     "exception": false,
     "start_time": "2022-10-13T07:47:57.217729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Plotting voxel representation of features\n",
    "\n",
    "In the following plots we use 3D scatterplot to demonstrate training samples. \n",
    "Specifically we plot `occupancy` feature that represents probability that certain voxel is occpupied by an atom.\n",
    "Recall that each training/test sample uses a combination of wildetype+mutant features. So we use the following color-coding:\n",
    "* blue color represents voxels that are occupied in both wildtype and mutant structures \n",
    "* red color represents voxels that are occupied only in the mutant structure\n",
    "* green color represents voxels that are occupied only in the wildtype structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36d5f37f",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T07:47:57.294748Z",
     "iopub.status.busy": "2022-10-13T07:47:57.293896Z",
     "iopub.status.idle": "2022-10-13T07:47:58.548024Z",
     "shell.execute_reply": "2022-10-13T07:47:58.547000Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.285929,
     "end_time": "2022-10-13T07:47:58.553486",
     "exception": false,
     "start_time": "2022-10-13T07:47:57.267557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.14.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "color=blue<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "blue",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "blue",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          4,
          4,
          4,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          15,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          13,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          10,
          10,
          10,
          11,
          11,
          11,
          12,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          0,
          0,
          0,
          1,
          1,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          0,
          0,
          0,
          1,
          1,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          9,
          0,
          0,
          1,
          1,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          8,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          7,
          7,
          7,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          5,
          5,
          6
         ],
         "z": [
          6,
          7,
          8,
          9,
          13,
          14,
          15,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          14,
          15,
          7,
          10,
          11,
          12,
          15,
          8,
          9,
          11,
          12,
          13,
          14,
          15,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          2,
          3,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          1,
          2,
          3,
          4,
          5,
          9,
          10,
          11,
          2,
          3,
          4,
          5,
          6,
          7,
          10,
          15,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          15,
          7,
          8,
          9,
          11,
          12,
          14,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          11,
          12,
          13,
          14,
          3,
          4,
          5,
          6,
          8,
          11,
          12,
          14,
          15,
          1,
          2,
          3,
          4,
          5,
          9,
          11,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          10,
          11,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          10,
          11,
          12,
          0,
          1,
          2,
          10,
          11,
          12,
          13,
          6,
          7,
          6,
          7,
          11,
          12,
          11,
          12,
          15,
          8,
          9,
          10,
          11,
          14,
          4,
          5,
          8,
          10,
          11,
          4,
          5,
          6,
          15,
          4,
          5,
          7,
          9,
          10,
          11,
          14,
          15,
          4,
          6,
          7,
          8,
          9,
          10,
          11,
          14,
          15,
          7,
          8,
          9,
          10,
          3,
          4,
          5,
          7,
          8,
          9,
          10,
          11,
          3,
          4,
          5,
          10,
          14,
          2,
          3,
          4,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          2,
          3,
          4,
          9,
          10,
          11,
          12,
          14,
          0,
          1,
          2,
          9,
          10,
          11,
          0,
          1,
          2,
          11,
          12,
          6,
          7,
          6,
          7,
          13,
          9,
          10,
          12,
          13,
          14,
          9,
          13,
          14,
          13,
          14,
          15,
          14,
          4,
          5,
          10,
          11,
          14,
          15,
          3,
          4,
          5,
          9,
          10,
          11,
          12,
          14,
          15,
          3,
          4,
          5,
          8,
          9,
          10,
          11,
          12,
          14,
          15,
          8,
          9,
          10,
          14,
          15,
          9,
          10,
          14,
          15,
          9,
          10,
          11,
          12,
          13,
          9,
          10,
          11,
          12,
          13,
          9,
          10,
          11,
          12,
          8,
          9,
          10,
          11,
          9,
          5,
          6,
          13,
          5,
          6,
          8,
          9,
          10,
          12,
          13,
          14,
          9,
          10,
          13,
          14,
          15,
          13,
          14,
          15,
          8,
          9,
          10,
          14,
          4,
          5,
          9,
          10,
          11,
          3,
          4,
          5,
          6,
          9,
          10,
          11,
          12,
          14,
          15,
          3,
          4,
          5,
          10,
          11,
          12,
          13,
          14,
          15,
          14,
          15,
          8,
          9,
          10,
          12,
          13,
          14,
          15,
          8,
          9,
          10,
          11,
          12,
          13,
          9,
          10,
          11,
          12,
          13,
          14,
          10,
          11,
          13,
          14,
          8,
          9,
          10,
          12,
          13,
          4,
          5,
          6,
          8,
          9,
          4,
          5,
          6,
          8,
          9,
          10,
          13,
          14,
          15,
          5,
          8,
          9,
          10,
          13,
          14,
          15,
          9,
          10,
          11,
          14,
          15,
          8,
          9,
          10,
          15,
          4,
          5,
          8,
          9,
          10,
          2,
          3,
          4,
          5,
          6,
          9,
          10,
          11,
          2,
          3,
          4,
          5,
          9,
          10,
          14,
          15,
          9,
          11,
          12,
          13,
          15,
          8,
          9,
          11,
          12,
          13,
          9,
          11,
          12,
          13,
          14,
          13,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          5,
          6,
          7,
          8,
          9,
          10,
          5,
          6,
          7,
          8,
          9,
          10,
          14,
          15,
          8,
          9,
          10,
          14,
          15,
          9,
          10,
          11,
          14,
          15,
          8,
          9,
          10,
          11,
          15,
          9,
          10,
          2,
          3,
          4,
          5,
          9,
          10,
          2,
          3,
          4,
          5,
          9,
          10,
          4,
          11,
          12,
          13,
          11,
          12,
          13,
          12,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          4,
          5,
          6,
          7,
          8,
          9,
          11,
          12,
          6,
          9,
          10,
          11,
          12,
          9,
          10,
          11,
          12,
          15,
          7,
          8,
          9,
          10,
          11,
          15,
          4,
          5,
          7,
          15,
          2,
          3,
          4,
          5,
          6,
          7,
          2,
          3,
          4,
          5,
          6,
          7,
          6,
          4,
          5,
          7,
          10,
          11,
          12,
          13,
          4,
          5,
          6,
          7,
          12,
          4,
          5,
          11,
          12,
          10,
          11,
          12,
          7,
          9,
          10,
          11,
          12,
          6,
          7,
          8,
          9,
          10,
          11,
          3,
          4,
          5,
          6,
          7,
          8,
          15,
          4,
          5,
          6,
          7,
          8,
          4,
          5,
          6,
          7,
          8,
          9,
          6,
          8,
          11,
          12,
          13,
          9,
          12,
          8,
          9,
          8,
          9,
          10,
          11,
          7,
          8,
          9,
          10,
          11,
          12,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          15,
          4,
          6,
          7,
          8,
          11,
          12,
          15,
          4,
          6,
          7,
          8,
          9,
          15,
          6,
          7,
          8,
          9,
          7,
          8,
          9,
          13,
          14,
          15,
          13,
          14,
          8,
          9,
          6,
          7,
          8,
          9,
          10,
          11,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          15,
          6,
          7,
          8,
          11,
          12,
          14,
          15,
          6,
          7,
          8,
          15,
          7,
          8,
          9,
          8,
          13,
          14,
          13,
          14,
          4,
          5,
          6,
          7,
          8,
          9,
          12,
          13,
          4,
          5,
          6,
          7,
          8,
          9,
          12,
          13,
          14,
          6,
          7,
          9,
          11,
          12,
          13,
          7,
          11,
          12,
          13,
          15,
          12,
          15,
          15,
          4,
          5,
          6,
          7,
          8,
          12,
          13,
          4,
          5,
          6,
          7,
          8,
          12,
          13,
          14,
          5,
          6,
          7,
          11,
          12,
          13,
          14,
          11,
          12,
          13,
          15,
          11,
          12,
          15,
          5,
          6,
          7,
          13,
          14,
          5,
          6,
          7,
          12,
          13,
          14,
          5,
          6,
          12,
          13,
          14,
          11,
          12,
          13,
          11,
          12,
          13,
          5,
          6,
          13,
          5,
          6,
          12,
          13,
          14,
          5,
          6,
          12,
          13,
          14,
          11,
          12,
          13,
          14,
          11,
          12,
          13,
          12,
          13,
          13
         ]
        },
        {
         "hovertemplate": "color=green<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "green",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "green",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          12,
          12,
          12,
          13,
          13,
          14,
          14,
          14
         ],
         "y": [
          1,
          3,
          7,
          9,
          9,
          10,
          14,
          0,
          3,
          4,
          4,
          5,
          6,
          6,
          7,
          7,
          10,
          10,
          11,
          13,
          5,
          5,
          10,
          14,
          1,
          1,
          2,
          6,
          9,
          10,
          14,
          4,
          6,
          8,
          8,
          9,
          10,
          11,
          12,
          13,
          7,
          8,
          9,
          9,
          9,
          10,
          2,
          3,
          8,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          0,
          2,
          4,
          4,
          5,
          9,
          9,
          10,
          10,
          10,
          1,
          1,
          6,
          7,
          10,
          10,
          0,
          4,
          8,
          0,
          1,
          4,
          4,
          5,
          5,
          6,
          0,
          3,
          3,
          4,
          5,
          3,
          5,
          4,
          5,
          6
         ],
         "z": [
          13,
          7,
          8,
          5,
          13,
          15,
          15,
          8,
          8,
          12,
          13,
          9,
          2,
          10,
          6,
          8,
          6,
          12,
          6,
          1,
          4,
          5,
          11,
          0,
          12,
          14,
          15,
          12,
          9,
          11,
          9,
          13,
          11,
          11,
          15,
          14,
          8,
          10,
          10,
          14,
          11,
          7,
          6,
          7,
          8,
          7,
          10,
          15,
          8,
          7,
          8,
          6,
          7,
          8,
          12,
          12,
          6,
          6,
          8,
          15,
          15,
          7,
          9,
          7,
          8,
          9,
          5,
          8,
          5,
          5,
          7,
          8,
          12,
          13,
          6,
          15,
          15,
          10,
          11,
          8,
          10,
          6,
          14,
          14,
          12,
          8,
          11,
          14,
          11,
          13,
          14,
          12
         ]
        },
        {
         "hovertemplate": "color=red<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "red",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "red",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          7,
          7,
          7,
          7,
          8,
          8,
          10,
          10,
          10,
          11,
          11
         ],
         "y": [
          7,
          10,
          13,
          13,
          14,
          0,
          1,
          6,
          7,
          9,
          10,
          11,
          14,
          15,
          15,
          3,
          3,
          5,
          8,
          10,
          10,
          12,
          13,
          0,
          3,
          3,
          4,
          4,
          6,
          8,
          9,
          11,
          12,
          0,
          1,
          1,
          3,
          5,
          7,
          9,
          1,
          1,
          3,
          3,
          3,
          8,
          6,
          9,
          1,
          2,
          2,
          7,
          3,
          6,
          5,
          5,
          7,
          5,
          7
         ],
         "z": [
          9,
          10,
          9,
          13,
          9,
          5,
          5,
          3,
          3,
          15,
          15,
          9,
          8,
          9,
          10,
          10,
          15,
          13,
          13,
          8,
          12,
          14,
          13,
          13,
          8,
          12,
          9,
          10,
          8,
          9,
          13,
          15,
          8,
          14,
          7,
          13,
          6,
          11,
          8,
          4,
          4,
          11,
          6,
          11,
          12,
          6,
          8,
          5,
          13,
          8,
          9,
          3,
          7,
          14,
          5,
          14,
          11,
          4,
          13
         ]
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "color"
         },
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0.0,
           1.0
          ],
          "y": [
           0.0,
           1.0
          ]
         },
         "xaxis": {
          "title": {
           "text": "x"
          }
         },
         "yaxis": {
          "title": {
           "text": "y"
          }
         },
         "zaxis": {
          "title": {
           "text": "z"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Train idx:123; ddg=1.3"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"4a5651cc-6cf0-4198-9b7c-2124cd0777de\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4a5651cc-6cf0-4198-9b7c-2124cd0777de\")) {                    Plotly.newPlot(                        \"4a5651cc-6cf0-4198-9b7c-2124cd0777de\",                        [{\"hovertemplate\":\"color=blue<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"blue\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"blue\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14],\"y\":[0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,2,2,2,2,2,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,0,0,1,1,1,1,2,2,2,4,4,4,4,4,5,5,5,5,5,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,9,9,9,9,10,10,10,10,10,10,10,10,11,11,11,11,11,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,15,15,15,15,15,0,0,1,1,1,2,2,2,2,2,3,3,3,4,4,4,5,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,10,10,10,10,11,11,11,11,11,12,12,12,12,12,13,13,13,13,14,14,14,14,15,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,4,4,4,5,5,5,5,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,9,9,10,10,10,10,10,10,10,11,11,11,11,11,11,12,12,12,12,12,12,13,13,13,13,0,0,0,0,0,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,4,4,4,4,4,5,5,5,5,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,9,10,10,10,10,10,11,11,11,11,11,12,12,12,12,12,13,0,0,0,0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,4,4,4,4,4,5,5,5,5,5,6,6,7,7,7,7,7,7,8,8,8,8,8,8,9,10,10,10,11,11,11,12,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,4,4,4,4,4,5,5,5,5,5,5,6,6,6,6,7,7,7,7,7,7,8,8,8,8,8,8,9,0,0,0,0,0,0,0,1,1,1,1,1,2,2,2,2,3,3,3,4,4,4,4,4,5,5,5,5,5,5,6,6,6,6,6,6,6,7,7,7,7,7,8,8,8,8,8,8,9,9,0,0,0,1,1,2,2,3,3,3,3,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,7,7,7,7,7,7,8,8,8,8,9,9,9,0,0,0,1,1,2,2,3,3,3,3,3,3,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,7,7,7,7,8,8,8,9,0,0,1,1,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,6,6,6,6,6,7,7,8,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,6,6,6,6,7,7,7,3,3,3,3,3,4,4,4,4,4,4,5,5,5,5,5,6,6,6,7,7,7,3,3,3,4,4,4,4,4,5,5,5,5,5,6,6,6,6,7,7,7,5,5,6],\"z\":[6,7,8,9,13,14,15,6,7,8,9,10,11,12,14,15,7,10,11,12,15,8,9,11,12,13,14,15,6,7,8,9,10,11,12,13,14,15,2,3,6,7,8,9,10,11,12,13,1,2,3,4,5,9,10,11,2,3,4,5,6,7,10,15,4,5,6,7,8,9,10,15,7,8,9,11,12,14,3,4,5,6,7,8,9,11,12,13,14,3,4,5,6,8,11,12,14,15,1,2,3,4,5,9,11,13,14,15,0,1,2,3,4,5,10,11,14,15,0,1,2,3,4,5,10,11,12,0,1,2,10,11,12,13,6,7,6,7,11,12,11,12,15,8,9,10,11,14,4,5,8,10,11,4,5,6,15,4,5,7,9,10,11,14,15,4,6,7,8,9,10,11,14,15,7,8,9,10,3,4,5,7,8,9,10,11,3,4,5,10,14,2,3,4,10,11,12,13,14,15,0,2,3,4,9,10,11,12,14,0,1,2,9,10,11,0,1,2,11,12,6,7,6,7,13,9,10,12,13,14,9,13,14,13,14,15,14,4,5,10,11,14,15,3,4,5,9,10,11,12,14,15,3,4,5,8,9,10,11,12,14,15,8,9,10,14,15,9,10,14,15,9,10,11,12,13,9,10,11,12,13,9,10,11,12,8,9,10,11,9,5,6,13,5,6,8,9,10,12,13,14,9,10,13,14,15,13,14,15,8,9,10,14,4,5,9,10,11,3,4,5,6,9,10,11,12,14,15,3,4,5,10,11,12,13,14,15,14,15,8,9,10,12,13,14,15,8,9,10,11,12,13,9,10,11,12,13,14,10,11,13,14,8,9,10,12,13,4,5,6,8,9,4,5,6,8,9,10,13,14,15,5,8,9,10,13,14,15,9,10,11,14,15,8,9,10,15,4,5,8,9,10,2,3,4,5,6,9,10,11,2,3,4,5,9,10,14,15,9,11,12,13,15,8,9,11,12,13,9,11,12,13,14,13,6,7,8,9,10,11,12,13,5,6,7,8,9,10,5,6,7,8,9,10,14,15,8,9,10,14,15,9,10,11,14,15,8,9,10,11,15,9,10,2,3,4,5,9,10,2,3,4,5,9,10,4,11,12,13,11,12,13,12,4,5,6,7,8,9,10,11,12,4,5,6,7,8,9,10,11,4,5,6,7,8,9,11,12,6,9,10,11,12,9,10,11,12,15,7,8,9,10,11,15,4,5,7,15,2,3,4,5,6,7,2,3,4,5,6,7,6,4,5,7,10,11,12,13,4,5,6,7,12,4,5,11,12,10,11,12,7,9,10,11,12,6,7,8,9,10,11,3,4,5,6,7,8,15,4,5,6,7,8,4,5,6,7,8,9,6,8,11,12,13,9,12,8,9,8,9,10,11,7,8,9,10,11,12,6,7,8,9,10,11,12,13,15,4,6,7,8,11,12,15,4,6,7,8,9,15,6,7,8,9,7,8,9,13,14,15,13,14,8,9,6,7,8,9,10,11,6,7,8,9,10,11,12,6,7,8,9,10,11,12,13,15,6,7,8,11,12,14,15,6,7,8,15,7,8,9,8,13,14,13,14,4,5,6,7,8,9,12,13,4,5,6,7,8,9,12,13,14,6,7,9,11,12,13,7,11,12,13,15,12,15,15,4,5,6,7,8,12,13,4,5,6,7,8,12,13,14,5,6,7,11,12,13,14,11,12,13,15,11,12,15,5,6,7,13,14,5,6,7,12,13,14,5,6,12,13,14,11,12,13,11,12,13,5,6,13,5,6,12,13,14,5,6,12,13,14,11,12,13,14,11,12,13,12,13,13],\"type\":\"scatter3d\"},{\"hovertemplate\":\"color=green<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"green\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"green\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,9,9,9,10,10,10,10,10,10,10,11,11,12,12,12,13,13,14,14,14],\"y\":[1,3,7,9,9,10,14,0,3,4,4,5,6,6,7,7,10,10,11,13,5,5,10,14,1,1,2,6,9,10,14,4,6,8,8,9,10,11,12,13,7,8,9,9,9,10,2,3,8,9,9,10,10,10,10,11,0,2,4,4,5,9,9,10,10,10,1,1,6,7,10,10,0,4,8,0,1,4,4,5,5,6,0,3,3,4,5,3,5,4,5,6],\"z\":[13,7,8,5,13,15,15,8,8,12,13,9,2,10,6,8,6,12,6,1,4,5,11,0,12,14,15,12,9,11,9,13,11,11,15,14,8,10,10,14,11,7,6,7,8,7,10,15,8,7,8,6,7,8,12,12,6,6,8,15,15,7,9,7,8,9,5,8,5,5,7,8,12,13,6,15,15,10,11,8,10,6,14,14,12,8,11,14,11,13,14,12],\"type\":\"scatter3d\"},{\"hovertemplate\":\"color=red<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"red\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"red\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,5,5,5,5,5,5,6,6,7,7,7,7,8,8,10,10,10,11,11],\"y\":[7,10,13,13,14,0,1,6,7,9,10,11,14,15,15,3,3,5,8,10,10,12,13,0,3,3,4,4,6,8,9,11,12,0,1,1,3,5,7,9,1,1,3,3,3,8,6,9,1,2,2,7,3,6,5,5,7,5,7],\"z\":[9,10,9,13,9,5,5,3,3,15,15,9,8,9,10,10,15,13,13,8,12,14,13,13,8,12,9,10,8,9,13,15,8,14,7,13,6,11,8,4,4,11,6,11,12,6,8,5,13,8,9,3,7,14,5,14,11,4,13],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"title\":{\"text\":\"color\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Train idx:123; ddg=1.3\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4a5651cc-6cf0-4198-9b7c-2124cd0777de');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "color=green<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "green",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "green",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          0,
          1,
          1,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15
         ],
         "y": [
          13,
          14,
          15,
          13,
          14,
          15,
          11,
          12,
          13,
          14,
          14,
          15,
          11,
          11,
          12,
          12,
          14,
          15,
          9,
          12,
          12,
          13,
          11,
          12,
          13,
          14,
          14,
          8,
          9,
          14,
          14,
          15,
          15,
          8,
          8,
          9,
          10,
          11,
          11,
          12,
          13,
          11,
          13,
          11,
          12,
          12,
          13,
          13,
          15,
          9,
          11,
          12,
          13,
          13,
          13,
          14,
          14,
          15,
          15,
          15,
          7,
          9,
          12,
          14,
          7,
          7,
          11,
          12,
          12,
          13,
          13,
          14,
          14,
          15,
          9,
          11,
          12,
          12,
          13,
          14,
          14,
          14,
          15,
          15,
          15,
          7,
          7,
          8,
          9,
          10,
          11,
          12,
          12,
          12,
          13,
          14,
          15
         ],
         "z": [
          5,
          5,
          2,
          1,
          1,
          6,
          5,
          11,
          2,
          2,
          7,
          10,
          8,
          11,
          7,
          11,
          11,
          6,
          2,
          6,
          7,
          3,
          3,
          3,
          12,
          2,
          3,
          3,
          0,
          11,
          13,
          1,
          10,
          1,
          2,
          5,
          5,
          2,
          5,
          5,
          5,
          3,
          8,
          3,
          0,
          3,
          0,
          6,
          11,
          3,
          8,
          1,
          1,
          3,
          7,
          3,
          5,
          4,
          7,
          11,
          0,
          3,
          4,
          7,
          0,
          4,
          11,
          5,
          6,
          5,
          7,
          6,
          7,
          3,
          3,
          7,
          8,
          9,
          8,
          8,
          9,
          11,
          6,
          7,
          9,
          13,
          14,
          11,
          0,
          6,
          6,
          6,
          7,
          8,
          7,
          11,
          10
         ]
        },
        {
         "hovertemplate": "color=blue<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "blue",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "blue",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15
         ],
         "y": [
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          11,
          11,
          12,
          12,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          11,
          11,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          8,
          9,
          9,
          9,
          10,
          10,
          10,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          7,
          7,
          7,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          7,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          6,
          6,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15
         ],
         "z": [
          6,
          7,
          3,
          4,
          5,
          6,
          7,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          8,
          9,
          8,
          9,
          2,
          3,
          6,
          8,
          2,
          3,
          4,
          6,
          7,
          3,
          4,
          5,
          6,
          7,
          8,
          8,
          9,
          7,
          8,
          9,
          2,
          3,
          4,
          8,
          9,
          2,
          3,
          4,
          2,
          3,
          4,
          7,
          8,
          9,
          10,
          11,
          4,
          5,
          6,
          8,
          9,
          10,
          3,
          4,
          5,
          6,
          8,
          9,
          3,
          4,
          5,
          3,
          4,
          5,
          6,
          7,
          8,
          11,
          4,
          3,
          4,
          5,
          6,
          9,
          10,
          3,
          4,
          5,
          6,
          8,
          9,
          10,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          3,
          4,
          5,
          3,
          4,
          7,
          10,
          11,
          12,
          3,
          3,
          4,
          5,
          3,
          4,
          5,
          3,
          4,
          5,
          3,
          4,
          5,
          8,
          9,
          4,
          5,
          7,
          8,
          9,
          3,
          4,
          5,
          7,
          8,
          9,
          11,
          12,
          1,
          2,
          3,
          4,
          5,
          10,
          11,
          12,
          3,
          4,
          2,
          3,
          4,
          5,
          6,
          7,
          2,
          3,
          4,
          5,
          6,
          4,
          5,
          6,
          4,
          5,
          6,
          8,
          9,
          7,
          8,
          9,
          4,
          5,
          7,
          8,
          11,
          12,
          13,
          1,
          2,
          3,
          4,
          5,
          7,
          10,
          11,
          12,
          13,
          8,
          1,
          2,
          6,
          7,
          8,
          9,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          2,
          3,
          4,
          5,
          6,
          5,
          6,
          7,
          8,
          9,
          7,
          8,
          9,
          12,
          2,
          8,
          11,
          12,
          7,
          8,
          9,
          7,
          8,
          9,
          1,
          2,
          3,
          6,
          7,
          8,
          9,
          0,
          1,
          2,
          3,
          4,
          6,
          7,
          8,
          0,
          3,
          4,
          6,
          0,
          1,
          6,
          0,
          1,
          2,
          3,
          6,
          7,
          8,
          9,
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          8,
          9,
          6,
          7,
          8,
          8,
          7,
          8,
          9,
          5,
          6,
          7,
          8,
          0,
          3,
          5,
          6,
          7,
          8,
          0,
          4,
          6,
          7,
          8,
          0,
          1,
          2,
          3,
          4,
          5,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          4,
          5,
          6,
          7,
          8,
          9,
          12,
          5,
          6,
          7,
          5,
          6,
          7,
          8,
          4,
          5,
          6,
          7,
          8,
          9,
          1,
          2,
          4,
          5,
          6,
          8,
          1,
          2,
          3,
          4,
          5,
          8,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          4,
          5,
          6,
          7,
          8,
          9,
          12,
          13,
          1,
          2,
          4,
          5,
          0,
          1,
          2,
          4,
          5,
          0,
          1,
          4,
          5,
          6,
          0,
          4,
          5,
          6,
          4,
          5,
          6,
          10,
          4,
          5,
          6,
          9,
          10,
          4,
          5,
          6,
          8,
          4,
          7,
          8,
          9,
          5,
          8,
          9,
          12,
          1,
          2,
          4,
          5,
          6,
          0,
          1,
          2,
          4,
          5,
          6,
          0,
          1,
          4,
          5,
          6,
          0,
          1,
          3,
          4,
          5,
          6,
          4,
          5,
          6,
          9,
          10,
          11,
          0,
          5,
          6,
          8,
          9,
          10,
          11,
          0,
          5,
          6,
          8,
          9,
          10,
          0,
          8,
          9,
          0,
          6,
          7,
          8,
          9,
          1,
          5,
          0,
          1,
          2,
          4,
          5,
          0,
          1,
          3,
          4,
          5,
          0,
          3,
          4,
          5,
          3,
          4,
          9,
          10,
          0,
          1,
          8,
          9,
          10,
          11,
          14,
          0,
          1,
          8,
          9,
          10,
          13,
          14,
          15,
          0,
          8,
          9,
          0,
          4,
          5,
          6,
          7,
          8,
          9,
          0,
          1,
          0,
          1,
          2,
          0,
          1,
          2,
          6,
          7,
          13,
          0,
          1,
          4,
          7,
          3,
          4,
          7,
          8,
          4,
          8,
          0,
          1,
          2,
          3,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          9,
          12,
          13,
          14,
          15,
          0,
          1,
          3,
          12,
          13,
          14,
          15,
          0,
          1,
          4,
          8,
          11,
          12,
          13,
          14,
          0,
          1,
          0,
          1,
          6,
          10,
          11,
          0,
          1,
          2,
          5,
          6,
          7,
          10,
          11,
          0,
          1,
          2,
          6,
          7,
          8,
          12,
          13,
          14,
          1,
          2,
          6,
          7,
          8,
          11,
          12,
          13,
          14,
          1,
          2,
          7,
          8,
          12,
          13,
          7,
          8,
          12,
          13,
          0,
          1,
          2,
          3,
          4,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          12,
          13,
          14,
          15,
          0,
          11,
          12,
          13,
          14
         ]
        },
        {
         "hovertemplate": "color=red<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "red",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "red",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15
         ],
         "y": [
          12,
          13,
          11,
          12,
          14,
          15,
          15,
          10,
          10,
          11,
          13,
          14,
          15,
          10,
          14,
          14,
          15,
          8,
          10,
          11,
          13,
          14,
          15,
          15,
          7,
          7,
          8,
          8,
          9,
          10,
          11,
          14,
          14,
          15,
          7,
          10,
          11,
          11,
          12,
          13,
          13,
          15,
          15,
          8,
          11,
          13,
          14,
          15,
          7,
          7,
          8,
          9,
          9,
          11,
          11,
          12,
          14,
          15,
          7,
          8,
          8,
          8,
          9,
          9,
          10,
          8,
          10,
          10,
          11,
          11,
          11,
          12,
          13,
          14,
          15,
          9,
          11,
          12,
          13,
          13,
          14,
          15,
          15,
          8,
          8,
          9,
          9,
          11,
          12,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          6,
          6,
          7,
          7,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          11,
          11,
          12,
          12,
          5,
          5,
          5,
          6,
          6,
          7,
          7,
          8,
          8,
          8,
          9,
          9,
          9,
          10,
          10,
          11,
          11,
          14,
          14,
          14,
          15,
          15,
          15
         ],
         "z": [
          7,
          9,
          10,
          10,
          5,
          5,
          8,
          9,
          10,
          6,
          7,
          8,
          12,
          5,
          8,
          9,
          5,
          4,
          6,
          6,
          10,
          13,
          8,
          13,
          8,
          9,
          8,
          9,
          1,
          7,
          7,
          0,
          9,
          8,
          9,
          0,
          0,
          7,
          7,
          0,
          1,
          7,
          9,
          10,
          7,
          4,
          4,
          5,
          9,
          10,
          10,
          9,
          10,
          5,
          9,
          8,
          9,
          3,
          9,
          8,
          9,
          10,
          0,
          9,
          0,
          6,
          1,
          7,
          0,
          7,
          9,
          11,
          10,
          10,
          0,
          2,
          0,
          1,
          1,
          11,
          10,
          1,
          10,
          7,
          8,
          7,
          8,
          5,
          15,
          1,
          10,
          13,
          14,
          15,
          1,
          12,
          13,
          14,
          6,
          7,
          6,
          7,
          8,
          9,
          14,
          8,
          9,
          12,
          13,
          14,
          5,
          9,
          12,
          13,
          4,
          12,
          2,
          5,
          6,
          5,
          7,
          8,
          15,
          3,
          9,
          15,
          3,
          9,
          15,
          9,
          14,
          9,
          14,
          4,
          8,
          9,
          2,
          8,
          9
         ]
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "color"
         },
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0.0,
           1.0
          ],
          "y": [
           0.0,
           1.0
          ]
         },
         "xaxis": {
          "title": {
           "text": "x"
          }
         },
         "yaxis": {
          "title": {
           "text": "y"
          }
         },
         "zaxis": {
          "title": {
           "text": "z"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Train idx:124; ddg=-0.06"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"4dbcbcc7-869f-43a4-9de7-c6d4f138b1fc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4dbcbcc7-869f-43a4-9de7-c6d4f138b1fc\")) {                    Plotly.newPlot(                        \"4dbcbcc7-869f-43a4-9de7-c6d4f138b1fc\",                        [{\"hovertemplate\":\"color=green<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"green\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"green\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0,1,1,2,2,2,3,3,3,3,3,3,4,4,4,4,4,4,5,5,5,5,6,6,6,6,6,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15],\"y\":[13,14,15,13,14,15,11,12,13,14,14,15,11,11,12,12,14,15,9,12,12,13,11,12,13,14,14,8,9,14,14,15,15,8,8,9,10,11,11,12,13,11,13,11,12,12,13,13,15,9,11,12,13,13,13,14,14,15,15,15,7,9,12,14,7,7,11,12,12,13,13,14,14,15,9,11,12,12,13,14,14,14,15,15,15,7,7,8,9,10,11,12,12,12,13,14,15],\"z\":[5,5,2,1,1,6,5,11,2,2,7,10,8,11,7,11,11,6,2,6,7,3,3,3,12,2,3,3,0,11,13,1,10,1,2,5,5,2,5,5,5,3,8,3,0,3,0,6,11,3,8,1,1,3,7,3,5,4,7,11,0,3,4,7,0,4,11,5,6,5,7,6,7,3,3,7,8,9,8,8,9,11,6,7,9,13,14,11,0,6,6,6,7,8,7,11,10],\"type\":\"scatter3d\"},{\"hovertemplate\":\"color=blue<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"blue\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"blue\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15],\"y\":[13,13,14,14,14,14,14,15,15,15,15,15,15,15,11,11,12,12,13,13,13,13,14,14,14,14,14,15,15,15,15,15,15,11,11,12,12,12,13,13,13,13,13,14,14,14,15,15,15,15,11,11,11,11,12,12,12,12,12,12,13,13,13,13,13,13,14,14,14,15,15,15,15,15,15,15,10,11,11,11,11,11,11,12,12,12,12,12,12,12,13,13,13,13,13,13,13,14,14,14,15,15,15,15,15,15,8,9,9,9,10,10,10,11,11,11,12,12,12,12,12,13,13,13,13,13,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,8,8,9,9,9,9,9,9,10,10,10,10,10,11,11,11,12,12,12,12,12,13,13,13,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,7,8,8,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,11,11,11,11,11,12,12,13,13,13,14,14,14,14,15,15,15,15,7,7,7,8,8,8,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,11,11,11,11,12,12,12,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,15,15,15,7,8,8,8,9,9,9,9,10,10,10,10,10,10,11,11,11,11,11,12,12,12,12,12,12,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,9,9,9,10,10,10,10,11,11,11,11,11,11,12,12,12,12,12,12,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,7,7,7,7,8,8,8,8,8,9,9,9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,12,13,13,13,13,14,14,14,14,15,15,15,15,7,7,7,7,7,8,8,8,8,8,8,9,9,9,9,9,10,10,10,10,10,10,11,11,11,11,11,11,12,12,12,12,12,12,12,13,13,13,13,13,13,14,14,14,15,15,15,15,15,7,7,8,8,8,8,8,9,9,9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,14,14,14,15,15,15,15,15,15,15,6,6,7,7,7,8,8,8,8,8,8,9,9,9,9,10,10,10,10,11,11,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,5,5,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,11,11,11,11,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,15,15,15,15,15],\"z\":[6,7,3,4,5,6,7,2,3,4,5,6,7,8,8,9,8,9,2,3,6,8,2,3,4,6,7,3,4,5,6,7,8,8,9,7,8,9,2,3,4,8,9,2,3,4,2,3,4,7,8,9,10,11,4,5,6,8,9,10,3,4,5,6,8,9,3,4,5,3,4,5,6,7,8,11,4,3,4,5,6,9,10,3,4,5,6,8,9,10,3,4,5,6,7,8,9,3,4,5,3,4,7,10,11,12,3,3,4,5,3,4,5,3,4,5,3,4,5,8,9,4,5,7,8,9,3,4,5,7,8,9,11,12,1,2,3,4,5,10,11,12,3,4,2,3,4,5,6,7,2,3,4,5,6,4,5,6,4,5,6,8,9,7,8,9,4,5,7,8,11,12,13,1,2,3,4,5,7,10,11,12,13,8,1,2,6,7,8,9,1,2,3,4,5,6,7,8,1,2,3,4,5,6,7,8,2,3,4,5,6,5,6,7,8,9,7,8,9,12,2,8,11,12,7,8,9,7,8,9,1,2,3,6,7,8,9,0,1,2,3,4,6,7,8,0,3,4,6,0,1,6,0,1,2,3,6,7,8,9,0,1,2,3,5,6,7,8,9,6,7,8,8,7,8,9,5,6,7,8,0,3,5,6,7,8,0,4,6,7,8,0,1,2,3,4,5,0,1,2,3,4,5,6,7,0,1,2,3,4,5,6,7,8,4,5,6,7,8,9,12,5,6,7,5,6,7,8,4,5,6,7,8,9,1,2,4,5,6,8,1,2,3,4,5,8,1,2,3,4,5,6,7,8,9,4,5,6,7,8,9,12,13,1,2,4,5,0,1,2,4,5,0,1,4,5,6,0,4,5,6,4,5,6,10,4,5,6,9,10,4,5,6,8,4,7,8,9,5,8,9,12,1,2,4,5,6,0,1,2,4,5,6,0,1,4,5,6,0,1,3,4,5,6,4,5,6,9,10,11,0,5,6,8,9,10,11,0,5,6,8,9,10,0,8,9,0,6,7,8,9,1,5,0,1,2,4,5,0,1,3,4,5,0,3,4,5,3,4,9,10,0,1,8,9,10,11,14,0,1,8,9,10,13,14,15,0,8,9,0,4,5,6,7,8,9,0,1,0,1,2,0,1,2,6,7,13,0,1,4,7,3,4,7,8,4,8,0,1,2,3,13,14,15,0,1,2,3,4,9,12,13,14,15,0,1,3,12,13,14,15,0,1,4,8,11,12,13,14,0,1,0,1,6,10,11,0,1,2,5,6,7,10,11,0,1,2,6,7,8,12,13,14,1,2,6,7,8,11,12,13,14,1,2,7,8,12,13,7,8,12,13,0,1,2,3,4,12,13,14,15,0,1,2,3,4,12,13,14,15,0,1,2,3,12,13,14,15,0,11,12,13,14],\"type\":\"scatter3d\"},{\"hovertemplate\":\"color=red<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"red\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"red\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[1,1,2,2,2,2,2,3,3,3,3,3,3,4,4,4,4,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15],\"y\":[12,13,11,12,14,15,15,10,10,11,13,14,15,10,14,14,15,8,10,11,13,14,15,15,7,7,8,8,9,10,11,14,14,15,7,10,11,11,12,13,13,15,15,8,11,13,14,15,7,7,8,9,9,11,11,12,14,15,7,8,8,8,9,9,10,8,10,10,11,11,11,12,13,14,15,9,11,12,13,13,14,15,15,8,8,9,9,11,12,14,14,14,14,14,15,15,15,15,6,6,7,7,8,8,8,9,9,9,9,9,10,10,11,11,12,12,5,5,5,6,6,7,7,8,8,8,9,9,9,10,10,11,11,14,14,14,15,15,15],\"z\":[7,9,10,10,5,5,8,9,10,6,7,8,12,5,8,9,5,4,6,6,10,13,8,13,8,9,8,9,1,7,7,0,9,8,9,0,0,7,7,0,1,7,9,10,7,4,4,5,9,10,10,9,10,5,9,8,9,3,9,8,9,10,0,9,0,6,1,7,0,7,9,11,10,10,0,2,0,1,1,11,10,1,10,7,8,7,8,5,15,1,10,13,14,15,1,12,13,14,6,7,6,7,8,9,14,8,9,12,13,14,5,9,12,13,4,12,2,5,6,5,7,8,15,3,9,15,3,9,15,9,14,9,14,4,8,9,2,8,9],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"title\":{\"text\":\"color\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Train idx:124; ddg=-0.06\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4dbcbcc7-869f-43a4-9de7-c6d4f138b1fc');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "color=blue<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "blue",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "blue",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15
         ],
         "y": [
          11,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          11,
          11,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          8,
          10,
          11,
          11,
          12,
          12,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          7,
          7,
          8,
          8,
          10,
          10,
          11,
          11,
          11,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          6,
          7,
          7,
          7,
          8,
          8,
          8,
          10,
          10,
          11,
          11,
          11,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          15,
          15,
          15,
          6,
          6,
          7,
          7,
          7,
          8,
          8,
          10,
          10,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          15,
          6,
          6,
          6,
          7,
          7,
          7,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          5,
          5,
          5,
          6,
          6,
          6,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          1,
          5,
          5,
          5,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          3,
          4,
          4,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          1,
          1,
          1,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          1,
          1,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          12,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          0,
          0,
          1,
          1,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          15,
          15,
          0,
          0,
          1,
          1,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          6,
          6,
          7,
          7,
          7,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          2,
          3,
          3,
          4,
          4,
          4,
          5,
          5,
          5,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          13,
          13,
          14,
          14
         ],
         "z": [
          10,
          10,
          11,
          15,
          10,
          11,
          12,
          14,
          15,
          9,
          10,
          11,
          12,
          13,
          15,
          11,
          12,
          13,
          10,
          11,
          9,
          10,
          11,
          10,
          11,
          12,
          15,
          10,
          11,
          12,
          13,
          11,
          12,
          13,
          12,
          12,
          11,
          12,
          10,
          11,
          12,
          5,
          6,
          7,
          8,
          11,
          12,
          5,
          6,
          8,
          12,
          15,
          12,
          13,
          12,
          13,
          11,
          12,
          11,
          12,
          13,
          11,
          12,
          13,
          6,
          7,
          12,
          13,
          5,
          6,
          7,
          8,
          9,
          5,
          6,
          7,
          8,
          9,
          13,
          12,
          13,
          14,
          12,
          13,
          14,
          11,
          12,
          11,
          12,
          13,
          11,
          12,
          13,
          6,
          7,
          12,
          13,
          6,
          7,
          8,
          6,
          7,
          8,
          12,
          13,
          12,
          13,
          14,
          13,
          14,
          12,
          13,
          11,
          12,
          13,
          6,
          7,
          11,
          12,
          13,
          5,
          6,
          7,
          8,
          5,
          6,
          7,
          8,
          0,
          12,
          13,
          14,
          12,
          13,
          14,
          12,
          13,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          7,
          8,
          10,
          11,
          12,
          13,
          6,
          7,
          8,
          11,
          12,
          6,
          7,
          8,
          15,
          2,
          3,
          4,
          7,
          8,
          9,
          15,
          12,
          13,
          14,
          12,
          13,
          14,
          8,
          13,
          14,
          7,
          8,
          9,
          10,
          8,
          9,
          10,
          11,
          12,
          9,
          10,
          11,
          12,
          4,
          7,
          8,
          9,
          11,
          12,
          4,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          6,
          7,
          8,
          11,
          12,
          15,
          4,
          5,
          7,
          8,
          9,
          10,
          15,
          3,
          4,
          5,
          7,
          8,
          9,
          10,
          14,
          15,
          11,
          12,
          14,
          12,
          12,
          13,
          14,
          12,
          13,
          14,
          7,
          8,
          9,
          10,
          7,
          8,
          9,
          10,
          11,
          12,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          9,
          10,
          11,
          12,
          13,
          3,
          4,
          6,
          7,
          8,
          10,
          11,
          12,
          3,
          4,
          6,
          7,
          8,
          10,
          11,
          12,
          4,
          6,
          7,
          8,
          10,
          11,
          14,
          15,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          14,
          15,
          4,
          5,
          8,
          9,
          10,
          14,
          15,
          11,
          12,
          13,
          14,
          15,
          11,
          12,
          13,
          14,
          14,
          13,
          14,
          13,
          14,
          15,
          10,
          11,
          13,
          14,
          15,
          8,
          9,
          10,
          11,
          13,
          14,
          7,
          8,
          9,
          10,
          11,
          12,
          8,
          9,
          10,
          11,
          12,
          13,
          8,
          10,
          11,
          12,
          3,
          4,
          5,
          6,
          7,
          8,
          10,
          11,
          12,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          10,
          11,
          12,
          14,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          13,
          14,
          15,
          9,
          14,
          15,
          6,
          7,
          14,
          15,
          11,
          12,
          13,
          14,
          12,
          13,
          14,
          14,
          9,
          13,
          14,
          15,
          6,
          7,
          9,
          10,
          12,
          13,
          14,
          15,
          7,
          12,
          13,
          14,
          10,
          11,
          13,
          14,
          15,
          9,
          10,
          11,
          13,
          14,
          15,
          9,
          10,
          11,
          14,
          15,
          9,
          10,
          11,
          14,
          15,
          7,
          8,
          9,
          11,
          14,
          15,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          14,
          15,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          13,
          14,
          15,
          7,
          8,
          9,
          10,
          11,
          13,
          14,
          15,
          6,
          7,
          8,
          10,
          14,
          15,
          13,
          14,
          15,
          13,
          14,
          15,
          15,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          14,
          15,
          10,
          11,
          12,
          13,
          14,
          15,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          7,
          8,
          11,
          14,
          15,
          7,
          8,
          10,
          11,
          12,
          15,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          5,
          8,
          9,
          10,
          11,
          14,
          15,
          9,
          10,
          11,
          13,
          14,
          15,
          7,
          9,
          10,
          11,
          14,
          15,
          13,
          14,
          15,
          14,
          15,
          13,
          15,
          8,
          9,
          10,
          11,
          12,
          13,
          15,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          15,
          7,
          8,
          9,
          10,
          11,
          13,
          8,
          11,
          12,
          14,
          15,
          10,
          11,
          12,
          13,
          14,
          15,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          9,
          10,
          11,
          14,
          15,
          9,
          9,
          10,
          11,
          9,
          10,
          11,
          12,
          14,
          10,
          11,
          12,
          14,
          15,
          13,
          15,
          12,
          13,
          14,
          10,
          11,
          12,
          13,
          14,
          15,
          7,
          8,
          10,
          11,
          12,
          13,
          14,
          15,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          7,
          8,
          11,
          12,
          13,
          11,
          12,
          13,
          10,
          11,
          12,
          14,
          9,
          10,
          11,
          15,
          9,
          10,
          11,
          15,
          10,
          9,
          10,
          11,
          9,
          10,
          11,
          12,
          10,
          11,
          14,
          15,
          14,
          15,
          12,
          13,
          15,
          12,
          13,
          14,
          15,
          13,
          14,
          15,
          8,
          13,
          14,
          15,
          14,
          15,
          13,
          14,
          15,
          9,
          10,
          11,
          9,
          10,
          11,
          12,
          9,
          10,
          11,
          12,
          13,
          15,
          12,
          13,
          9,
          10,
          11,
          12,
          9,
          10,
          11,
          12,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          12,
          13,
          14,
          15,
          14,
          15,
          13,
          14,
          15,
          13,
          14,
          15,
          13,
          14,
          15,
          9,
          10,
          13,
          14,
          15,
          9,
          10,
          11,
          14,
          9,
          10,
          11,
          12,
          10,
          11,
          12,
          13,
          11,
          12,
          13,
          14,
          12,
          13,
          14,
          11,
          12,
          11,
          12
         ]
        },
        {
         "hovertemplate": "color=green<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "green",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "green",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          0,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15
         ],
         "y": [
          13,
          7,
          15,
          6,
          7,
          8,
          15,
          6,
          7,
          8,
          5,
          5,
          6,
          8,
          5,
          5,
          5,
          6,
          8,
          8,
          9,
          9,
          7,
          9,
          11,
          13,
          14,
          4,
          12,
          13,
          14,
          3,
          4,
          5,
          14,
          1,
          4,
          5,
          12,
          15,
          0,
          5,
          6,
          11,
          12,
          13,
          15,
          4,
          5,
          5,
          11,
          11,
          12,
          12,
          15,
          4,
          10,
          11,
          11,
          12,
          14,
          15,
          4,
          6,
          11,
          11,
          12,
          14,
          8,
          14,
          14
         ],
         "z": [
          9,
          12,
          11,
          12,
          11,
          11,
          15,
          12,
          11,
          11,
          12,
          13,
          11,
          12,
          12,
          13,
          14,
          11,
          7,
          8,
          7,
          8,
          12,
          7,
          3,
          14,
          14,
          13,
          5,
          13,
          13,
          13,
          12,
          12,
          13,
          11,
          11,
          11,
          13,
          9,
          12,
          15,
          13,
          14,
          15,
          13,
          13,
          6,
          6,
          15,
          14,
          15,
          14,
          15,
          9,
          9,
          14,
          14,
          15,
          15,
          8,
          9,
          12,
          13,
          11,
          15,
          12,
          8,
          13,
          9,
          10
         ]
        },
        {
         "hovertemplate": "color=red<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "red",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "red",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          1,
          2,
          4,
          4,
          5,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          14,
          14,
          15
         ],
         "y": [
          13,
          8,
          14,
          15,
          6,
          8,
          13,
          14,
          15,
          6,
          7,
          8,
          10,
          0,
          0,
          7,
          7,
          8,
          11,
          11,
          12,
          12,
          9,
          9,
          10,
          10,
          12,
          12,
          15,
          5,
          8,
          11,
          3,
          13,
          14,
          3,
          5,
          12,
          13,
          14,
          9,
          9,
          15,
          2,
          7,
          10
         ],
         "z": [
          13,
          13,
          9,
          9,
          14,
          13,
          9,
          9,
          14,
          15,
          15,
          14,
          8,
          13,
          15,
          13,
          14,
          13,
          5,
          13,
          14,
          15,
          14,
          15,
          14,
          15,
          9,
          15,
          9,
          15,
          13,
          15,
          15,
          3,
          12,
          14,
          12,
          10,
          12,
          15,
          12,
          14,
          12,
          14,
          12,
          14
         ]
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "color"
         },
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0.0,
           1.0
          ],
          "y": [
           0.0,
           1.0
          ]
         },
         "xaxis": {
          "title": {
           "text": "x"
          }
         },
         "yaxis": {
          "title": {
           "text": "y"
          }
         },
         "zaxis": {
          "title": {
           "text": "z"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Train idx:125; ddg=-0.5"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"1d428ef1-f563-4e5a-8983-08500bdfb9af\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1d428ef1-f563-4e5a-8983-08500bdfb9af\")) {                    Plotly.newPlot(                        \"1d428ef1-f563-4e5a-8983-08500bdfb9af\",                        [{\"hovertemplate\":\"color=blue<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"blue\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"blue\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15],\"y\":[11,12,12,12,13,13,13,13,13,14,14,14,14,14,14,15,15,15,11,11,12,12,12,13,13,13,13,14,14,14,14,15,15,15,8,10,11,11,12,12,13,14,14,14,14,14,14,15,15,15,15,15,7,7,8,8,10,10,11,11,11,12,12,12,13,13,13,13,14,14,14,14,14,15,15,15,15,15,6,7,7,7,8,8,8,10,10,11,11,11,12,12,12,13,13,13,13,14,14,14,15,15,15,6,6,7,7,7,8,8,10,10,11,11,11,12,12,12,12,12,13,13,13,13,14,14,14,14,15,6,6,6,7,7,7,10,10,11,11,11,11,11,11,11,12,12,12,12,12,12,13,13,13,13,13,14,14,14,14,15,15,15,15,15,15,15,5,5,5,6,6,6,7,7,7,8,8,8,8,9,9,9,9,9,10,10,10,10,11,11,11,11,11,11,12,12,12,12,12,12,12,12,13,13,13,13,13,13,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,0,0,0,1,5,5,5,6,6,6,7,7,7,7,8,8,8,8,8,8,9,9,9,9,9,9,9,10,10,10,10,10,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,0,0,0,0,0,1,1,1,1,3,4,4,5,5,5,6,6,6,6,6,7,7,7,7,7,7,8,8,8,8,8,8,9,9,9,9,9,9,10,10,10,10,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,15,15,15,15,0,0,0,0,1,1,1,2,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,6,6,6,6,6,7,7,7,7,7,7,8,8,8,8,8,9,9,9,9,9,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,15,15,15,15,15,15,0,0,0,1,1,1,2,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,6,6,7,7,7,7,7,7,8,8,8,8,8,8,8,9,9,9,9,9,9,9,10,10,10,10,10,11,11,11,11,11,11,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,14,14,14,14,14,14,15,15,15,15,15,15,0,0,0,1,1,2,2,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,6,6,6,6,6,7,7,7,7,7,7,8,8,8,8,8,8,8,9,9,9,9,9,9,9,10,10,10,10,10,12,13,13,13,14,14,14,14,14,15,15,15,0,0,1,1,2,2,2,3,3,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,6,6,6,6,6,7,7,7,8,8,8,8,9,9,9,9,10,10,10,10,11,13,13,13,14,14,14,14,15,15,0,0,1,1,2,2,2,3,3,3,3,4,4,4,5,5,5,5,6,6,7,7,7,8,8,8,9,9,9,9,10,10,10,10,10,10,11,11,13,13,13,13,14,14,14,14,15,15,15,0,0,0,0,1,1,1,2,3,3,4,4,4,5,5,5,6,6,6,7,7,7,7,7,8,8,8,8,9,9,9,9,10,10,10,10,11,11,11,11,12,12,12,13,13,14,14],\"z\":[10,10,11,15,10,11,12,14,15,9,10,11,12,13,15,11,12,13,10,11,9,10,11,10,11,12,15,10,11,12,13,11,12,13,12,12,11,12,10,11,12,5,6,7,8,11,12,5,6,8,12,15,12,13,12,13,11,12,11,12,13,11,12,13,6,7,12,13,5,6,7,8,9,5,6,7,8,9,13,12,13,14,12,13,14,11,12,11,12,13,11,12,13,6,7,12,13,6,7,8,6,7,8,12,13,12,13,14,13,14,12,13,11,12,13,6,7,11,12,13,5,6,7,8,5,6,7,8,0,12,13,14,12,13,14,12,13,7,8,9,10,11,12,13,7,8,10,11,12,13,6,7,8,11,12,6,7,8,15,2,3,4,7,8,9,15,12,13,14,12,13,14,8,13,14,7,8,9,10,8,9,10,11,12,9,10,11,12,4,7,8,9,11,12,4,6,7,8,9,10,11,12,6,7,8,11,12,15,4,5,7,8,9,10,15,3,4,5,7,8,9,10,14,15,11,12,14,12,12,13,14,12,13,14,7,8,9,10,7,8,9,10,11,12,7,8,9,10,11,12,13,9,10,11,12,13,3,4,6,7,8,10,11,12,3,4,6,7,8,10,11,12,4,6,7,8,10,11,14,15,4,5,6,7,8,9,10,14,15,4,5,8,9,10,14,15,11,12,13,14,15,11,12,13,14,14,13,14,13,14,15,10,11,13,14,15,8,9,10,11,13,14,7,8,9,10,11,12,8,9,10,11,12,13,8,10,11,12,3,4,5,6,7,8,10,11,12,2,3,4,5,6,7,8,10,11,12,14,2,3,4,5,6,7,8,9,10,11,13,14,15,9,14,15,6,7,14,15,11,12,13,14,12,13,14,14,9,13,14,15,6,7,9,10,12,13,14,15,7,12,13,14,10,11,13,14,15,9,10,11,13,14,15,9,10,11,14,15,9,10,11,14,15,7,8,9,11,14,15,3,4,5,6,7,8,9,10,11,12,2,3,4,5,6,7,8,9,10,11,12,14,15,2,3,4,5,6,7,8,9,10,11,13,14,15,7,8,9,10,11,13,14,15,6,7,8,10,14,15,13,14,15,13,14,15,15,7,8,9,10,11,12,13,14,6,7,8,9,10,11,12,13,14,6,7,8,9,10,11,12,13,14,14,15,10,11,12,13,14,15,9,10,11,12,13,14,15,9,10,11,12,13,14,15,7,8,11,14,15,7,8,10,11,12,15,5,6,7,8,9,10,11,12,5,8,9,10,11,14,15,9,10,11,13,14,15,7,9,10,11,14,15,13,14,15,14,15,13,15,8,9,10,11,12,13,15,7,8,9,10,11,12,13,15,7,8,9,10,11,13,8,11,12,14,15,10,11,12,13,14,15,9,10,11,12,13,14,15,9,10,11,12,13,14,15,9,10,11,14,15,9,9,10,11,9,10,11,12,14,10,11,12,14,15,13,15,12,13,14,10,11,12,13,14,15,7,8,10,11,12,13,14,15,7,8,9,10,11,12,13,14,7,8,11,12,13,11,12,13,10,11,12,14,9,10,11,15,9,10,11,15,10,9,10,11,9,10,11,12,10,11,14,15,14,15,12,13,15,12,13,14,15,13,14,15,8,13,14,15,14,15,13,14,15,9,10,11,9,10,11,12,9,10,11,12,13,15,12,13,9,10,11,12,9,10,11,12,9,10,11,12,13,14,15,12,13,14,15,14,15,13,14,15,13,14,15,13,14,15,9,10,13,14,15,9,10,11,14,9,10,11,12,10,11,12,13,11,12,13,14,12,13,14,11,12,11,12],\"type\":\"scatter3d\"},{\"hovertemplate\":\"color=green<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"green\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"green\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0,2,2,3,3,3,3,4,4,4,5,5,5,5,6,6,6,6,6,6,6,6,7,7,7,7,7,8,8,8,8,9,9,9,9,10,10,10,10,10,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,14,14,14,14,14,14,15,15,15],\"y\":[13,7,15,6,7,8,15,6,7,8,5,5,6,8,5,5,5,6,8,8,9,9,7,9,11,13,14,4,12,13,14,3,4,5,14,1,4,5,12,15,0,5,6,11,12,13,15,4,5,5,11,11,12,12,15,4,10,11,11,12,14,15,4,6,11,11,12,14,8,14,14],\"z\":[9,12,11,12,11,11,15,12,11,11,12,13,11,12,12,13,14,11,7,8,7,8,12,7,3,14,14,13,5,13,13,13,12,12,13,11,11,11,13,9,12,15,13,14,15,13,13,6,6,15,14,15,14,15,9,9,14,14,15,15,8,9,12,13,11,15,12,8,13,9,10],\"type\":\"scatter3d\"},{\"hovertemplate\":\"color=red<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"red\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"red\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[1,2,4,4,5,6,6,6,6,7,7,7,7,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,10,10,10,11,11,11,12,12,12,12,12,13,13,13,14,14,15],\"y\":[13,8,14,15,6,8,13,14,15,6,7,8,10,0,0,7,7,8,11,11,12,12,9,9,10,10,12,12,15,5,8,11,3,13,14,3,5,12,13,14,9,9,15,2,7,10],\"z\":[13,13,9,9,14,13,9,9,14,15,15,14,8,13,15,13,14,13,5,13,14,15,14,15,14,15,9,15,9,15,13,15,15,3,12,14,12,10,12,15,12,14,12,14,12,14],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"title\":{\"text\":\"color\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Train idx:125; ddg=-0.5\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1d428ef1-f563-4e5a-8983-08500bdfb9af');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "color=blue<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "blue",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "blue",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          7,
          7,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          6,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          1,
          1,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          1,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          1,
          1,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          11,
          12,
          12,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          0,
          1,
          1,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          1,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15
         ],
         "z": [
          8,
          9,
          10,
          11,
          12,
          8,
          9,
          10,
          11,
          8,
          9,
          10,
          12,
          5,
          6,
          10,
          11,
          12,
          13,
          14,
          0,
          5,
          6,
          7,
          8,
          10,
          11,
          12,
          13,
          14,
          5,
          6,
          7,
          8,
          10,
          11,
          12,
          13,
          14,
          6,
          7,
          8,
          0,
          12,
          10,
          11,
          12,
          13,
          3,
          4,
          5,
          6,
          7,
          10,
          11,
          12,
          0,
          3,
          4,
          5,
          6,
          7,
          10,
          11,
          12,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          10,
          11,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          13,
          14,
          2,
          3,
          4,
          14,
          4,
          5,
          10,
          11,
          4,
          5,
          9,
          10,
          11,
          9,
          10,
          11,
          8,
          9,
          10,
          11,
          8,
          9,
          10,
          11,
          12,
          10,
          11,
          12,
          13,
          0,
          5,
          6,
          7,
          11,
          12,
          13,
          14,
          5,
          6,
          7,
          13,
          4,
          0,
          4,
          7,
          13,
          14,
          5,
          6,
          7,
          8,
          11,
          0,
          1,
          2,
          4,
          5,
          6,
          7,
          10,
          11,
          12,
          14,
          15,
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          11,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          13,
          14,
          2,
          3,
          5,
          6,
          7,
          10,
          4,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          15,
          4,
          5,
          6,
          10,
          11,
          12,
          15,
          11,
          10,
          11,
          9,
          10,
          11,
          12,
          0,
          9,
          10,
          11,
          12,
          13,
          0,
          3,
          8,
          9,
          10,
          11,
          12,
          0,
          3,
          4,
          8,
          9,
          3,
          4,
          5,
          12,
          13,
          14,
          3,
          4,
          5,
          6,
          7,
          13,
          14,
          15,
          1,
          4,
          5,
          6,
          7,
          8,
          13,
          14,
          0,
          1,
          2,
          4,
          5,
          6,
          7,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          13,
          14,
          15,
          0,
          1,
          2,
          13,
          14,
          15,
          0,
          1,
          2,
          13,
          14,
          5,
          6,
          7,
          11,
          2,
          5,
          6,
          10,
          11,
          12,
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          14,
          15,
          11,
          9,
          10,
          11,
          0,
          9,
          10,
          11,
          0,
          2,
          3,
          4,
          8,
          9,
          10,
          2,
          3,
          4,
          5,
          7,
          8,
          9,
          10,
          12,
          13,
          3,
          4,
          5,
          7,
          8,
          9,
          12,
          13,
          14,
          3,
          4,
          5,
          12,
          13,
          14,
          15,
          3,
          4,
          5,
          6,
          7,
          12,
          13,
          14,
          0,
          1,
          2,
          3,
          4,
          5,
          0,
          1,
          2,
          0,
          1,
          2,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          14,
          15,
          10,
          11,
          9,
          10,
          11,
          12,
          9,
          10,
          11,
          3,
          4,
          7,
          8,
          9,
          10,
          0,
          1,
          2,
          3,
          4,
          5,
          7,
          8,
          9,
          12,
          13,
          0,
          1,
          2,
          3,
          4,
          5,
          7,
          8,
          9,
          12,
          13,
          14,
          15,
          2,
          3,
          4,
          5,
          11,
          12,
          13,
          14,
          2,
          3,
          4,
          5,
          11,
          12,
          13,
          2,
          3,
          4,
          13,
          3,
          4,
          5,
          15,
          4,
          15,
          3,
          15,
          9,
          10,
          13,
          14,
          0,
          1,
          6,
          7,
          9,
          10,
          13,
          14,
          15,
          0,
          1,
          2,
          6,
          7,
          8,
          9,
          10,
          11,
          11,
          14,
          4,
          5,
          10,
          11,
          13,
          14,
          15,
          4,
          5,
          8,
          9,
          10,
          11,
          13,
          14,
          15,
          0,
          7,
          8,
          9,
          10,
          11,
          12,
          0,
          1,
          2,
          4,
          5,
          7,
          8,
          9,
          10,
          11,
          0,
          1,
          2,
          4,
          5,
          7,
          8,
          9,
          12,
          13,
          15,
          0,
          2,
          3,
          11,
          12,
          13,
          15,
          0,
          2,
          3,
          4,
          11,
          12,
          13,
          14,
          3,
          4,
          11,
          12,
          13,
          14,
          2,
          3,
          4,
          12,
          13,
          2,
          3,
          4,
          7,
          8,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          7,
          8,
          13,
          14,
          15,
          0,
          1,
          3,
          4,
          9,
          13,
          14,
          15,
          9,
          10,
          13,
          14,
          15,
          0,
          5,
          6,
          7,
          8,
          9,
          10,
          14,
          4,
          14,
          3,
          4,
          5,
          13,
          14,
          15,
          3,
          4,
          5,
          6,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          5,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          0,
          1,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          0,
          1,
          9,
          10,
          11,
          15,
          0,
          13,
          15,
          0,
          11,
          12,
          13,
          14,
          2,
          3,
          4,
          10,
          11,
          12,
          13,
          2,
          3,
          4,
          5,
          8,
          10,
          11,
          12,
          13,
          14,
          1,
          2,
          3,
          4,
          6,
          7,
          8,
          9,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          6,
          7,
          8,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          6,
          7,
          13,
          14,
          15,
          2,
          3,
          4,
          6,
          11,
          13,
          14,
          2,
          3,
          5,
          6,
          7,
          11,
          12,
          4,
          3,
          4,
          5,
          2,
          3,
          4,
          5,
          13,
          14,
          1,
          2,
          3,
          4,
          5,
          11,
          12,
          13,
          14,
          15,
          1,
          2,
          3,
          10,
          11,
          12,
          13,
          14,
          15,
          9,
          10,
          11,
          12,
          13,
          9,
          10,
          11,
          12,
          13,
          3,
          8,
          13,
          2,
          7,
          8,
          9,
          10,
          11,
          12,
          1,
          2,
          3,
          4,
          5,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          2,
          3,
          4,
          5,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          3,
          4,
          6,
          7,
          8,
          9,
          10,
          12,
          13,
          14,
          0,
          1,
          2,
          3,
          6,
          7,
          8,
          14,
          0,
          1,
          2,
          3,
          6,
          7,
          8,
          9,
          12,
          14,
          2,
          3,
          4,
          8,
          9,
          10,
          11,
          12,
          13,
          2,
          3,
          6,
          8,
          9,
          10,
          11,
          12,
          4,
          14,
          15,
          3,
          4,
          5,
          1,
          2,
          3,
          4,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          7,
          11,
          12,
          13,
          15,
          0,
          2,
          3,
          7,
          10,
          12,
          13,
          14,
          2,
          3,
          4,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          0,
          1,
          2,
          3,
          4,
          7,
          8,
          9,
          10,
          11,
          12,
          0,
          1,
          2,
          3,
          4,
          5,
          7,
          8,
          9,
          10,
          11,
          12,
          2,
          3,
          4,
          5,
          9,
          10,
          11,
          13,
          14,
          15,
          9,
          10,
          13,
          14,
          6,
          7,
          8,
          11,
          12,
          2,
          5,
          6,
          7,
          8,
          9,
          11,
          12,
          13,
          3,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          0,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          13,
          14,
          15,
          0,
          1,
          2,
          0,
          1,
          2,
          3,
          14,
          15,
          0,
          1,
          2,
          11,
          12,
          14,
          15,
          0,
          1,
          6,
          7,
          8,
          11,
          12,
          13,
          0,
          2,
          3,
          6,
          7,
          8,
          10,
          11,
          12,
          13,
          14,
          1,
          2,
          3,
          4,
          6,
          7,
          8,
          9,
          10,
          11,
          13,
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          0,
          1,
          2,
          3,
          6,
          7,
          8,
          9,
          10,
          3,
          13,
          2,
          3,
          5,
          6,
          7,
          8,
          11,
          12,
          13,
          14,
          5,
          6,
          7,
          8,
          11,
          12,
          13,
          14,
          15,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          12,
          13,
          14,
          15,
          12,
          13,
          14,
          15,
          13,
          15,
          0,
          1,
          0,
          1,
          6,
          7,
          10,
          11,
          12,
          0,
          5,
          6,
          7,
          10,
          11,
          12,
          15,
          0,
          5,
          6,
          7,
          8,
          10,
          11,
          12,
          0,
          1,
          5,
          6,
          7,
          8,
          10,
          11,
          12,
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          2,
          3,
          2,
          3,
          4,
          5,
          6,
          7,
          12,
          13,
          14,
          15,
          2,
          3,
          5,
          6,
          7,
          9,
          11,
          12,
          13,
          14,
          15,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          13,
          14,
          15,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          13,
          14,
          15,
          12,
          13,
          15,
          13,
          10,
          11,
          12,
          10,
          11,
          12,
          15,
          10,
          11,
          12,
          15,
          0,
          5,
          6,
          7,
          10,
          11,
          12,
          14,
          15,
          0,
          5,
          6,
          7,
          10,
          11,
          12,
          15,
          0,
          1,
          5,
          6,
          10,
          11,
          0,
          1,
          2,
          5,
          6,
          7,
          10,
          11,
          12,
          0,
          1,
          2,
          6,
          7,
          8,
          9,
          2,
          3,
          7,
          8,
          9,
          10,
          0,
          1,
          2,
          3,
          4,
          6,
          7,
          8,
          9,
          10,
          15,
          0,
          1,
          2,
          3,
          6,
          7,
          13,
          14,
          15,
          4,
          5,
          6,
          9,
          14,
          15,
          4,
          5,
          6,
          7,
          11,
          12,
          15,
          11,
          12,
          2,
          10,
          11,
          12,
          10,
          11,
          12,
          10,
          11,
          12,
          15,
          10,
          11,
          12,
          15,
          10,
          11,
          14,
          15,
          5,
          6,
          15,
          0,
          11,
          13,
          0,
          1,
          10,
          11,
          13,
          0,
          7,
          8,
          14,
          7,
          8,
          9,
          14,
          1,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          1,
          4,
          5,
          6,
          7,
          8,
          10,
          11,
          12,
          4,
          5,
          6,
          7,
          8,
          10,
          11,
          12,
          13,
          2,
          3,
          11,
          12,
          13,
          14,
          1,
          2,
          3,
          10,
          11,
          12,
          13,
          0,
          1,
          2,
          10,
          11,
          12,
          15,
          0,
          1,
          10,
          11,
          12,
          14,
          15,
          0,
          15,
          13,
          2,
          3,
          12,
          13,
          14,
          0,
          1,
          2,
          3,
          4,
          12,
          13,
          14,
          0,
          1,
          2,
          3,
          12,
          13,
          14,
          15,
          0,
          7,
          8,
          13,
          14,
          15,
          7,
          8,
          13,
          14,
          15,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          3,
          4,
          6,
          7,
          8,
          10,
          11,
          12,
          4,
          5,
          6,
          7,
          8,
          10,
          11,
          12,
          13,
          2,
          3,
          11,
          12,
          13,
          14,
          15,
          1,
          2,
          3,
          11,
          12,
          13,
          0,
          1,
          2,
          11,
          12,
          13,
          15,
          0,
          1,
          2,
          15,
          0,
          7,
          8,
          15,
          7,
          8,
          9,
          12,
          13,
          14,
          2,
          3,
          7,
          8,
          9,
          10,
          12,
          13,
          14,
          15,
          0,
          2,
          3,
          7,
          8,
          9,
          10,
          12,
          13,
          14,
          15,
          0,
          2,
          3,
          12,
          13,
          14,
          15,
          13,
          14,
          15,
          5,
          6,
          14,
          15,
          5,
          6,
          7,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          2,
          3,
          4,
          6,
          7,
          9,
          10,
          11,
          15,
          0,
          3,
          4,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          15,
          3,
          4,
          6,
          7,
          8,
          10,
          11,
          12,
          13,
          9,
          14,
          15,
          1,
          2,
          8,
          9,
          11,
          12,
          13,
          0,
          1,
          2,
          11,
          12,
          13,
          0,
          10,
          11,
          12,
          0,
          7,
          8,
          10,
          11,
          12,
          13,
          14,
          15,
          6,
          7,
          8,
          9,
          10,
          11,
          13,
          14,
          15,
          7,
          8,
          9,
          10,
          12,
          13,
          14,
          15,
          3,
          7,
          8,
          9,
          10,
          13,
          14,
          15,
          2,
          3,
          14,
          15,
          2,
          3,
          4,
          10,
          11,
          12,
          14,
          15,
          2,
          3,
          5,
          10,
          11,
          12,
          2,
          3,
          5,
          6,
          10,
          11,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          15,
          0,
          2,
          3,
          4,
          5,
          9,
          10,
          11,
          15,
          0,
          2,
          3,
          4,
          6,
          7,
          9,
          10,
          11,
          15,
          0,
          2,
          3,
          4,
          5,
          6,
          7,
          10,
          11,
          12,
          13,
          15
         ]
        },
        {
         "hovertemplate": "color=green<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "green",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "green",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          2,
          4,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15
         ],
         "y": [
          8,
          10,
          11,
          12,
          3,
          5,
          8,
          8,
          0,
          13,
          1,
          3,
          10,
          13,
          14,
          2,
          12,
          6,
          8,
          2,
          4,
          5,
          5,
          6,
          8,
          9,
          2,
          3,
          3,
          3,
          4,
          4,
          4,
          6,
          8,
          9,
          13,
          3,
          3,
          3,
          3,
          4,
          4,
          5,
          11,
          11,
          0,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          5,
          7,
          7,
          12,
          2,
          2,
          3,
          4,
          4,
          5,
          5,
          8,
          8,
          8,
          9,
          9,
          10,
          1,
          6,
          8,
          9,
          9,
          1,
          5,
          6,
          7,
          8,
          8,
          9,
          9,
          0,
          7,
          8,
          8,
          9,
          10
         ],
         "z": [
          0,
          14,
          14,
          6,
          6,
          0,
          0,
          4,
          10,
          15,
          10,
          12,
          15,
          10,
          3,
          6,
          9,
          14,
          3,
          5,
          7,
          8,
          14,
          4,
          6,
          14,
          3,
          6,
          7,
          8,
          6,
          7,
          8,
          4,
          4,
          5,
          9,
          5,
          6,
          7,
          8,
          5,
          8,
          8,
          4,
          13,
          14,
          5,
          6,
          7,
          5,
          6,
          7,
          8,
          4,
          7,
          12,
          14,
          0,
          1,
          6,
          5,
          6,
          5,
          6,
          2,
          3,
          4,
          3,
          4,
          10,
          0,
          4,
          4,
          3,
          4,
          0,
          10,
          4,
          4,
          4,
          5,
          3,
          4,
          8,
          4,
          4,
          5,
          5,
          6
         ]
        },
        {
         "hovertemplate": "color=red<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "red",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "red",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          1,
          2,
          2,
          2,
          2,
          3,
          3,
          4,
          4,
          4,
          4,
          5,
          5,
          6,
          6,
          6,
          7,
          7,
          8,
          8,
          9,
          9,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15
         ],
         "y": [
          15,
          12,
          14,
          14,
          15,
          10,
          11,
          7,
          11,
          14,
          15,
          13,
          15,
          3,
          13,
          14,
          4,
          12,
          6,
          6,
          0,
          15,
          1,
          6,
          7,
          8,
          2,
          3,
          3,
          7,
          7,
          7,
          7,
          8,
          8,
          2,
          6,
          11,
          2,
          5,
          6,
          6,
          7,
          8,
          12,
          3,
          3,
          4,
          6,
          6,
          6,
          6,
          7,
          7,
          8,
          10
         ],
         "z": [
          9,
          15,
          4,
          15,
          4,
          14,
          14,
          8,
          3,
          8,
          15,
          2,
          13,
          2,
          4,
          1,
          0,
          15,
          6,
          8,
          12,
          11,
          15,
          4,
          4,
          4,
          9,
          0,
          1,
          3,
          5,
          6,
          10,
          5,
          6,
          3,
          1,
          14,
          3,
          1,
          0,
          1,
          1,
          1,
          15,
          1,
          2,
          6,
          0,
          1,
          2,
          3,
          1,
          2,
          1,
          9
         ]
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "color"
         },
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0.0,
           1.0
          ],
          "y": [
           0.0,
           1.0
          ]
         },
         "xaxis": {
          "title": {
           "text": "x"
          }
         },
         "yaxis": {
          "title": {
           "text": "y"
          }
         },
         "zaxis": {
          "title": {
           "text": "z"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Train idx:126; ddg=-0.6"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"98cf9fd7-a91f-4747-8e33-6df3ea0fbfd9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"98cf9fd7-a91f-4747-8e33-6df3ea0fbfd9\")) {                    Plotly.newPlot(                        \"98cf9fd7-a91f-4747-8e33-6df3ea0fbfd9\",                        [{\"hovertemplate\":\"color=blue<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"blue\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"blue\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15],\"y\":[0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,6,6,6,7,7,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,13,13,13,13,14,14,14,14,15,15,15,15,15,0,0,0,1,1,1,1,2,2,2,2,2,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,6,7,7,7,7,7,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,0,1,1,2,2,2,2,3,3,3,3,3,3,4,4,4,4,4,4,4,5,5,5,5,5,6,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,12,12,12,12,12,13,13,13,13,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,1,2,2,2,3,3,3,3,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,10,10,10,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,1,1,2,2,2,2,3,3,3,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,9,9,9,9,10,10,10,10,11,11,12,12,13,13,13,13,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,10,10,10,10,10,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,14,14,14,14,14,15,15,15,15,15,15,15,15,1,1,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,7,7,7,8,8,8,8,8,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,15,15,15,15,15,15,15,0,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,5,5,5,5,5,6,6,6,6,6,7,7,7,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,0,0,0,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,11,11,11,11,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,0,0,0,2,2,2,3,3,3,3,3,3,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,11,11,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,0,0,0,0,1,1,3,3,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,11,11,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,0,0,0,1,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,9,9,9,9,10,10,10,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,15,15,15,15,15,15,15,0,0,1,1,1,1,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,6,6,6,7,7,7,8,8,8,8,8,9,9,9,9,10,10,10,10,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,4,4,5,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,10,10,10,10,10,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,0,0,0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,9,9,9,10,10,10,10,11,11,11,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,10,11,11,11,11,11,11,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15],\"z\":[8,9,10,11,12,8,9,10,11,8,9,10,12,5,6,10,11,12,13,14,0,5,6,7,8,10,11,12,13,14,5,6,7,8,10,11,12,13,14,6,7,8,0,12,10,11,12,13,3,4,5,6,7,10,11,12,0,3,4,5,6,7,10,11,12,15,0,1,2,3,4,5,6,7,10,11,15,0,1,2,3,4,5,13,14,2,3,4,14,4,5,10,11,4,5,9,10,11,9,10,11,8,9,10,11,8,9,10,11,12,10,11,12,13,0,5,6,7,11,12,13,14,5,6,7,13,4,0,4,7,13,14,5,6,7,8,11,0,1,2,4,5,6,7,10,11,12,14,15,0,1,2,3,5,6,7,11,13,14,15,0,1,2,3,5,6,7,13,14,15,0,1,2,3,13,14,2,3,5,6,7,10,4,5,6,7,9,10,11,12,15,4,5,6,10,11,12,15,11,10,11,9,10,11,12,0,9,10,11,12,13,0,3,8,9,10,11,12,0,3,4,8,9,3,4,5,12,13,14,3,4,5,6,7,13,14,15,1,4,5,6,7,8,13,14,0,1,2,4,5,6,7,14,15,0,1,2,3,4,5,6,13,14,15,0,1,2,13,14,15,0,1,2,13,14,5,6,7,11,2,5,6,10,11,12,0,1,2,3,5,6,7,8,9,10,11,12,14,15,11,9,10,11,0,9,10,11,0,2,3,4,8,9,10,2,3,4,5,7,8,9,10,12,13,3,4,5,7,8,9,12,13,14,3,4,5,12,13,14,15,3,4,5,6,7,12,13,14,0,1,2,3,4,5,0,1,2,0,1,2,6,7,8,9,10,11,12,0,1,2,3,5,6,7,8,9,10,11,12,14,15,10,11,9,10,11,12,9,10,11,3,4,7,8,9,10,0,1,2,3,4,5,7,8,9,12,13,0,1,2,3,4,5,7,8,9,12,13,14,15,2,3,4,5,11,12,13,14,2,3,4,5,11,12,13,2,3,4,13,3,4,5,15,4,15,3,15,9,10,13,14,0,1,6,7,9,10,13,14,15,0,1,2,6,7,8,9,10,11,11,14,4,5,10,11,13,14,15,4,5,8,9,10,11,13,14,15,0,7,8,9,10,11,12,0,1,2,4,5,7,8,9,10,11,0,1,2,4,5,7,8,9,12,13,15,0,2,3,11,12,13,15,0,2,3,4,11,12,13,14,3,4,11,12,13,14,2,3,4,12,13,2,3,4,7,8,12,13,14,15,0,1,2,3,4,7,8,13,14,15,0,1,3,4,9,13,14,15,9,10,13,14,15,0,5,6,7,8,9,10,14,4,14,3,4,5,13,14,15,3,4,5,6,8,9,10,11,12,13,14,15,0,5,7,8,9,10,11,12,13,14,0,1,7,8,9,10,11,12,13,0,1,9,10,11,15,0,13,15,0,11,12,13,14,2,3,4,10,11,12,13,2,3,4,5,8,10,11,12,13,14,1,2,3,4,6,7,8,9,12,13,14,15,0,1,2,3,4,6,7,8,12,13,14,15,0,1,2,3,6,7,13,14,15,2,3,4,6,11,13,14,2,3,5,6,7,11,12,4,3,4,5,2,3,4,5,13,14,1,2,3,4,5,11,12,13,14,15,1,2,3,10,11,12,13,14,15,9,10,11,12,13,9,10,11,12,13,3,8,13,2,7,8,9,10,11,12,1,2,3,4,5,8,9,10,11,12,13,14,2,3,4,5,9,10,11,12,13,14,15,3,4,6,7,8,9,10,12,13,14,0,1,2,3,6,7,8,14,0,1,2,3,6,7,8,9,12,14,2,3,4,8,9,10,11,12,13,2,3,6,8,9,10,11,12,4,14,15,3,4,5,1,2,3,4,13,14,15,0,1,2,3,4,13,14,15,0,1,2,3,11,12,13,14,15,0,1,7,11,12,13,15,0,2,3,7,10,12,13,14,2,3,4,6,7,8,9,10,11,12,13,14,0,1,2,3,4,7,8,9,10,11,12,0,1,2,3,4,5,7,8,9,10,11,12,2,3,4,5,9,10,11,13,14,15,9,10,13,14,6,7,8,11,12,2,5,6,7,8,9,11,12,13,3,5,6,7,8,9,10,11,12,13,14,0,4,5,6,7,8,9,10,11,12,13,14,15,13,14,15,0,1,2,0,1,2,3,14,15,0,1,2,11,12,14,15,0,1,6,7,8,11,12,13,0,2,3,6,7,8,10,11,12,13,14,1,2,3,4,6,7,8,9,10,11,13,0,1,2,3,5,6,7,8,9,10,11,0,1,2,3,6,7,8,9,10,3,13,2,3,5,6,7,8,11,12,13,14,5,6,7,8,11,12,13,14,15,4,5,6,7,8,9,10,11,12,13,14,15,0,4,5,6,7,8,9,10,12,13,14,15,12,13,14,15,13,15,0,1,0,1,6,7,10,11,12,0,5,6,7,10,11,12,15,0,5,6,7,8,10,11,12,0,1,5,6,7,8,10,11,12,0,1,2,3,5,6,7,8,9,10,11,0,1,2,3,5,6,7,2,3,2,3,4,5,6,7,12,13,14,15,2,3,5,6,7,9,11,12,13,14,15,4,5,6,7,8,9,10,13,14,15,4,5,6,7,8,9,10,13,14,15,12,13,15,13,10,11,12,10,11,12,15,10,11,12,15,0,5,6,7,10,11,12,14,15,0,5,6,7,10,11,12,15,0,1,5,6,10,11,0,1,2,5,6,7,10,11,12,0,1,2,6,7,8,9,2,3,7,8,9,10,0,1,2,3,4,6,7,8,9,10,15,0,1,2,3,6,7,13,14,15,4,5,6,9,14,15,4,5,6,7,11,12,15,11,12,2,10,11,12,10,11,12,10,11,12,15,10,11,12,15,10,11,14,15,5,6,15,0,11,13,0,1,10,11,13,0,7,8,14,7,8,9,14,1,3,4,5,6,7,8,9,10,0,1,2,3,4,5,6,7,8,9,10,0,1,2,3,4,5,6,7,8,1,4,5,6,7,8,10,11,12,4,5,6,7,8,10,11,12,13,2,3,11,12,13,14,1,2,3,10,11,12,13,0,1,2,10,11,12,15,0,1,10,11,12,14,15,0,15,13,2,3,12,13,14,0,1,2,3,4,12,13,14,0,1,2,3,12,13,14,15,0,7,8,13,14,15,7,8,13,14,15,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,0,1,2,3,4,5,6,7,8,3,4,6,7,8,10,11,12,4,5,6,7,8,10,11,12,13,2,3,11,12,13,14,15,1,2,3,11,12,13,0,1,2,11,12,13,15,0,1,2,15,0,7,8,15,7,8,9,12,13,14,2,3,7,8,9,10,12,13,14,15,0,2,3,7,8,9,10,12,13,14,15,0,2,3,12,13,14,15,13,14,15,5,6,14,15,5,6,7,2,3,4,5,6,7,8,2,3,4,6,7,9,10,11,15,0,3,4,6,7,8,9,10,11,12,15,3,4,6,7,8,10,11,12,13,9,14,15,1,2,8,9,11,12,13,0,1,2,11,12,13,0,10,11,12,0,7,8,10,11,12,13,14,15,6,7,8,9,10,11,13,14,15,7,8,9,10,12,13,14,15,3,7,8,9,10,13,14,15,2,3,14,15,2,3,4,10,11,12,14,15,2,3,5,10,11,12,2,3,5,6,10,11,0,1,2,3,4,5,6,15,0,2,3,4,5,9,10,11,15,0,2,3,4,6,7,9,10,11,15,0,2,3,4,5,6,7,10,11,12,13,15],\"type\":\"scatter3d\"},{\"hovertemplate\":\"color=green<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"green\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"green\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0,0,0,0,1,1,1,1,2,4,5,5,5,5,5,6,6,7,7,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,14,14,14,14,14,14,14,14,15,15,15,15,15,15],\"y\":[8,10,11,12,3,5,8,8,0,13,1,3,10,13,14,2,12,6,8,2,4,5,5,6,8,9,2,3,3,3,4,4,4,6,8,9,13,3,3,3,3,4,4,5,11,11,0,3,3,3,4,4,4,4,5,7,7,12,2,2,3,4,4,5,5,8,8,8,9,9,10,1,6,8,9,9,1,5,6,7,8,8,9,9,0,7,8,8,9,10],\"z\":[0,14,14,6,6,0,0,4,10,15,10,12,15,10,3,6,9,14,3,5,7,8,14,4,6,14,3,6,7,8,6,7,8,4,4,5,9,5,6,7,8,5,8,8,4,13,14,5,6,7,5,6,7,8,4,7,12,14,0,1,6,5,6,5,6,2,3,4,3,4,10,0,4,4,3,4,0,10,4,4,4,5,3,4,8,4,4,5,5,6],\"type\":\"scatter3d\"},{\"hovertemplate\":\"color=red<br>x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"red\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"red\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[1,2,2,2,2,3,3,4,4,4,4,5,5,6,6,6,7,7,8,8,9,9,11,11,11,11,12,12,12,12,12,12,12,12,12,13,13,13,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15],\"y\":[15,12,14,14,15,10,11,7,11,14,15,13,15,3,13,14,4,12,6,6,0,15,1,6,7,8,2,3,3,7,7,7,7,8,8,2,6,11,2,5,6,6,7,8,12,3,3,4,6,6,6,6,7,7,8,10],\"z\":[9,15,4,15,4,14,14,8,3,8,15,2,13,2,4,1,0,15,6,8,12,11,15,4,4,4,9,0,1,3,5,6,10,5,6,3,1,14,3,1,0,1,1,1,15,1,2,6,0,1,2,3,1,2,1,9],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"title\":{\"text\":\"color\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Train idx:126; ddg=-0.6\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('98cf9fd7-a91f-4747-8e33-6df3ea0fbfd9');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "def plot_voxels():\n",
    "    for i in [123, 124, 125, 126]:\n",
    "        df = pd.DataFrame([(x, y1, z) for x in range(16) for y1 in range(16) for z in range(16)], columns=['x', 'y', 'z'])\n",
    "        df['occupancy1'] = X[i, :, :, :, 6].flatten() > 0.9\n",
    "        df['occupancy2'] = X[i, :, :, :, 13].flatten() > 0.9\n",
    "        df.loc[df.occupancy1 | df.occupancy2, 'color'] = 'blue'\n",
    "        df.loc[~df.occupancy1 & df.occupancy2, 'color'] = 'red'\n",
    "        df.loc[df.occupancy1 & ~df.occupancy2, 'color'] = 'green'\n",
    "        ddg = df_train.ddg[i]\n",
    "        fig = px.scatter_3d(df.dropna(), x='x', y='y', z='z', color='color', title=f\"Train idx:{i}; ddg={ddg}\")\n",
    "        fig.show()\n",
    "\n",
    "plot_voxels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d738704",
   "metadata": {
    "papermill": {
     "duration": 0.065029,
     "end_time": "2022-10-13T07:47:58.685649",
     "exception": false,
     "start_time": "2022-10-13T07:47:58.620620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1166337",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T07:47:58.823452Z",
     "iopub.status.busy": "2022-10-13T07:47:58.823101Z",
     "iopub.status.idle": "2022-10-13T07:47:58.828845Z",
     "shell.execute_reply": "2022-10-13T07:47:58.828032Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.07494,
     "end_time": "2022-10-13T07:47:58.830946",
     "exception": false,
     "start_time": "2022-10-13T07:47:58.756006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdb_ids = df_train.pdb_id\n",
    "y = df_train.ddg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aded63b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T07:47:58.965458Z",
     "iopub.status.busy": "2022-10-13T07:47:58.965136Z",
     "iopub.status.idle": "2022-10-13T08:12:31.558307Z",
     "shell.execute_reply": "2022-10-13T08:12:31.557114Z"
    },
    "papermill": {
     "duration": 1472.662771,
     "end_time": "2022-10-13T08:12:31.560448",
     "exception": false,
     "start_time": "2022-10-13T07:47:58.897677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:   0%|          | 0/10 [00:00<?, ?it/s]2022-10-13 07:48:01.772454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-13 07:48:01.777969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-13 07:48:01.778733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-13 07:48:01.781727: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-13 07:48:01.782080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-13 07:48:01.782796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-13 07:48:01.783412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-13 07:48:04.198865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-13 07:48:04.199774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-13 07:48:04.200442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-13 07:48:04.201015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15381 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-10-13 07:48:05.874980: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 663355392 exceeds 10% of free system memory.\n",
      "2022-10-13 07:48:06.684249: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 663355392 exceeds 10% of free system memory.\n",
      "2022-10-13 07:48:07.262316: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 07:48:08.683268: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/362 [============================>.] - ETA: 0s - loss: 4.2530 - mae: 1.4277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 07:48:16.688901: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 73859072 exceeds 10% of free system memory.\n",
      "2022-10-13 07:48:16.789912: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 73859072 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/362 [==============================] - 10s 7ms/step - loss: 4.2491 - mae: 1.4270 - val_loss: 3.4612 - val_mae: 1.3516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.46119, saving model to models/model0.h5\n",
      "Epoch 2/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 4.0141 - mae: 1.3656 - val_loss: 3.3268 - val_mae: 1.3225\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.46119 to 3.32677, saving model to models/model0.h5\n",
      "Epoch 3/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.7408 - mae: 1.3154 - val_loss: 2.8789 - val_mae: 1.2233\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.32677 to 2.87890, saving model to models/model0.h5\n",
      "Epoch 4/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.4468 - mae: 1.2530 - val_loss: 3.2341 - val_mae: 1.2788\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.87890\n",
      "Epoch 5/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.3767 - mae: 1.2316 - val_loss: 2.5300 - val_mae: 1.1562\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.87890 to 2.52999, saving model to models/model0.h5\n",
      "Epoch 6/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.0891 - mae: 1.1828 - val_loss: 2.4753 - val_mae: 1.1492\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.52999 to 2.47531, saving model to models/model0.h5\n",
      "Epoch 7/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.1275 - mae: 1.2067 - val_loss: 2.6978 - val_mae: 1.1717\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.47531\n",
      "Epoch 8/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.9969 - mae: 1.1951 - val_loss: 2.8013 - val_mae: 1.2044\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.47531\n",
      "Epoch 9/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.7997 - mae: 1.1568 - val_loss: 2.7903 - val_mae: 1.2260\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.47531\n",
      "Epoch 10/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.7127 - mae: 1.1460 - val_loss: 2.6157 - val_mae: 1.1496\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.47531\n",
      "Epoch 11/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.4996 - mae: 1.0965 - val_loss: 2.6180 - val_mae: 1.1497\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.47531\n",
      "Epoch 12/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.6145 - mae: 1.1226 - val_loss: 2.8007 - val_mae: 1.1850\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.47531\n",
      "Epoch 13/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.6443 - mae: 1.1297 - val_loss: 2.5954 - val_mae: 1.1609\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.47531\n",
      "Epoch 14/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 2.4038 - mae: 1.0837 - val_loss: 2.2811 - val_mae: 1.0837\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.47531 to 2.28112, saving model to models/model0.h5\n",
      "Epoch 15/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3256 - mae: 1.0791 - val_loss: 2.4307 - val_mae: 1.1090\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.28112\n",
      "Epoch 16/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3358 - mae: 1.0739 - val_loss: 2.4751 - val_mae: 1.1475\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.28112\n",
      "Epoch 17/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.1835 - mae: 1.0407 - val_loss: 2.5258 - val_mae: 1.1302\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.28112\n",
      "Epoch 18/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.1673 - mae: 1.0323 - val_loss: 2.3491 - val_mae: 1.1061\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.28112\n",
      "Epoch 19/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.0136 - mae: 1.0128 - val_loss: 2.3849 - val_mae: 1.1273\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.28112\n",
      "Epoch 20/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9162 - mae: 0.9848 - val_loss: 2.4473 - val_mae: 1.1158\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.28112\n",
      "Epoch 21/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8879 - mae: 0.9814 - val_loss: 2.4160 - val_mae: 1.1043\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.28112\n",
      "Epoch 22/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.0041 - mae: 0.9774 - val_loss: 2.5078 - val_mae: 1.1190\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.28112\n",
      "Epoch 23/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.9752 - mae: 0.9849 - val_loss: 2.4283 - val_mae: 1.1206\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.28112\n",
      "Epoch 24/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8594 - mae: 0.9557 - val_loss: 2.4333 - val_mae: 1.1385\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.28112\n",
      "Epoch 25/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6974 - mae: 0.9063 - val_loss: 2.4026 - val_mae: 1.0942\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.28112\n",
      "Epoch 26/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4424 - mae: 0.8744 - val_loss: 2.3155 - val_mae: 1.0804\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.28112\n",
      "Epoch 27/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4626 - mae: 0.8661 - val_loss: 2.2888 - val_mae: 1.0863\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.28112\n",
      "Epoch 28/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.4274 - mae: 0.8405 - val_loss: 2.3000 - val_mae: 1.0699\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.28112\n",
      "Epoch 29/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.4644 - mae: 0.8339 - val_loss: 2.3654 - val_mae: 1.0865\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.28112\n",
      "Epoch 30/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.3161 - mae: 0.8208 - val_loss: 2.2319 - val_mae: 1.0637\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.28112 to 2.23192, saving model to models/model0.h5\n",
      "Epoch 31/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3127 - mae: 0.8296 - val_loss: 2.3784 - val_mae: 1.0936\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.23192\n",
      "Epoch 32/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3598 - mae: 0.8357 - val_loss: 2.3244 - val_mae: 1.0892\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.23192\n",
      "Epoch 33/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2925 - mae: 0.8221 - val_loss: 2.3115 - val_mae: 1.0810\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.23192\n",
      "Epoch 34/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2730 - mae: 0.8018 - val_loss: 2.2687 - val_mae: 1.0837\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.23192\n",
      "Epoch 35/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2291 - mae: 0.7999 - val_loss: 2.2311 - val_mae: 1.0831\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.23192 to 2.23110, saving model to models/model0.h5\n",
      "Epoch 36/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2632 - mae: 0.7977 - val_loss: 2.2658 - val_mae: 1.0700\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.23110\n",
      "Epoch 37/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2412 - mae: 0.7896 - val_loss: 2.2366 - val_mae: 1.0663\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.23110\n",
      "Epoch 38/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3247 - mae: 0.7996 - val_loss: 2.2626 - val_mae: 1.0861\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.23110\n",
      "Epoch 39/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2307 - mae: 0.7771 - val_loss: 2.2421 - val_mae: 1.0713\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.23110\n",
      "Epoch 40/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2970 - mae: 0.7848 - val_loss: 2.2543 - val_mae: 1.0749\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.23110\n",
      "Epoch 41/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1271 - mae: 0.7642 - val_loss: 2.2234 - val_mae: 1.0787\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.23110 to 2.22340, saving model to models/model0.h5\n",
      "Epoch 42/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1552 - mae: 0.7645 - val_loss: 2.2373 - val_mae: 1.0618\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.22340\n",
      "Epoch 43/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2174 - mae: 0.7756 - val_loss: 2.2541 - val_mae: 1.0716\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.22340\n",
      "Epoch 44/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1086 - mae: 0.7511 - val_loss: 2.2918 - val_mae: 1.0819\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.22340\n",
      "Epoch 45/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 1.1019 - mae: 0.7520 - val_loss: 2.2962 - val_mae: 1.1019\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.22340\n",
      "Epoch 46/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1432 - mae: 0.7620 - val_loss: 2.2791 - val_mae: 1.0724\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.22340\n",
      "Epoch 47/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1483 - mae: 0.7472 - val_loss: 2.2529 - val_mae: 1.0729\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.22340\n",
      "Epoch 48/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1670 - mae: 0.7439 - val_loss: 2.3054 - val_mae: 1.0950\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.22340\n",
      "Epoch 49/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1597 - mae: 0.7383 - val_loss: 2.3778 - val_mae: 1.0887\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.22340\n",
      "Epoch 50/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1449 - mae: 0.7431 - val_loss: 2.3047 - val_mae: 1.0781\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.22340\n",
      "Epoch 51/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1057 - mae: 0.7335 - val_loss: 2.3127 - val_mae: 1.0910\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.22340\n",
      "Epoch 52/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0459 - mae: 0.7238 - val_loss: 2.2877 - val_mae: 1.0752\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.22340\n",
      "Epoch 53/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0524 - mae: 0.7135 - val_loss: 2.2606 - val_mae: 1.0768\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.22340\n",
      "Epoch 54/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0490 - mae: 0.7053 - val_loss: 2.2490 - val_mae: 1.0750\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.22340\n",
      "Epoch 55/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9340 - mae: 0.6912 - val_loss: 2.2282 - val_mae: 1.0785\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.22340\n",
      "Epoch 56/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9772 - mae: 0.6928 - val_loss: 2.2133 - val_mae: 1.0786\n",
      "\n",
      "Epoch 00056: val_loss improved from 2.22340 to 2.21326, saving model to models/model0.h5\n",
      "Epoch 57/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0064 - mae: 0.7009 - val_loss: 2.2005 - val_mae: 1.0797\n",
      "\n",
      "Epoch 00057: val_loss improved from 2.21326 to 2.20050, saving model to models/model0.h5\n",
      "Epoch 58/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9581 - mae: 0.6886 - val_loss: 2.2133 - val_mae: 1.0733\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.20050\n",
      "Epoch 59/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0187 - mae: 0.6958 - val_loss: 2.2061 - val_mae: 1.0736\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.20050\n",
      "Epoch 60/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0649 - mae: 0.6922 - val_loss: 2.2328 - val_mae: 1.0673\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.20050\n",
      "Epoch 61/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9005 - mae: 0.6784 - val_loss: 2.2085 - val_mae: 1.0641\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.20050\n",
      "Epoch 62/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9422 - mae: 0.6857 - val_loss: 2.2032 - val_mae: 1.0734\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.20050\n",
      "Epoch 63/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9634 - mae: 0.6911 - val_loss: 2.2060 - val_mae: 1.0694\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.20050\n",
      "Epoch 64/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9143 - mae: 0.6784 - val_loss: 2.2221 - val_mae: 1.0748\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.20050\n",
      "Epoch 65/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9437 - mae: 0.6848 - val_loss: 2.1898 - val_mae: 1.0692\n",
      "\n",
      "Epoch 00065: val_loss improved from 2.20050 to 2.18981, saving model to models/model0.h5\n",
      "Epoch 66/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9528 - mae: 0.6756 - val_loss: 2.1958 - val_mae: 1.0700\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.18981\n",
      "Epoch 67/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0154 - mae: 0.6870 - val_loss: 2.1972 - val_mae: 1.0620\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.18981\n",
      "Epoch 68/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8466 - mae: 0.6672 - val_loss: 2.2023 - val_mae: 1.0636\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.18981\n",
      "Epoch 69/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8606 - mae: 0.6619 - val_loss: 2.2510 - val_mae: 1.0675\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.18981\n",
      "Epoch 70/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9885 - mae: 0.6781 - val_loss: 2.1960 - val_mae: 1.0671\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.18981\n",
      "Epoch 71/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.8195 - mae: 0.6455 - val_loss: 2.2079 - val_mae: 1.0711\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.18981\n",
      "Epoch 72/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8391 - mae: 0.6511 - val_loss: 2.3246 - val_mae: 1.0806\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.18981\n",
      "Epoch 73/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9638 - mae: 0.6767 - val_loss: 2.2136 - val_mae: 1.0707\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.18981\n",
      "Epoch 74/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9547 - mae: 0.6611 - val_loss: 2.2255 - val_mae: 1.0785\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.18981\n",
      "Epoch 75/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9712 - mae: 0.6720 - val_loss: 2.1908 - val_mae: 1.0695\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.18981\n",
      "Epoch 76/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 0.9637 - mae: 0.6500 - val_loss: 2.2019 - val_mae: 1.0672\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.18981\n",
      "Epoch 77/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9737 - mae: 0.6609 - val_loss: 2.1882 - val_mae: 1.0644\n",
      "\n",
      "Epoch 00077: val_loss improved from 2.18981 to 2.18824, saving model to models/model0.h5\n",
      "Epoch 78/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9089 - mae: 0.6527 - val_loss: 2.1958 - val_mae: 1.0666\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.18824\n",
      "Epoch 79/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8640 - mae: 0.6569 - val_loss: 2.2119 - val_mae: 1.0667\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.18824\n",
      "Epoch 80/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.7900 - mae: 0.6437 - val_loss: 2.2017 - val_mae: 1.0676\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.18824\n",
      "Epoch 81/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8582 - mae: 0.6437 - val_loss: 2.2008 - val_mae: 1.0661\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2.18824\n",
      "Epoch 82/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9056 - mae: 0.6534 - val_loss: 2.1957 - val_mae: 1.0656\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2.18824\n",
      "Epoch 83/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8715 - mae: 0.6525 - val_loss: 2.1915 - val_mae: 1.0693\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2.18824\n",
      "Epoch 84/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9282 - mae: 0.6589 - val_loss: 2.2069 - val_mae: 1.0687\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2.18824\n",
      "Epoch 85/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9219 - mae: 0.6586 - val_loss: 2.2087 - val_mae: 1.0698\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2.18824\n",
      "Epoch 86/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8774 - mae: 0.6515 - val_loss: 2.2137 - val_mae: 1.0702\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2.18824\n",
      "Epoch 87/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9470 - mae: 0.6678 - val_loss: 2.2455 - val_mae: 1.0715\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2.18824\n",
      "Epoch 88/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.8596 - mae: 0.6483 - val_loss: 2.2330 - val_mae: 1.0708\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2.18824\n",
      "Epoch 89/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8181 - mae: 0.6384 - val_loss: 2.2324 - val_mae: 1.0713\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2.18824\n",
      "Epoch 90/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8721 - mae: 0.6462 - val_loss: 2.2256 - val_mae: 1.0711\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2.18824\n",
      "Epoch 91/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9012 - mae: 0.6536 - val_loss: 2.2195 - val_mae: 1.0706\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2.18824\n",
      "Epoch 92/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.7871 - mae: 0.6223 - val_loss: 2.2183 - val_mae: 1.0714\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2.18824\n",
      "Epoch 93/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.8540 - mae: 0.6361 - val_loss: 2.2192 - val_mae: 1.0719\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2.18824\n",
      "Epoch 94/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.8450 - mae: 0.6292 - val_loss: 2.2202 - val_mae: 1.0707\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2.18824\n",
      "Epoch 95/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8432 - mae: 0.6490 - val_loss: 2.2150 - val_mae: 1.0708\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2.18824\n",
      "Epoch 96/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8149 - mae: 0.6514 - val_loss: 2.2188 - val_mae: 1.0721\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2.18824\n",
      "Epoch 97/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.8302 - mae: 0.6422 - val_loss: 2.2164 - val_mae: 1.0711\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2.18824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  10%|‚ñà         | 1/10 [04:29<40:28, 269.86s/it]2022-10-13 07:52:31.821520: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 663355392 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "362/362 [==============================] - 3s 6ms/step - loss: 4.2393 - mae: 1.4341 - val_loss: 4.2666 - val_mae: 1.3787\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.26660, saving model to models/model1.h5\n",
      "Epoch 2/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.8767 - mae: 1.3659 - val_loss: 4.1136 - val_mae: 1.3678\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.26660 to 4.11358, saving model to models/model1.h5\n",
      "Epoch 3/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.8242 - mae: 1.3457 - val_loss: 4.0047 - val_mae: 1.3305\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.11358 to 4.00468, saving model to models/model1.h5\n",
      "Epoch 4/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.5755 - mae: 1.2880 - val_loss: 3.9545 - val_mae: 1.3063\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.00468 to 3.95454, saving model to models/model1.h5\n",
      "Epoch 5/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.3987 - mae: 1.2485 - val_loss: 3.5987 - val_mae: 1.2472\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.95454 to 3.59875, saving model to models/model1.h5\n",
      "Epoch 6/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.2311 - mae: 1.2111 - val_loss: 3.5514 - val_mae: 1.2408\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.59875 to 3.55138, saving model to models/model1.h5\n",
      "Epoch 7/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.2112 - mae: 1.2062 - val_loss: 3.5429 - val_mae: 1.2357\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.55138 to 3.54292, saving model to models/model1.h5\n",
      "Epoch 8/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.0402 - mae: 1.1769 - val_loss: 3.4074 - val_mae: 1.1882\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.54292 to 3.40737, saving model to models/model1.h5\n",
      "Epoch 9/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.9366 - mae: 1.1617 - val_loss: 3.4516 - val_mae: 1.2520\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.40737\n",
      "Epoch 10/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.7902 - mae: 1.1445 - val_loss: 3.2851 - val_mae: 1.2055\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.40737 to 3.28514, saving model to models/model1.h5\n",
      "Epoch 11/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.6829 - mae: 1.1184 - val_loss: 3.5975 - val_mae: 1.2348\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.28514\n",
      "Epoch 12/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.5585 - mae: 1.1057 - val_loss: 3.3970 - val_mae: 1.2153\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.28514\n",
      "Epoch 13/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.4904 - mae: 1.0852 - val_loss: 3.1962 - val_mae: 1.1854\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.28514 to 3.19616, saving model to models/model1.h5\n",
      "Epoch 14/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.4112 - mae: 1.0808 - val_loss: 3.2825 - val_mae: 1.1939\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.19616\n",
      "Epoch 15/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3612 - mae: 1.0807 - val_loss: 3.1974 - val_mae: 1.1620\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.19616\n",
      "Epoch 16/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.2762 - mae: 1.0626 - val_loss: 3.1769 - val_mae: 1.1641\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.19616 to 3.17694, saving model to models/model1.h5\n",
      "Epoch 17/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.0972 - mae: 1.0183 - val_loss: 3.0664 - val_mae: 1.1529\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.17694 to 3.06641, saving model to models/model1.h5\n",
      "Epoch 18/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9484 - mae: 0.9874 - val_loss: 3.0747 - val_mae: 1.1807\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.06641\n",
      "Epoch 19/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.0860 - mae: 1.0029 - val_loss: 3.1039 - val_mae: 1.1725\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.06641\n",
      "Epoch 20/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.9701 - mae: 0.9886 - val_loss: 3.0932 - val_mae: 1.1883\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.06641\n",
      "Epoch 21/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9381 - mae: 0.9848 - val_loss: 2.8479 - val_mae: 1.1303\n",
      "\n",
      "Epoch 00021: val_loss improved from 3.06641 to 2.84791, saving model to models/model1.h5\n",
      "Epoch 22/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8398 - mae: 0.9716 - val_loss: 3.0233 - val_mae: 1.1838\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.84791\n",
      "Epoch 23/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8987 - mae: 0.9699 - val_loss: 2.9045 - val_mae: 1.1322\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.84791\n",
      "Epoch 24/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9283 - mae: 0.9758 - val_loss: 2.8687 - val_mae: 1.1226\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.84791\n",
      "Epoch 25/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.8949 - mae: 0.9716 - val_loss: 3.1773 - val_mae: 1.1842\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.84791\n",
      "Epoch 26/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.6754 - mae: 0.9345 - val_loss: 2.8771 - val_mae: 1.1009\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.84791\n",
      "Epoch 27/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7906 - mae: 0.9683 - val_loss: 2.7714 - val_mae: 1.1360\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.84791 to 2.77144, saving model to models/model1.h5\n",
      "Epoch 28/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7246 - mae: 0.9492 - val_loss: 3.0069 - val_mae: 1.1400\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.77144\n",
      "Epoch 29/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.7649 - mae: 0.9313 - val_loss: 2.8940 - val_mae: 1.1562\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.77144\n",
      "Epoch 30/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7970 - mae: 0.9444 - val_loss: 3.1135 - val_mae: 1.1543\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.77144\n",
      "Epoch 31/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.7176 - mae: 0.9232 - val_loss: 2.9145 - val_mae: 1.1263\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.77144\n",
      "Epoch 32/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7462 - mae: 0.9422 - val_loss: 2.7322 - val_mae: 1.1364\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.77144 to 2.73217, saving model to models/model1.h5\n",
      "Epoch 33/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4863 - mae: 0.8870 - val_loss: 3.1059 - val_mae: 1.2156\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.73217\n",
      "Epoch 34/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6798 - mae: 0.9147 - val_loss: 2.9526 - val_mae: 1.1390\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.73217\n",
      "Epoch 35/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5379 - mae: 0.8865 - val_loss: 2.9921 - val_mae: 1.1734\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.73217\n",
      "Epoch 36/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.5485 - mae: 0.8902 - val_loss: 3.0137 - val_mae: 1.1713\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.73217\n",
      "Epoch 37/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6531 - mae: 0.9184 - val_loss: 2.9271 - val_mae: 1.1600\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.73217\n",
      "Epoch 38/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5147 - mae: 0.8806 - val_loss: 2.9103 - val_mae: 1.1609\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.73217\n",
      "Epoch 39/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4497 - mae: 0.8734 - val_loss: 2.9235 - val_mae: 1.1727\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.73217\n",
      "Epoch 40/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4811 - mae: 0.8716 - val_loss: 2.8197 - val_mae: 1.1316\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.73217\n",
      "Epoch 41/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4603 - mae: 0.8715 - val_loss: 3.1351 - val_mae: 1.1936\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.73217\n",
      "Epoch 42/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 1.3380 - mae: 0.8424 - val_loss: 2.8495 - val_mae: 1.1479\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.73217\n",
      "Epoch 43/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3314 - mae: 0.8148 - val_loss: 2.9031 - val_mae: 1.1446\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.73217\n",
      "Epoch 44/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1598 - mae: 0.7824 - val_loss: 2.8347 - val_mae: 1.1343\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.73217\n",
      "Epoch 45/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2666 - mae: 0.7763 - val_loss: 2.8647 - val_mae: 1.1300\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.73217\n",
      "Epoch 46/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1558 - mae: 0.7627 - val_loss: 2.7823 - val_mae: 1.1154\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.73217\n",
      "Epoch 47/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1759 - mae: 0.7678 - val_loss: 2.9340 - val_mae: 1.1465\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.73217\n",
      "Epoch 48/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0575 - mae: 0.7379 - val_loss: 2.8215 - val_mae: 1.1242\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.73217\n",
      "Epoch 49/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0613 - mae: 0.7403 - val_loss: 2.7259 - val_mae: 1.0990\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.73217 to 2.72594, saving model to models/model1.h5\n",
      "Epoch 50/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0924 - mae: 0.7497 - val_loss: 2.6976 - val_mae: 1.0992\n",
      "\n",
      "Epoch 00050: val_loss improved from 2.72594 to 2.69755, saving model to models/model1.h5\n",
      "Epoch 51/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0261 - mae: 0.7260 - val_loss: 2.7231 - val_mae: 1.1181\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.69755\n",
      "Epoch 52/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1211 - mae: 0.7443 - val_loss: 2.7941 - val_mae: 1.1254\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.69755\n",
      "Epoch 53/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1476 - mae: 0.7575 - val_loss: 2.7573 - val_mae: 1.1291\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.69755\n",
      "Epoch 54/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1034 - mae: 0.7296 - val_loss: 2.7698 - val_mae: 1.1410\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.69755\n",
      "Epoch 55/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9870 - mae: 0.7120 - val_loss: 2.8106 - val_mae: 1.1172\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.69755\n",
      "Epoch 56/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0041 - mae: 0.7061 - val_loss: 2.7500 - val_mae: 1.1105\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.69755\n",
      "Epoch 57/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9289 - mae: 0.7050 - val_loss: 2.7301 - val_mae: 1.1226\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.69755\n",
      "Epoch 58/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 0.9470 - mae: 0.7019 - val_loss: 2.7551 - val_mae: 1.1184\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.69755\n",
      "Epoch 59/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9622 - mae: 0.7035 - val_loss: 2.7216 - val_mae: 1.1101\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.69755\n",
      "Epoch 60/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1089 - mae: 0.7207 - val_loss: 2.6777 - val_mae: 1.1128\n",
      "\n",
      "Epoch 00060: val_loss improved from 2.69755 to 2.67770, saving model to models/model1.h5\n",
      "Epoch 61/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9826 - mae: 0.6921 - val_loss: 2.7619 - val_mae: 1.1161\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.67770\n",
      "Epoch 62/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9946 - mae: 0.7109 - val_loss: 2.8601 - val_mae: 1.1311\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.67770\n",
      "Epoch 63/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0097 - mae: 0.7073 - val_loss: 2.7253 - val_mae: 1.1016\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.67770\n",
      "Epoch 64/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0166 - mae: 0.6991 - val_loss: 2.7067 - val_mae: 1.1175\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.67770\n",
      "Epoch 65/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9580 - mae: 0.6889 - val_loss: 2.7156 - val_mae: 1.1114\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.67770\n",
      "Epoch 66/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9654 - mae: 0.6774 - val_loss: 2.7155 - val_mae: 1.1101\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.67770\n",
      "Epoch 67/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9882 - mae: 0.6804 - val_loss: 2.7761 - val_mae: 1.1200\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.67770\n",
      "Epoch 68/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9157 - mae: 0.6821 - val_loss: 2.7924 - val_mae: 1.1213\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.67770\n",
      "Epoch 69/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9049 - mae: 0.6762 - val_loss: 2.7575 - val_mae: 1.1204\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.67770\n",
      "Epoch 70/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9719 - mae: 0.6750 - val_loss: 2.7499 - val_mae: 1.1255\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.67770\n",
      "Epoch 71/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0005 - mae: 0.6718 - val_loss: 2.7361 - val_mae: 1.1272\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.67770\n",
      "Epoch 72/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8371 - mae: 0.6482 - val_loss: 2.7364 - val_mae: 1.1206\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.67770\n",
      "Epoch 73/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 0.9243 - mae: 0.6626 - val_loss: 2.7525 - val_mae: 1.1185\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.67770\n",
      "Epoch 74/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.8060 - mae: 0.6516 - val_loss: 2.7345 - val_mae: 1.1159\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.67770\n",
      "Epoch 75/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8764 - mae: 0.6528 - val_loss: 2.7291 - val_mae: 1.1171\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.67770\n",
      "Epoch 76/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8740 - mae: 0.6516 - val_loss: 2.7055 - val_mae: 1.1155\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.67770\n",
      "Epoch 77/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9066 - mae: 0.6572 - val_loss: 2.7485 - val_mae: 1.1150\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.67770\n",
      "Epoch 78/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8806 - mae: 0.6578 - val_loss: 2.7404 - val_mae: 1.1047\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.67770\n",
      "Epoch 79/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9229 - mae: 0.6529 - val_loss: 2.7502 - val_mae: 1.1107\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.67770\n",
      "Epoch 80/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8325 - mae: 0.6438 - val_loss: 2.7475 - val_mae: 1.1159\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.67770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  20%|‚ñà‚ñà        | 2/10 [07:55<30:56, 232.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "362/362 [==============================] - 3s 6ms/step - loss: 4.2351 - mae: 1.4319 - val_loss: 3.9076 - val_mae: 1.3445\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.90760, saving model to models/model2.h5\n",
      "Epoch 2/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.9280 - mae: 1.3474 - val_loss: 3.8498 - val_mae: 1.3446\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.90760 to 3.84975, saving model to models/model2.h5\n",
      "Epoch 3/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.7134 - mae: 1.3066 - val_loss: 3.5255 - val_mae: 1.2390\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.84975 to 3.52555, saving model to models/model2.h5\n",
      "Epoch 4/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.5870 - mae: 1.2794 - val_loss: 3.5573 - val_mae: 1.2706\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.52555\n",
      "Epoch 5/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.3217 - mae: 1.2471 - val_loss: 3.4088 - val_mae: 1.2277\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.52555 to 3.40876, saving model to models/model2.h5\n",
      "Epoch 6/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.2312 - mae: 1.2273 - val_loss: 3.2782 - val_mae: 1.2139\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.40876 to 3.27821, saving model to models/model2.h5\n",
      "Epoch 7/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.9806 - mae: 1.2062 - val_loss: 3.3464 - val_mae: 1.2184\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.27821\n",
      "Epoch 8/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.6857 - mae: 1.1471 - val_loss: 3.2684 - val_mae: 1.2041\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.27821 to 3.26845, saving model to models/model2.h5\n",
      "Epoch 9/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.6988 - mae: 1.1356 - val_loss: 3.3401 - val_mae: 1.2120\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.26845\n",
      "Epoch 10/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.6375 - mae: 1.1222 - val_loss: 3.4558 - val_mae: 1.2292\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.26845\n",
      "Epoch 11/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3983 - mae: 1.0838 - val_loss: 3.1702 - val_mae: 1.1886\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.26845 to 3.17025, saving model to models/model2.h5\n",
      "Epoch 12/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.5742 - mae: 1.1045 - val_loss: 3.1360 - val_mae: 1.1814\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.17025 to 3.13595, saving model to models/model2.h5\n",
      "Epoch 13/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.5299 - mae: 1.0958 - val_loss: 3.1129 - val_mae: 1.1716\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.13595 to 3.11292, saving model to models/model2.h5\n",
      "Epoch 14/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.1984 - mae: 1.0498 - val_loss: 3.0930 - val_mae: 1.1659\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.11292 to 3.09301, saving model to models/model2.h5\n",
      "Epoch 15/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.2126 - mae: 1.0544 - val_loss: 3.2893 - val_mae: 1.1932\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.09301\n",
      "Epoch 16/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.1759 - mae: 1.0198 - val_loss: 3.2179 - val_mae: 1.1912\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.09301\n",
      "Epoch 17/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.9278 - mae: 0.9966 - val_loss: 3.1411 - val_mae: 1.1835\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.09301\n",
      "Epoch 18/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.0908 - mae: 1.0100 - val_loss: 3.2091 - val_mae: 1.1837\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.09301\n",
      "Epoch 19/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9577 - mae: 1.0088 - val_loss: 3.3013 - val_mae: 1.2085\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.09301\n",
      "Epoch 20/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.0412 - mae: 1.0086 - val_loss: 3.1591 - val_mae: 1.1676\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.09301\n",
      "Epoch 21/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.9030 - mae: 0.9712 - val_loss: 3.1675 - val_mae: 1.1944\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.09301\n",
      "Epoch 22/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9819 - mae: 0.9971 - val_loss: 3.0567 - val_mae: 1.1581\n",
      "\n",
      "Epoch 00022: val_loss improved from 3.09301 to 3.05670, saving model to models/model2.h5\n",
      "Epoch 23/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8584 - mae: 0.9637 - val_loss: 3.1828 - val_mae: 1.1822\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.05670\n",
      "Epoch 24/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6997 - mae: 0.9466 - val_loss: 3.0227 - val_mae: 1.1546\n",
      "\n",
      "Epoch 00024: val_loss improved from 3.05670 to 3.02265, saving model to models/model2.h5\n",
      "Epoch 25/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6101 - mae: 0.9209 - val_loss: 3.0715 - val_mae: 1.1551\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.02265\n",
      "Epoch 26/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.6516 - mae: 0.9377 - val_loss: 3.0857 - val_mae: 1.1582\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.02265\n",
      "Epoch 27/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.6994 - mae: 0.9195 - val_loss: 3.1964 - val_mae: 1.1752\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.02265\n",
      "Epoch 28/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5603 - mae: 0.8937 - val_loss: 3.1202 - val_mae: 1.1557\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.02265\n",
      "Epoch 29/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.5754 - mae: 0.9001 - val_loss: 3.1946 - val_mae: 1.1563\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.02265\n",
      "Epoch 30/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8571 - mae: 0.9495 - val_loss: 3.1085 - val_mae: 1.1476\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.02265\n",
      "Epoch 31/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4944 - mae: 0.8793 - val_loss: 3.1151 - val_mae: 1.1632\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.02265\n",
      "Epoch 32/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.5583 - mae: 0.8978 - val_loss: 3.2015 - val_mae: 1.1743\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.02265\n",
      "Epoch 33/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.5589 - mae: 0.8798 - val_loss: 3.1148 - val_mae: 1.1548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.02265\n",
      "Epoch 34/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5621 - mae: 0.8985 - val_loss: 3.1175 - val_mae: 1.1412\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.02265\n",
      "Epoch 35/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3024 - mae: 0.8167 - val_loss: 3.1003 - val_mae: 1.1453\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.02265\n",
      "Epoch 36/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3589 - mae: 0.8192 - val_loss: 3.0700 - val_mae: 1.1343\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.02265\n",
      "Epoch 37/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.3205 - mae: 0.8010 - val_loss: 3.1596 - val_mae: 1.1585\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.02265\n",
      "Epoch 38/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1538 - mae: 0.7763 - val_loss: 3.0994 - val_mae: 1.1482\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.02265\n",
      "Epoch 39/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2582 - mae: 0.7909 - val_loss: 3.2243 - val_mae: 1.1718\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.02265\n",
      "Epoch 40/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1273 - mae: 0.7642 - val_loss: 3.1948 - val_mae: 1.1671\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.02265\n",
      "Epoch 41/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1771 - mae: 0.7592 - val_loss: 3.1237 - val_mae: 1.1534\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.02265\n",
      "Epoch 42/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2860 - mae: 0.7869 - val_loss: 3.1408 - val_mae: 1.1569\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.02265\n",
      "Epoch 43/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1028 - mae: 0.7448 - val_loss: 3.1202 - val_mae: 1.1555\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.02265\n",
      "Epoch 44/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0286 - mae: 0.7246 - val_loss: 3.1465 - val_mae: 1.1520\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.02265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  30%|‚ñà‚ñà‚ñà       | 3/10 [10:21<22:29, 192.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "362/362 [==============================] - 3s 6ms/step - loss: 4.2915 - mae: 1.4412 - val_loss: 3.1744 - val_mae: 1.2752\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.17444, saving model to models/model3.h5\n",
      "Epoch 2/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 4.0375 - mae: 1.3737 - val_loss: 2.5186 - val_mae: 1.1518\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.17444 to 2.51859, saving model to models/model3.h5\n",
      "Epoch 3/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.8597 - mae: 1.3227 - val_loss: 2.6459 - val_mae: 1.1552\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.51859\n",
      "Epoch 4/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.6741 - mae: 1.3063 - val_loss: 2.4202 - val_mae: 1.0954\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.51859 to 2.42022, saving model to models/model3.h5\n",
      "Epoch 5/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.4209 - mae: 1.2549 - val_loss: 2.2992 - val_mae: 1.0804\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.42022 to 2.29922, saving model to models/model3.h5\n",
      "Epoch 6/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.3003 - mae: 1.2267 - val_loss: 2.2515 - val_mae: 1.0626\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.29922 to 2.25154, saving model to models/model3.h5\n",
      "Epoch 7/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.1619 - mae: 1.2130 - val_loss: 2.2873 - val_mae: 1.0783\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.25154\n",
      "Epoch 8/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.0256 - mae: 1.1936 - val_loss: 2.2713 - val_mae: 1.0661\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.25154\n",
      "Epoch 9/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.8922 - mae: 1.1688 - val_loss: 2.2897 - val_mae: 1.0777\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.25154\n",
      "Epoch 10/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.9710 - mae: 1.1631 - val_loss: 2.2164 - val_mae: 1.0789\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.25154 to 2.21641, saving model to models/model3.h5\n",
      "Epoch 11/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.7608 - mae: 1.1343 - val_loss: 2.4490 - val_mae: 1.1194\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.21641\n",
      "Epoch 12/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.7169 - mae: 1.1253 - val_loss: 2.3284 - val_mae: 1.1067\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.21641\n",
      "Epoch 13/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.6176 - mae: 1.1025 - val_loss: 2.2481 - val_mae: 1.0969\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.21641\n",
      "Epoch 14/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.4856 - mae: 1.0847 - val_loss: 2.2503 - val_mae: 1.1061\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.21641\n",
      "Epoch 15/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.3480 - mae: 1.0449 - val_loss: 2.3570 - val_mae: 1.1057\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.21641\n",
      "Epoch 16/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3201 - mae: 1.0565 - val_loss: 2.1804 - val_mae: 1.0544\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.21641 to 2.18036, saving model to models/model3.h5\n",
      "Epoch 17/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3096 - mae: 1.0499 - val_loss: 2.2572 - val_mae: 1.0931\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.18036\n",
      "Epoch 18/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.1936 - mae: 1.0402 - val_loss: 2.1948 - val_mae: 1.0730\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.18036\n",
      "Epoch 19/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.1089 - mae: 1.0133 - val_loss: 2.0819 - val_mae: 1.0505\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.18036 to 2.08194, saving model to models/model3.h5\n",
      "Epoch 20/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.1650 - mae: 1.0154 - val_loss: 2.0698 - val_mae: 1.0473\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.08194 to 2.06983, saving model to models/model3.h5\n",
      "Epoch 21/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.1194 - mae: 1.0152 - val_loss: 2.0155 - val_mae: 1.0282\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.06983 to 2.01547, saving model to models/model3.h5\n",
      "Epoch 22/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.0479 - mae: 0.9860 - val_loss: 2.0351 - val_mae: 1.0190\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.01547\n",
      "Epoch 23/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.9573 - mae: 0.9761 - val_loss: 2.2230 - val_mae: 1.0678\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.01547\n",
      "Epoch 24/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.0237 - mae: 0.9790 - val_loss: 2.0610 - val_mae: 1.0353\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.01547\n",
      "Epoch 25/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.9029 - mae: 0.9612 - val_loss: 1.9898 - val_mae: 1.0207\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.01547 to 1.98976, saving model to models/model3.h5\n",
      "Epoch 26/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.9021 - mae: 0.9509 - val_loss: 2.2378 - val_mae: 1.0778\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.98976\n",
      "Epoch 27/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9089 - mae: 0.9525 - val_loss: 2.0539 - val_mae: 1.0340\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.98976\n",
      "Epoch 28/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8946 - mae: 0.9527 - val_loss: 2.1379 - val_mae: 1.0716\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.98976\n",
      "Epoch 29/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.8588 - mae: 0.9340 - val_loss: 2.1192 - val_mae: 1.0557\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.98976\n",
      "Epoch 30/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.8510 - mae: 0.9320 - val_loss: 2.1123 - val_mae: 1.0373\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.98976\n",
      "Epoch 31/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.9485 - mae: 0.9506 - val_loss: 2.1224 - val_mae: 1.0620\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.98976\n",
      "Epoch 32/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8488 - mae: 0.9281 - val_loss: 2.0260 - val_mae: 1.0180\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.98976\n",
      "Epoch 33/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6719 - mae: 0.9007 - val_loss: 2.0175 - val_mae: 1.0382\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.98976\n",
      "Epoch 34/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6782 - mae: 0.8997 - val_loss: 1.9667 - val_mae: 1.0126\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.98976 to 1.96672, saving model to models/model3.h5\n",
      "Epoch 35/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9143 - mae: 0.9562 - val_loss: 2.0385 - val_mae: 1.0329\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.96672\n",
      "Epoch 36/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.6218 - mae: 0.8780 - val_loss: 2.0140 - val_mae: 1.0321\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.96672\n",
      "Epoch 37/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.6065 - mae: 0.8700 - val_loss: 2.0315 - val_mae: 1.0212\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.96672\n",
      "Epoch 38/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5653 - mae: 0.8723 - val_loss: 2.0114 - val_mae: 1.0282\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.96672\n",
      "Epoch 39/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.5845 - mae: 0.8774 - val_loss: 2.0539 - val_mae: 1.0321\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.96672\n",
      "Epoch 40/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4997 - mae: 0.8624 - val_loss: 2.0046 - val_mae: 1.0204\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.96672\n",
      "Epoch 41/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4674 - mae: 0.8595 - val_loss: 2.0366 - val_mae: 1.0343\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.96672\n",
      "Epoch 42/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.6230 - mae: 0.8747 - val_loss: 2.0476 - val_mae: 1.0192\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.96672\n",
      "Epoch 43/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5681 - mae: 0.8761 - val_loss: 2.1457 - val_mae: 1.0739\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.96672\n",
      "Epoch 44/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5392 - mae: 0.8485 - val_loss: 2.2676 - val_mae: 1.0809\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.96672\n",
      "Epoch 45/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.4018 - mae: 0.8278 - val_loss: 1.9429 - val_mae: 1.0098\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.96672 to 1.94293, saving model to models/model3.h5\n",
      "Epoch 46/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3041 - mae: 0.7969 - val_loss: 1.9251 - val_mae: 1.0032\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.94293 to 1.92508, saving model to models/model3.h5\n",
      "Epoch 47/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2448 - mae: 0.7725 - val_loss: 1.9797 - val_mae: 1.0186\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.92508\n",
      "Epoch 48/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2331 - mae: 0.7813 - val_loss: 2.0028 - val_mae: 1.0199\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.92508\n",
      "Epoch 49/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0996 - mae: 0.7518 - val_loss: 1.9889 - val_mae: 1.0187\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.92508\n",
      "Epoch 50/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1656 - mae: 0.7527 - val_loss: 1.9527 - val_mae: 1.0069\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.92508\n",
      "Epoch 51/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1446 - mae: 0.7599 - val_loss: 1.9629 - val_mae: 1.0106\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.92508\n",
      "Epoch 52/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1229 - mae: 0.7410 - val_loss: 1.9229 - val_mae: 1.0010\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.92508 to 1.92292, saving model to models/model3.h5\n",
      "Epoch 53/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1762 - mae: 0.7604 - val_loss: 1.9709 - val_mae: 1.0311\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.92292\n",
      "Epoch 54/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0822 - mae: 0.7392 - val_loss: 2.0047 - val_mae: 1.0273\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.92292\n",
      "Epoch 55/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1214 - mae: 0.7438 - val_loss: 1.9646 - val_mae: 1.0154\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.92292\n",
      "Epoch 56/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1143 - mae: 0.7364 - val_loss: 1.9810 - val_mae: 1.0215\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.92292\n",
      "Epoch 57/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1345 - mae: 0.7401 - val_loss: 1.9785 - val_mae: 1.0175\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.92292\n",
      "Epoch 58/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1000 - mae: 0.7257 - val_loss: 2.0380 - val_mae: 1.0456\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.92292\n",
      "Epoch 59/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1007 - mae: 0.7401 - val_loss: 2.0357 - val_mae: 1.0308\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.92292\n",
      "Epoch 60/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0514 - mae: 0.7116 - val_loss: 2.0060 - val_mae: 1.0258\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.92292\n",
      "Epoch 61/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1042 - mae: 0.7203 - val_loss: 2.0011 - val_mae: 1.0270\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.92292\n",
      "Epoch 62/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0465 - mae: 0.7130 - val_loss: 1.9436 - val_mae: 1.0050\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.92292\n",
      "Epoch 63/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9849 - mae: 0.6939 - val_loss: 1.9517 - val_mae: 1.0118\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.92292\n",
      "Epoch 64/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9680 - mae: 0.6822 - val_loss: 1.9675 - val_mae: 1.0153\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.92292\n",
      "Epoch 65/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0072 - mae: 0.6858 - val_loss: 1.9611 - val_mae: 1.0126\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.92292\n",
      "Epoch 66/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9021 - mae: 0.6850 - val_loss: 1.9520 - val_mae: 1.0070\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.92292\n",
      "Epoch 67/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9213 - mae: 0.6840 - val_loss: 1.9544 - val_mae: 1.0080\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.92292\n",
      "Epoch 68/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0549 - mae: 0.6976 - val_loss: 1.9675 - val_mae: 1.0145\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.92292\n",
      "Epoch 69/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9536 - mae: 0.6881 - val_loss: 1.9567 - val_mae: 1.0123\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.92292\n",
      "Epoch 70/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9578 - mae: 0.6838 - val_loss: 1.9621 - val_mae: 1.0125\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.92292\n",
      "Epoch 71/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0896 - mae: 0.6943 - val_loss: 1.9954 - val_mae: 1.0239\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.92292\n",
      "Epoch 72/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8857 - mae: 0.6646 - val_loss: 1.9424 - val_mae: 1.0108\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.92292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [12:52<17:37, 176.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 4.3451 - mae: 1.4373 - val_loss: 3.1690 - val_mae: 1.4054\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.16899, saving model to models/model4.h5\n",
      "Epoch 2/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 4.1127 - mae: 1.3948 - val_loss: 3.1429 - val_mae: 1.2965\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.16899 to 3.14288, saving model to models/model4.h5\n",
      "Epoch 3/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.8976 - mae: 1.3476 - val_loss: 3.2958 - val_mae: 1.2816\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.14288\n",
      "Epoch 4/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.8567 - mae: 1.3438 - val_loss: 2.8587 - val_mae: 1.2151\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.14288 to 2.85866, saving model to models/model4.h5\n",
      "Epoch 5/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.5283 - mae: 1.2727 - val_loss: 2.5175 - val_mae: 1.1257\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.85866 to 2.51755, saving model to models/model4.h5\n",
      "Epoch 6/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.4466 - mae: 1.2476 - val_loss: 2.7782 - val_mae: 1.1819\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.51755\n",
      "Epoch 7/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.2298 - mae: 1.2226 - val_loss: 2.5640 - val_mae: 1.1265\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.51755\n",
      "Epoch 8/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.1023 - mae: 1.1970 - val_loss: 2.3602 - val_mae: 1.1008\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.51755 to 2.36022, saving model to models/model4.h5\n",
      "Epoch 9/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.8591 - mae: 1.1540 - val_loss: 2.5296 - val_mae: 1.1210\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.36022\n",
      "Epoch 10/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.7097 - mae: 1.1403 - val_loss: 2.4863 - val_mae: 1.0969\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.36022\n",
      "Epoch 11/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 2.7956 - mae: 1.1453 - val_loss: 2.7308 - val_mae: 1.1982\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.36022\n",
      "Epoch 12/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.7060 - mae: 1.1289 - val_loss: 2.4554 - val_mae: 1.0898\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.36022\n",
      "Epoch 13/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.4468 - mae: 1.0780 - val_loss: 2.3854 - val_mae: 1.0851\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.36022\n",
      "Epoch 14/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3270 - mae: 1.0548 - val_loss: 2.7191 - val_mae: 1.1354\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.36022\n",
      "Epoch 15/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3780 - mae: 1.0660 - val_loss: 2.3522 - val_mae: 1.0885\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.36022 to 2.35225, saving model to models/model4.h5\n",
      "Epoch 16/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.2820 - mae: 1.0493 - val_loss: 2.6142 - val_mae: 1.1381\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.35225\n",
      "Epoch 17/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.1761 - mae: 1.0257 - val_loss: 2.3775 - val_mae: 1.0689\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.35225\n",
      "Epoch 18/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.0303 - mae: 1.0039 - val_loss: 2.7087 - val_mae: 1.1605\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.35225\n",
      "Epoch 19/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9826 - mae: 0.9832 - val_loss: 2.6298 - val_mae: 1.1259\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.35225\n",
      "Epoch 20/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.0345 - mae: 0.9898 - val_loss: 2.4329 - val_mae: 1.0928\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.35225\n",
      "Epoch 21/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8637 - mae: 0.9604 - val_loss: 2.3584 - val_mae: 1.0896\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.35225\n",
      "Epoch 22/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.8124 - mae: 0.9516 - val_loss: 2.3438 - val_mae: 1.1103\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.35225 to 2.34384, saving model to models/model4.h5\n",
      "Epoch 23/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8384 - mae: 0.9505 - val_loss: 2.2316 - val_mae: 1.0952\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.34384 to 2.23158, saving model to models/model4.h5\n",
      "Epoch 24/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8030 - mae: 0.9462 - val_loss: 2.2801 - val_mae: 1.0829\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.23158\n",
      "Epoch 25/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7737 - mae: 0.9657 - val_loss: 2.2603 - val_mae: 1.0579\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.23158\n",
      "Epoch 26/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6987 - mae: 0.9203 - val_loss: 2.5469 - val_mae: 1.1357\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.23158\n",
      "Epoch 27/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 1.8558 - mae: 0.9498 - val_loss: 2.2587 - val_mae: 1.0817\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.23158\n",
      "Epoch 28/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6919 - mae: 0.9319 - val_loss: 2.1543 - val_mae: 1.0509\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.23158 to 2.15434, saving model to models/model4.h5\n",
      "Epoch 29/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7006 - mae: 0.9229 - val_loss: 2.2344 - val_mae: 1.0718\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.15434\n",
      "Epoch 30/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5316 - mae: 0.8915 - val_loss: 2.1664 - val_mae: 1.0487\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.15434\n",
      "Epoch 31/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5470 - mae: 0.8828 - val_loss: 2.2813 - val_mae: 1.0750\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.15434\n",
      "Epoch 32/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 1.6355 - mae: 0.9093 - val_loss: 2.2982 - val_mae: 1.1070\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.15434\n",
      "Epoch 33/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.5211 - mae: 0.8951 - val_loss: 2.3268 - val_mae: 1.0879\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.15434\n",
      "Epoch 34/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5415 - mae: 0.8847 - val_loss: 2.3863 - val_mae: 1.0727\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.15434\n",
      "Epoch 35/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7890 - mae: 0.9328 - val_loss: 2.3524 - val_mae: 1.1161\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.15434\n",
      "Epoch 36/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5891 - mae: 0.8937 - val_loss: 2.2721 - val_mae: 1.1014\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.15434\n",
      "Epoch 37/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4065 - mae: 0.8580 - val_loss: 2.3901 - val_mae: 1.1121\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.15434\n",
      "Epoch 38/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.4030 - mae: 0.8584 - val_loss: 2.3490 - val_mae: 1.1285\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.15434\n",
      "Epoch 39/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3573 - mae: 0.8449 - val_loss: 2.2974 - val_mae: 1.0989\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.15434\n",
      "Epoch 40/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2994 - mae: 0.8207 - val_loss: 2.3492 - val_mae: 1.0984\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.15434\n",
      "Epoch 41/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2180 - mae: 0.7822 - val_loss: 2.1359 - val_mae: 1.0589\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.15434 to 2.13585, saving model to models/model4.h5\n",
      "Epoch 42/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2466 - mae: 0.7837 - val_loss: 2.1897 - val_mae: 1.0563\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.13585\n",
      "Epoch 43/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2138 - mae: 0.7746 - val_loss: 2.1457 - val_mae: 1.0585\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.13585\n",
      "Epoch 44/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1649 - mae: 0.7535 - val_loss: 2.1969 - val_mae: 1.0670\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.13585\n",
      "Epoch 45/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1411 - mae: 0.7634 - val_loss: 2.1772 - val_mae: 1.0535\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.13585\n",
      "Epoch 46/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1640 - mae: 0.7458 - val_loss: 2.1548 - val_mae: 1.0548\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.13585\n",
      "Epoch 47/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9817 - mae: 0.7301 - val_loss: 2.1601 - val_mae: 1.0488\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.13585\n",
      "Epoch 48/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 1.0722 - mae: 0.7386 - val_loss: 2.0869 - val_mae: 1.0365\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.13585 to 2.08691, saving model to models/model4.h5\n",
      "Epoch 49/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1164 - mae: 0.7315 - val_loss: 2.0752 - val_mae: 1.0302\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.08691 to 2.07518, saving model to models/model4.h5\n",
      "Epoch 50/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9777 - mae: 0.7213 - val_loss: 2.1464 - val_mae: 1.0520\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.07518\n",
      "Epoch 51/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9738 - mae: 0.7135 - val_loss: 2.1262 - val_mae: 1.0494\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.07518\n",
      "Epoch 52/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0771 - mae: 0.7328 - val_loss: 2.1756 - val_mae: 1.0564\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.07518\n",
      "Epoch 53/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9883 - mae: 0.7172 - val_loss: 2.1507 - val_mae: 1.0532\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.07518\n",
      "Epoch 54/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0436 - mae: 0.7208 - val_loss: 2.1522 - val_mae: 1.0473\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.07518\n",
      "Epoch 55/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0391 - mae: 0.7243 - val_loss: 2.1415 - val_mae: 1.0416\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.07518\n",
      "Epoch 56/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9813 - mae: 0.7018 - val_loss: 2.1158 - val_mae: 1.0321\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.07518\n",
      "Epoch 57/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9928 - mae: 0.7196 - val_loss: 2.1917 - val_mae: 1.0594\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.07518\n",
      "Epoch 58/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 0.9802 - mae: 0.7002 - val_loss: 2.1523 - val_mae: 1.0493\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.07518\n",
      "Epoch 59/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9934 - mae: 0.6967 - val_loss: 2.2060 - val_mae: 1.0648\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.07518\n",
      "Epoch 60/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9839 - mae: 0.7005 - val_loss: 2.1908 - val_mae: 1.0591\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.07518\n",
      "Epoch 61/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9375 - mae: 0.6814 - val_loss: 2.1620 - val_mae: 1.0514\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.07518\n",
      "Epoch 62/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9596 - mae: 0.6737 - val_loss: 2.1644 - val_mae: 1.0507\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.07518\n",
      "Epoch 63/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9513 - mae: 0.6842 - val_loss: 2.1624 - val_mae: 1.0450\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.07518\n",
      "Epoch 64/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9767 - mae: 0.6848 - val_loss: 2.2145 - val_mae: 1.0560\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.07518\n",
      "Epoch 65/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9417 - mae: 0.6645 - val_loss: 2.1674 - val_mae: 1.0414\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.07518\n",
      "Epoch 66/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9573 - mae: 0.6707 - val_loss: 2.2070 - val_mae: 1.0520\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.07518\n",
      "Epoch 67/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8581 - mae: 0.6526 - val_loss: 2.1261 - val_mae: 1.0351\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.07518\n",
      "Epoch 68/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8428 - mae: 0.6551 - val_loss: 2.1318 - val_mae: 1.0377\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.07518\n",
      "Epoch 69/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.8849 - mae: 0.6721 - val_loss: 2.1526 - val_mae: 1.0428\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.07518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [15:17<13:44, 164.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "362/362 [==============================] - 3s 6ms/step - loss: 4.0713 - mae: 1.3995 - val_loss: 4.7294 - val_mae: 1.4386\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.72942, saving model to models/model5.h5\n",
      "Epoch 2/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.7416 - mae: 1.3373 - val_loss: 4.5831 - val_mae: 1.3827\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.72942 to 4.58315, saving model to models/model5.h5\n",
      "Epoch 3/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.4926 - mae: 1.2862 - val_loss: 4.4615 - val_mae: 1.3253\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.58315 to 4.46153, saving model to models/model5.h5\n",
      "Epoch 4/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.3224 - mae: 1.2423 - val_loss: 4.4712 - val_mae: 1.3284\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.46153\n",
      "Epoch 5/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.2281 - mae: 1.2309 - val_loss: 4.6517 - val_mae: 1.3902\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.46153\n",
      "Epoch 6/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.1866 - mae: 1.2348 - val_loss: 4.3723 - val_mae: 1.3087\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.46153 to 4.37230, saving model to models/model5.h5\n",
      "Epoch 7/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.1023 - mae: 1.2015 - val_loss: 4.3669 - val_mae: 1.3131\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.37230 to 4.36695, saving model to models/model5.h5\n",
      "Epoch 8/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.8684 - mae: 1.1792 - val_loss: 4.3148 - val_mae: 1.2736\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.36695 to 4.31485, saving model to models/model5.h5\n",
      "Epoch 9/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.6795 - mae: 1.1458 - val_loss: 4.2510 - val_mae: 1.2880\n",
      "\n",
      "Epoch 00009: val_loss improved from 4.31485 to 4.25105, saving model to models/model5.h5\n",
      "Epoch 10/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.6427 - mae: 1.1386 - val_loss: 4.1671 - val_mae: 1.2863\n",
      "\n",
      "Epoch 00010: val_loss improved from 4.25105 to 4.16712, saving model to models/model5.h5\n",
      "Epoch 11/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.5770 - mae: 1.1230 - val_loss: 4.1127 - val_mae: 1.2666\n",
      "\n",
      "Epoch 00011: val_loss improved from 4.16712 to 4.11267, saving model to models/model5.h5\n",
      "Epoch 12/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.4221 - mae: 1.0894 - val_loss: 4.3253 - val_mae: 1.2946\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.11267\n",
      "Epoch 13/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.4817 - mae: 1.0919 - val_loss: 4.2189 - val_mae: 1.2965\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.11267\n",
      "Epoch 14/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3406 - mae: 1.0771 - val_loss: 4.5194 - val_mae: 1.3473\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.11267\n",
      "Epoch 15/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.2656 - mae: 1.0644 - val_loss: 4.6756 - val_mae: 1.3962\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.11267\n",
      "Epoch 16/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.1919 - mae: 1.0508 - val_loss: 4.1437 - val_mae: 1.2683\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.11267\n",
      "Epoch 17/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.3278 - mae: 1.0636 - val_loss: 4.1206 - val_mae: 1.2620\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.11267\n",
      "Epoch 18/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.1392 - mae: 1.0441 - val_loss: 4.1270 - val_mae: 1.2531\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.11267\n",
      "Epoch 19/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.1383 - mae: 1.0370 - val_loss: 4.1668 - val_mae: 1.2927\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.11267\n",
      "Epoch 20/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.0618 - mae: 1.0148 - val_loss: 3.9235 - val_mae: 1.2218\n",
      "\n",
      "Epoch 00020: val_loss improved from 4.11267 to 3.92351, saving model to models/model5.h5\n",
      "Epoch 21/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9014 - mae: 0.9721 - val_loss: 3.9644 - val_mae: 1.2416\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.92351\n",
      "Epoch 22/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8721 - mae: 0.9735 - val_loss: 4.0075 - val_mae: 1.2545\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.92351\n",
      "Epoch 23/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.9144 - mae: 0.9803 - val_loss: 3.8946 - val_mae: 1.2386\n",
      "\n",
      "Epoch 00023: val_loss improved from 3.92351 to 3.89456, saving model to models/model5.h5\n",
      "Epoch 24/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.7804 - mae: 0.9584 - val_loss: 3.9449 - val_mae: 1.2477\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.89456\n",
      "Epoch 25/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9352 - mae: 0.9604 - val_loss: 4.2975 - val_mae: 1.3154\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.89456\n",
      "Epoch 26/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.7693 - mae: 0.9519 - val_loss: 3.9777 - val_mae: 1.2170\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.89456\n",
      "Epoch 27/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7304 - mae: 0.9417 - val_loss: 3.9915 - val_mae: 1.2303\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.89456\n",
      "Epoch 28/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7365 - mae: 0.9290 - val_loss: 3.8679 - val_mae: 1.2103\n",
      "\n",
      "Epoch 00028: val_loss improved from 3.89456 to 3.86788, saving model to models/model5.h5\n",
      "Epoch 29/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6431 - mae: 0.9183 - val_loss: 3.9334 - val_mae: 1.2221\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.86788\n",
      "Epoch 30/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8733 - mae: 0.9462 - val_loss: 3.9444 - val_mae: 1.2114\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.86788\n",
      "Epoch 31/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.5771 - mae: 0.9017 - val_loss: 4.0995 - val_mae: 1.2610\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.86788\n",
      "Epoch 32/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6080 - mae: 0.9083 - val_loss: 3.8353 - val_mae: 1.2141\n",
      "\n",
      "Epoch 00032: val_loss improved from 3.86788 to 3.83535, saving model to models/model5.h5\n",
      "Epoch 33/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.5946 - mae: 0.9018 - val_loss: 4.0454 - val_mae: 1.2464\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.83535\n",
      "Epoch 34/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5618 - mae: 0.8900 - val_loss: 4.0320 - val_mae: 1.2597\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.83535\n",
      "Epoch 35/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4970 - mae: 0.8822 - val_loss: 3.8458 - val_mae: 1.2338\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.83535\n",
      "Epoch 36/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5567 - mae: 0.8857 - val_loss: 4.1511 - val_mae: 1.2553\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.83535\n",
      "Epoch 37/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.4615 - mae: 0.8550 - val_loss: 4.0630 - val_mae: 1.2192\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.83535\n",
      "Epoch 38/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.4701 - mae: 0.8763 - val_loss: 4.1926 - val_mae: 1.2597\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.83535\n",
      "Epoch 39/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.4567 - mae: 0.8699 - val_loss: 4.1714 - val_mae: 1.2456\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.83535\n",
      "Epoch 40/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3636 - mae: 0.8456 - val_loss: 4.0257 - val_mae: 1.2780\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.83535\n",
      "Epoch 41/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4505 - mae: 0.8797 - val_loss: 3.9453 - val_mae: 1.2281\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.83535\n",
      "Epoch 42/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.4152 - mae: 0.8539 - val_loss: 3.8631 - val_mae: 1.2247\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.83535\n",
      "Epoch 43/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2579 - mae: 0.8134 - val_loss: 3.8887 - val_mae: 1.2217\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.83535\n",
      "Epoch 44/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1441 - mae: 0.7800 - val_loss: 3.9319 - val_mae: 1.2118\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.83535\n",
      "Epoch 45/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1981 - mae: 0.7623 - val_loss: 3.8866 - val_mae: 1.2222\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.83535\n",
      "Epoch 46/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2217 - mae: 0.7889 - val_loss: 3.8956 - val_mae: 1.2152\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.83535\n",
      "Epoch 47/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1591 - mae: 0.7673 - val_loss: 3.8761 - val_mae: 1.2258\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.83535\n",
      "Epoch 48/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2209 - mae: 0.7853 - val_loss: 3.9613 - val_mae: 1.2310\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.83535\n",
      "Epoch 49/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2239 - mae: 0.7687 - val_loss: 3.9246 - val_mae: 1.2412\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.83535\n",
      "Epoch 50/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0479 - mae: 0.7302 - val_loss: 3.9195 - val_mae: 1.2288\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.83535\n",
      "Epoch 51/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0808 - mae: 0.7419 - val_loss: 3.8896 - val_mae: 1.2334\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.83535\n",
      "Epoch 52/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1847 - mae: 0.7557 - val_loss: 3.9070 - val_mae: 1.2309\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.83535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [17:07<09:45, 146.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 4.4251 - mae: 1.4444 - val_loss: 2.8672 - val_mae: 1.3058\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.86725, saving model to models/model6.h5\n",
      "Epoch 2/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 4.1579 - mae: 1.3923 - val_loss: 2.8222 - val_mae: 1.2273\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.86725 to 2.82219, saving model to models/model6.h5\n",
      "Epoch 3/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9344 - mae: 1.3501 - val_loss: 2.6278 - val_mae: 1.1898\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.82219 to 2.62779, saving model to models/model6.h5\n",
      "Epoch 4/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.7016 - mae: 1.3016 - val_loss: 2.4158 - val_mae: 1.1766\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.62779 to 2.41575, saving model to models/model6.h5\n",
      "Epoch 5/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.5244 - mae: 1.2674 - val_loss: 2.7450 - val_mae: 1.2834\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.41575\n",
      "Epoch 6/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.3804 - mae: 1.2494 - val_loss: 2.6850 - val_mae: 1.1867\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.41575\n",
      "Epoch 7/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.3203 - mae: 1.2266 - val_loss: 2.5129 - val_mae: 1.1786\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.41575\n",
      "Epoch 8/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.2275 - mae: 1.2283 - val_loss: 2.5463 - val_mae: 1.1540\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.41575\n",
      "Epoch 9/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.1007 - mae: 1.1949 - val_loss: 2.6051 - val_mae: 1.2000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.41575\n",
      "Epoch 10/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 2.9604 - mae: 1.1776 - val_loss: 2.4705 - val_mae: 1.1535\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.41575\n",
      "Epoch 11/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.9080 - mae: 1.1636 - val_loss: 2.5270 - val_mae: 1.1980\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.41575\n",
      "Epoch 12/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.0685 - mae: 1.2036 - val_loss: 2.4767 - val_mae: 1.1702\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.41575\n",
      "Epoch 13/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.6333 - mae: 1.1304 - val_loss: 2.6950 - val_mae: 1.2198\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.41575\n",
      "Epoch 14/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.6420 - mae: 1.1162 - val_loss: 2.3333 - val_mae: 1.1477\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.41575 to 2.33331, saving model to models/model6.h5\n",
      "Epoch 15/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.5545 - mae: 1.0960 - val_loss: 2.2753 - val_mae: 1.1276\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.33331 to 2.27529, saving model to models/model6.h5\n",
      "Epoch 16/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.4372 - mae: 1.0909 - val_loss: 2.4832 - val_mae: 1.1644\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.27529\n",
      "Epoch 17/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.5835 - mae: 1.0931 - val_loss: 2.3178 - val_mae: 1.1282\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.27529\n",
      "Epoch 18/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.4540 - mae: 1.0755 - val_loss: 2.3575 - val_mae: 1.1426\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.27529\n",
      "Epoch 19/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3422 - mae: 1.0561 - val_loss: 2.4402 - val_mae: 1.1446\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.27529\n",
      "Epoch 20/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.2678 - mae: 1.0387 - val_loss: 2.3666 - val_mae: 1.1469\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.27529\n",
      "Epoch 21/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.3712 - mae: 1.0680 - val_loss: 2.4292 - val_mae: 1.1356\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.27529\n",
      "Epoch 22/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.0583 - mae: 1.0272 - val_loss: 2.2828 - val_mae: 1.1289\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.27529\n",
      "Epoch 23/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.1235 - mae: 1.0213 - val_loss: 2.4657 - val_mae: 1.1645\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.27529\n",
      "Epoch 24/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.0407 - mae: 1.0058 - val_loss: 2.3945 - val_mae: 1.1314\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.27529\n",
      "Epoch 25/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 2.0363 - mae: 0.9902 - val_loss: 2.4957 - val_mae: 1.1634\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.27529\n",
      "Epoch 26/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.8202 - mae: 0.9447 - val_loss: 2.2790 - val_mae: 1.1104\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.27529\n",
      "Epoch 27/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8661 - mae: 0.9487 - val_loss: 2.2669 - val_mae: 1.1142\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.27529 to 2.26688, saving model to models/model6.h5\n",
      "Epoch 28/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6038 - mae: 0.8990 - val_loss: 2.2574 - val_mae: 1.1004\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.26688 to 2.25743, saving model to models/model6.h5\n",
      "Epoch 29/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6697 - mae: 0.8988 - val_loss: 2.2692 - val_mae: 1.1014\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.25743\n",
      "Epoch 30/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5363 - mae: 0.8871 - val_loss: 2.2936 - val_mae: 1.1185\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.25743\n",
      "Epoch 31/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 1.5346 - mae: 0.8518 - val_loss: 2.2811 - val_mae: 1.1106\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.25743\n",
      "Epoch 32/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.5592 - mae: 0.8872 - val_loss: 2.2683 - val_mae: 1.1125\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.25743\n",
      "Epoch 33/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5750 - mae: 0.8821 - val_loss: 2.1990 - val_mae: 1.1041\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.25743 to 2.19900, saving model to models/model6.h5\n",
      "Epoch 34/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5328 - mae: 0.8664 - val_loss: 2.2520 - val_mae: 1.0933\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.19900\n",
      "Epoch 35/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3672 - mae: 0.8472 - val_loss: 2.2616 - val_mae: 1.1005\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.19900\n",
      "Epoch 36/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.4417 - mae: 0.8492 - val_loss: 2.2133 - val_mae: 1.0912\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.19900\n",
      "Epoch 37/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4537 - mae: 0.8435 - val_loss: 2.2554 - val_mae: 1.1064\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.19900\n",
      "Epoch 38/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3382 - mae: 0.8475 - val_loss: 2.2415 - val_mae: 1.1070\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.19900\n",
      "Epoch 39/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3049 - mae: 0.8296 - val_loss: 2.3422 - val_mae: 1.1225\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.19900\n",
      "Epoch 40/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.3984 - mae: 0.8307 - val_loss: 2.3319 - val_mae: 1.1105\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.19900\n",
      "Epoch 41/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 1.3583 - mae: 0.8260 - val_loss: 2.2625 - val_mae: 1.0990\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.19900\n",
      "Epoch 42/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2711 - mae: 0.8066 - val_loss: 2.2789 - val_mae: 1.1022\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.19900\n",
      "Epoch 43/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2806 - mae: 0.8150 - val_loss: 2.2563 - val_mae: 1.1130\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.19900\n",
      "Epoch 44/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2412 - mae: 0.7848 - val_loss: 2.2382 - val_mae: 1.1048\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.19900\n",
      "Epoch 45/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1963 - mae: 0.7836 - val_loss: 2.2564 - val_mae: 1.1049\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.19900\n",
      "Epoch 46/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1950 - mae: 0.7795 - val_loss: 2.2379 - val_mae: 1.0972\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.19900\n",
      "Epoch 47/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 1.1693 - mae: 0.7648 - val_loss: 2.2497 - val_mae: 1.0929\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.19900\n",
      "Epoch 48/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1308 - mae: 0.7687 - val_loss: 2.2781 - val_mae: 1.0976\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.19900\n",
      "Epoch 49/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1595 - mae: 0.7604 - val_loss: 2.2590 - val_mae: 1.0935\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.19900\n",
      "Epoch 50/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0988 - mae: 0.7631 - val_loss: 2.2580 - val_mae: 1.0967\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.19900\n",
      "Epoch 51/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1327 - mae: 0.7662 - val_loss: 2.2581 - val_mae: 1.0995\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.19900\n",
      "Epoch 52/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2006 - mae: 0.7824 - val_loss: 2.2588 - val_mae: 1.0981\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.19900\n",
      "Epoch 53/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1225 - mae: 0.7677 - val_loss: 2.2735 - val_mae: 1.0987\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.19900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [19:00<06:46, 135.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "362/362 [==============================] - 4s 7ms/step - loss: 4.1400 - mae: 1.4225 - val_loss: 5.0308 - val_mae: 1.4793\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.03075, saving model to models/model7.h5\n",
      "Epoch 2/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.9243 - mae: 1.3711 - val_loss: 4.8499 - val_mae: 1.4257\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.03075 to 4.84993, saving model to models/model7.h5\n",
      "Epoch 3/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.7396 - mae: 1.3278 - val_loss: 4.1171 - val_mae: 1.2813\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.84993 to 4.11713, saving model to models/model7.h5\n",
      "Epoch 4/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 4.0624 - mae: 1.3873 - val_loss: 4.9988 - val_mae: 1.4960\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.11713\n",
      "Epoch 5/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9785 - mae: 1.4059 - val_loss: 4.9763 - val_mae: 1.4951\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.11713\n",
      "Epoch 6/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9370 - mae: 1.4021 - val_loss: 4.9568 - val_mae: 1.4949\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.11713\n",
      "Epoch 7/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.9335 - mae: 1.4096 - val_loss: 4.9554 - val_mae: 1.4949\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.11713\n",
      "Epoch 8/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 3.9303 - mae: 1.4034 - val_loss: 4.9542 - val_mae: 1.4949\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.11713\n",
      "Epoch 9/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9344 - mae: 1.4074 - val_loss: 4.9496 - val_mae: 1.4957\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.11713\n",
      "Epoch 10/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9268 - mae: 1.4063 - val_loss: 4.9505 - val_mae: 1.4955\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.11713\n",
      "Epoch 11/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9264 - mae: 1.4082 - val_loss: 4.9532 - val_mae: 1.4950\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.11713\n",
      "Epoch 12/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9131 - mae: 1.4038 - val_loss: 4.9539 - val_mae: 1.4950\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.11713\n",
      "Epoch 13/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.9251 - mae: 1.4089 - val_loss: 4.9580 - val_mae: 1.4949\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.11713\n",
      "Epoch 14/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9234 - mae: 1.4072 - val_loss: 4.9555 - val_mae: 1.4949\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.11713\n",
      "Epoch 15/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9309 - mae: 1.4099 - val_loss: 4.9557 - val_mae: 1.4949\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.11713\n",
      "Epoch 16/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.9115 - mae: 1.4059 - val_loss: 4.9537 - val_mae: 1.4950\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.11713\n",
      "Epoch 17/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9106 - mae: 1.4057 - val_loss: 4.9531 - val_mae: 1.4950\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.11713\n",
      "Epoch 18/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.9063 - mae: 1.4026 - val_loss: 4.9510 - val_mae: 1.4954\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.11713\n",
      "Epoch 19/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.9295 - mae: 1.4110 - val_loss: 4.9548 - val_mae: 1.4949\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.11713\n",
      "Epoch 20/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9148 - mae: 1.4047 - val_loss: 4.9535 - val_mae: 1.4950\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.11713\n",
      "Epoch 21/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9049 - mae: 1.4046 - val_loss: 4.9531 - val_mae: 1.4950\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.11713\n",
      "Epoch 22/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.9064 - mae: 1.4065 - val_loss: 4.9515 - val_mae: 1.4953\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.11713\n",
      "Epoch 23/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.8983 - mae: 1.4062 - val_loss: 4.9515 - val_mae: 1.4953\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.11713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [20:26<03:59, 119.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "362/362 [==============================] - 3s 6ms/step - loss: 4.0043 - mae: 1.3988 - val_loss: 5.4609 - val_mae: 1.4422\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.46093, saving model to models/model8.h5\n",
      "Epoch 2/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.6809 - mae: 1.3264 - val_loss: 4.6305 - val_mae: 1.3136\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.46093 to 4.63052, saving model to models/model8.h5\n",
      "Epoch 3/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.4707 - mae: 1.2775 - val_loss: 4.9267 - val_mae: 1.3546\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.63052\n",
      "Epoch 4/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.2546 - mae: 1.2353 - val_loss: 4.8819 - val_mae: 1.3533\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.63052\n",
      "Epoch 5/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.2178 - mae: 1.2274 - val_loss: 4.4698 - val_mae: 1.3070\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.63052 to 4.46981, saving model to models/model8.h5\n",
      "Epoch 6/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.1372 - mae: 1.2122 - val_loss: 4.6983 - val_mae: 1.3104\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.46981\n",
      "Epoch 7/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.0260 - mae: 1.1930 - val_loss: 4.7752 - val_mae: 1.3259\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.46981\n",
      "Epoch 8/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.8952 - mae: 1.1678 - val_loss: 4.4250 - val_mae: 1.2879\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.46981 to 4.42499, saving model to models/model8.h5\n",
      "Epoch 9/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.7543 - mae: 1.1510 - val_loss: 4.4857 - val_mae: 1.2994\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.42499\n",
      "Epoch 10/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.6783 - mae: 1.1295 - val_loss: 4.3335 - val_mae: 1.2812\n",
      "\n",
      "Epoch 00010: val_loss improved from 4.42499 to 4.33347, saving model to models/model8.h5\n",
      "Epoch 11/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.5256 - mae: 1.1065 - val_loss: 4.2364 - val_mae: 1.2778\n",
      "\n",
      "Epoch 00011: val_loss improved from 4.33347 to 4.23637, saving model to models/model8.h5\n",
      "Epoch 12/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.5630 - mae: 1.1082 - val_loss: 4.2935 - val_mae: 1.2801\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.23637\n",
      "Epoch 13/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.4347 - mae: 1.0880 - val_loss: 4.3641 - val_mae: 1.3027\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.23637\n",
      "Epoch 14/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3438 - mae: 1.0613 - val_loss: 4.3850 - val_mae: 1.2857\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.23637\n",
      "Epoch 15/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 2.2899 - mae: 1.0380 - val_loss: 4.2335 - val_mae: 1.2591\n",
      "\n",
      "Epoch 00015: val_loss improved from 4.23637 to 4.23345, saving model to models/model8.h5\n",
      "Epoch 16/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.2700 - mae: 1.0404 - val_loss: 4.1343 - val_mae: 1.2462\n",
      "\n",
      "Epoch 00016: val_loss improved from 4.23345 to 4.13426, saving model to models/model8.h5\n",
      "Epoch 17/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.1728 - mae: 1.0150 - val_loss: 4.2698 - val_mae: 1.2633\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.13426\n",
      "Epoch 18/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.1137 - mae: 0.9938 - val_loss: 4.2210 - val_mae: 1.2773\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.13426\n",
      "Epoch 19/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.0363 - mae: 0.9822 - val_loss: 4.2043 - val_mae: 1.2662\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.13426\n",
      "Epoch 20/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.0605 - mae: 0.9866 - val_loss: 4.1044 - val_mae: 1.2584\n",
      "\n",
      "Epoch 00020: val_loss improved from 4.13426 to 4.10444, saving model to models/model8.h5\n",
      "Epoch 21/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.0664 - mae: 0.9806 - val_loss: 4.1943 - val_mae: 1.2354\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.10444\n",
      "Epoch 22/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9223 - mae: 0.9540 - val_loss: 4.0395 - val_mae: 1.2240\n",
      "\n",
      "Epoch 00022: val_loss improved from 4.10444 to 4.03955, saving model to models/model8.h5\n",
      "Epoch 23/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9306 - mae: 0.9405 - val_loss: 4.1132 - val_mae: 1.2744\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.03955\n",
      "Epoch 24/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8521 - mae: 0.9352 - val_loss: 4.0647 - val_mae: 1.2258\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.03955\n",
      "Epoch 25/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.9218 - mae: 0.9546 - val_loss: 4.0448 - val_mae: 1.2290\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.03955\n",
      "Epoch 26/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7771 - mae: 0.9219 - val_loss: 3.9542 - val_mae: 1.2226\n",
      "\n",
      "Epoch 00026: val_loss improved from 4.03955 to 3.95422, saving model to models/model8.h5\n",
      "Epoch 27/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7798 - mae: 0.9164 - val_loss: 3.7236 - val_mae: 1.2077\n",
      "\n",
      "Epoch 00027: val_loss improved from 3.95422 to 3.72358, saving model to models/model8.h5\n",
      "Epoch 28/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7183 - mae: 0.8951 - val_loss: 3.7672 - val_mae: 1.2167\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.72358\n",
      "Epoch 29/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6454 - mae: 0.8880 - val_loss: 3.7085 - val_mae: 1.2207\n",
      "\n",
      "Epoch 00029: val_loss improved from 3.72358 to 3.70848, saving model to models/model8.h5\n",
      "Epoch 30/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7294 - mae: 0.9055 - val_loss: 3.9068 - val_mae: 1.2364\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.70848\n",
      "Epoch 31/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 1.7055 - mae: 0.8786 - val_loss: 4.0012 - val_mae: 1.2252\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.70848\n",
      "Epoch 32/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.6063 - mae: 0.8562 - val_loss: 4.0392 - val_mae: 1.2446\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.70848\n",
      "Epoch 33/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5282 - mae: 0.8684 - val_loss: 3.8445 - val_mae: 1.1934\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.70848\n",
      "Epoch 34/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6784 - mae: 0.8960 - val_loss: 4.1480 - val_mae: 1.2449\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.70848\n",
      "Epoch 35/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5624 - mae: 0.8651 - val_loss: 4.0950 - val_mae: 1.2247\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.70848\n",
      "Epoch 36/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 1.5601 - mae: 0.8633 - val_loss: 3.8099 - val_mae: 1.2186\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.70848\n",
      "Epoch 37/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.4651 - mae: 0.8443 - val_loss: 3.8565 - val_mae: 1.2133\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.70848\n",
      "Epoch 38/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6021 - mae: 0.8620 - val_loss: 3.8097 - val_mae: 1.2181\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.70848\n",
      "Epoch 39/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2925 - mae: 0.8029 - val_loss: 3.9304 - val_mae: 1.2236\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.70848\n",
      "Epoch 40/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.3842 - mae: 0.8092 - val_loss: 3.7589 - val_mae: 1.2061\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.70848\n",
      "Epoch 41/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.3509 - mae: 0.7865 - val_loss: 3.6886 - val_mae: 1.1934\n",
      "\n",
      "Epoch 00041: val_loss improved from 3.70848 to 3.68855, saving model to models/model8.h5\n",
      "Epoch 42/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2808 - mae: 0.7714 - val_loss: 3.6650 - val_mae: 1.1844\n",
      "\n",
      "Epoch 00042: val_loss improved from 3.68855 to 3.66496, saving model to models/model8.h5\n",
      "Epoch 43/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.2050 - mae: 0.7560 - val_loss: 3.6667 - val_mae: 1.1977\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.66496\n",
      "Epoch 44/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1327 - mae: 0.7456 - val_loss: 3.7458 - val_mae: 1.2022\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.66496\n",
      "Epoch 45/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1327 - mae: 0.7506 - val_loss: 3.6723 - val_mae: 1.2081\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.66496\n",
      "Epoch 46/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1650 - mae: 0.7583 - val_loss: 3.6900 - val_mae: 1.2050\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.66496\n",
      "Epoch 47/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 1.1778 - mae: 0.7409 - val_loss: 3.7216 - val_mae: 1.2113\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.66496\n",
      "Epoch 48/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.2456 - mae: 0.7504 - val_loss: 3.6475 - val_mae: 1.2008\n",
      "\n",
      "Epoch 00048: val_loss improved from 3.66496 to 3.64749, saving model to models/model8.h5\n",
      "Epoch 49/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0819 - mae: 0.7356 - val_loss: 3.6633 - val_mae: 1.1952\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.64749\n",
      "Epoch 50/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1344 - mae: 0.7308 - val_loss: 3.6575 - val_mae: 1.1961\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.64749\n",
      "Epoch 51/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9265 - mae: 0.6993 - val_loss: 3.6816 - val_mae: 1.1917\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.64749\n",
      "Epoch 52/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0079 - mae: 0.7179 - val_loss: 3.6870 - val_mae: 1.2054\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.64749\n",
      "Epoch 53/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1791 - mae: 0.7392 - val_loss: 3.6916 - val_mae: 1.1943\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.64749\n",
      "Epoch 54/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.1195 - mae: 0.7369 - val_loss: 3.6663 - val_mae: 1.1999\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.64749\n",
      "Epoch 55/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0028 - mae: 0.7007 - val_loss: 3.8196 - val_mae: 1.2268\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.64749\n",
      "Epoch 56/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.1205 - mae: 0.7290 - val_loss: 3.7701 - val_mae: 1.2118\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.64749\n",
      "Epoch 57/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0007 - mae: 0.6987 - val_loss: 3.7403 - val_mae: 1.2092\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.64749\n",
      "Epoch 58/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0306 - mae: 0.7030 - val_loss: 3.6734 - val_mae: 1.2003\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.64749\n",
      "Epoch 59/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9827 - mae: 0.6808 - val_loss: 3.6476 - val_mae: 1.1991\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.64749\n",
      "Epoch 60/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0928 - mae: 0.7137 - val_loss: 3.6695 - val_mae: 1.2023\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.64749\n",
      "Epoch 61/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.9467 - mae: 0.6756 - val_loss: 3.6851 - val_mae: 1.2076\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.64749\n",
      "Epoch 62/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.0187 - mae: 0.6840 - val_loss: 3.6930 - val_mae: 1.2123\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.64749\n",
      "Epoch 63/200\n",
      "362/362 [==============================] - 3s 8ms/step - loss: 1.0749 - mae: 0.7028 - val_loss: 3.7106 - val_mae: 1.2137\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.64749\n",
      "Epoch 64/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9578 - mae: 0.6900 - val_loss: 3.7278 - val_mae: 1.2146\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.64749\n",
      "Epoch 65/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.0530 - mae: 0.6797 - val_loss: 3.6663 - val_mae: 1.2077\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.64749\n",
      "Epoch 66/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9669 - mae: 0.6778 - val_loss: 3.6673 - val_mae: 1.2064\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.64749\n",
      "Epoch 67/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9390 - mae: 0.6737 - val_loss: 3.6948 - val_mae: 1.2146\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 3.64749\n",
      "Epoch 68/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.9137 - mae: 0.6674 - val_loss: 3.7077 - val_mae: 1.2122\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3.64749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [22:51<02:07, 127.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "362/362 [==============================] - 3s 6ms/step - loss: 4.2438 - mae: 1.4226 - val_loss: 3.1499 - val_mae: 1.2527\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.14991, saving model to models/model9.h5\n",
      "Epoch 2/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 4.0578 - mae: 1.3797 - val_loss: 3.2013 - val_mae: 1.2632\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3.14991\n",
      "Epoch 3/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.8959 - mae: 1.3463 - val_loss: 2.9271 - val_mae: 1.1983\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.14991 to 2.92712, saving model to models/model9.h5\n",
      "Epoch 4/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.6925 - mae: 1.2909 - val_loss: 2.9986 - val_mae: 1.2130\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.92712\n",
      "Epoch 5/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.5345 - mae: 1.2871 - val_loss: 3.1190 - val_mae: 1.2744\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.92712\n",
      "Epoch 6/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.3735 - mae: 1.2497 - val_loss: 2.8458 - val_mae: 1.2058\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.92712 to 2.84578, saving model to models/model9.h5\n",
      "Epoch 7/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.3508 - mae: 1.2451 - val_loss: 2.9982 - val_mae: 1.2368\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.84578\n",
      "Epoch 8/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 3.1946 - mae: 1.2139 - val_loss: 2.9757 - val_mae: 1.2371\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.84578\n",
      "Epoch 9/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 3.0557 - mae: 1.2018 - val_loss: 2.8678 - val_mae: 1.2053\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.84578\n",
      "Epoch 10/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 3.0374 - mae: 1.1908 - val_loss: 2.7767 - val_mae: 1.1798\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.84578 to 2.77674, saving model to models/model9.h5\n",
      "Epoch 11/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.8601 - mae: 1.1657 - val_loss: 2.7860 - val_mae: 1.1754\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.77674\n",
      "Epoch 12/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 2.8293 - mae: 1.1525 - val_loss: 2.7038 - val_mae: 1.1666\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.77674 to 2.70379, saving model to models/model9.h5\n",
      "Epoch 13/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.6633 - mae: 1.1279 - val_loss: 2.8480 - val_mae: 1.1969\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.70379\n",
      "Epoch 14/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.6118 - mae: 1.1127 - val_loss: 3.0252 - val_mae: 1.2351\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.70379\n",
      "Epoch 15/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.5566 - mae: 1.1129 - val_loss: 2.9668 - val_mae: 1.2412\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.70379\n",
      "Epoch 16/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.5679 - mae: 1.1028 - val_loss: 2.8278 - val_mae: 1.1886\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.70379\n",
      "Epoch 17/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3735 - mae: 1.0822 - val_loss: 2.9000 - val_mae: 1.2144\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.70379\n",
      "Epoch 18/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.4462 - mae: 1.0749 - val_loss: 2.9978 - val_mae: 1.2107\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.70379\n",
      "Epoch 19/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 2.3795 - mae: 1.0547 - val_loss: 2.9044 - val_mae: 1.1966\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.70379\n",
      "Epoch 20/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3003 - mae: 1.0594 - val_loss: 2.8007 - val_mae: 1.1875\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.70379\n",
      "Epoch 21/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.3571 - mae: 1.0486 - val_loss: 2.9676 - val_mae: 1.2246\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.70379\n",
      "Epoch 22/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.2835 - mae: 1.0521 - val_loss: 2.9353 - val_mae: 1.2173\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.70379\n",
      "Epoch 23/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.0236 - mae: 0.9863 - val_loss: 2.7358 - val_mae: 1.1713\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.70379\n",
      "Epoch 24/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 2.0775 - mae: 1.0000 - val_loss: 2.7633 - val_mae: 1.1685\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.70379\n",
      "Epoch 25/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 1.8838 - mae: 0.9448 - val_loss: 2.7034 - val_mae: 1.1546\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.70379 to 2.70344, saving model to models/model9.h5\n",
      "Epoch 26/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.8544 - mae: 0.9530 - val_loss: 2.7554 - val_mae: 1.1849\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.70344\n",
      "Epoch 27/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.9321 - mae: 0.9438 - val_loss: 2.6917 - val_mae: 1.1681\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.70344 to 2.69172, saving model to models/model9.h5\n",
      "Epoch 28/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.8449 - mae: 0.9356 - val_loss: 2.7481 - val_mae: 1.1645\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.69172\n",
      "Epoch 29/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.9235 - mae: 0.9255 - val_loss: 2.7310 - val_mae: 1.1629\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.69172\n",
      "Epoch 30/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.8084 - mae: 0.9263 - val_loss: 2.7328 - val_mae: 1.1581\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.69172\n",
      "Epoch 31/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6757 - mae: 0.9008 - val_loss: 2.7003 - val_mae: 1.1448\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.69172\n",
      "Epoch 32/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7870 - mae: 0.9179 - val_loss: 2.7769 - val_mae: 1.1664\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.69172\n",
      "Epoch 33/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7885 - mae: 0.9061 - val_loss: 2.7922 - val_mae: 1.1697\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.69172\n",
      "Epoch 34/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.7223 - mae: 0.9049 - val_loss: 2.7058 - val_mae: 1.1558\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.69172\n",
      "Epoch 35/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.8147 - mae: 0.9058 - val_loss: 2.7287 - val_mae: 1.1564\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.69172\n",
      "Epoch 36/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6462 - mae: 0.8889 - val_loss: 2.7281 - val_mae: 1.1526\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.69172\n",
      "Epoch 37/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6004 - mae: 0.8810 - val_loss: 2.7470 - val_mae: 1.1619\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.69172\n",
      "Epoch 38/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6029 - mae: 0.8578 - val_loss: 2.7108 - val_mae: 1.1501\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.69172\n",
      "Epoch 39/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6198 - mae: 0.8748 - val_loss: 2.7475 - val_mae: 1.1574\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.69172\n",
      "Epoch 40/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.6318 - mae: 0.8780 - val_loss: 2.7486 - val_mae: 1.1610\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.69172\n",
      "Epoch 41/200\n",
      "362/362 [==============================] - 3s 7ms/step - loss: 1.6848 - mae: 0.8547 - val_loss: 2.7237 - val_mae: 1.1595\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.69172\n",
      "Epoch 42/200\n",
      "362/362 [==============================] - 2s 7ms/step - loss: 1.7542 - mae: 0.8745 - val_loss: 2.7172 - val_mae: 1.1544\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.69172\n",
      "Epoch 43/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.5658 - mae: 0.8676 - val_loss: 2.6975 - val_mae: 1.1532\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.69172\n",
      "Epoch 44/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5710 - mae: 0.8529 - val_loss: 2.7363 - val_mae: 1.1601\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.69172\n",
      "Epoch 45/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5543 - mae: 0.8486 - val_loss: 2.7040 - val_mae: 1.1515\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.69172\n",
      "Epoch 46/200\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 1.4889 - mae: 0.8323 - val_loss: 2.7116 - val_mae: 1.1569\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.69172\n",
      "Epoch 47/200\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 1.5480 - mae: 0.8444 - val_loss: 2.7123 - val_mae: 1.1543\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.69172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [24:31<00:00, 147.16s/it]\n"
     ]
    }
   ],
   "source": [
    "def gen_model(params):\n",
    "    def build_model(params):\n",
    "        conv_layer_sizes = params['conv_layer_sizes']\n",
    "        dense_layer_size = params['dense_layer_size']\n",
    "        dropout_rate = params['dropout_rate']\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv3D(filters=conv_layer_sizes[0], kernel_size=(3, 3, 3), input_shape=(16, 16, 16, 14)))\n",
    "        model.add(layers.Activation(activation='relu'))\n",
    "\n",
    "        for ls in conv_layer_sizes[1:]:\n",
    "            model.add(layers.Conv3D(filters=ls, kernel_size=(3, 3, 3)))\n",
    "            model.add(layers.Activation(activation='relu'))\n",
    "\n",
    "        model.add(layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        model.add(layers.Dropout(rate=dropout_rate))\n",
    "        model.add(layers.Dense(units=dense_layer_size, activation='relu'))\n",
    "        model.add(layers.Dropout(rate=dropout_rate))\n",
    "        model.add(layers.Dense(units=1))\n",
    "        return model\n",
    "\n",
    "    model = build_model(params)\n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        amsgrad=False\n",
    "    ), metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, params, path):\n",
    "    model = gen_model(params)\n",
    "    scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=params['scheduler_factor'],\n",
    "        patience=params['scheduler_patience'],\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        min_delta=0.0001,\n",
    "        cooldown=0,\n",
    "        min_lr=1e-5,\n",
    "    )\n",
    "\n",
    "    checkpoint = callbacks.ModelCheckpoint(path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=params['early_stopping_patience'])\n",
    "    result = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                       epochs=EPOCHS, batch_size=params['batch_size'], verbose=1, callbacks=[scheduler, checkpoint, early_stopping])\n",
    "    return load_model(path), result\n",
    "\n",
    "\n",
    "!mkdir -p models\n",
    "kfold = GroupKFold(N_FOLDS)\n",
    "thermonet_models = []\n",
    "val_losses = []\n",
    "if GROUP_KFOLD:\n",
    "    groups = pdb_ids\n",
    "else:\n",
    "    groups = range(len(pdb_ids))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tqdm(kfold.split(X, y, groups=groups), total=N_FOLDS, desc=\"Folds\")):\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_val = X[val_idx]\n",
    "    y_val = y[val_idx]\n",
    "    path = f'{MODELS_PATH}/model{fold}.h5'\n",
    "    model, result = train_model(X_train, y_train, X_val, y_val, PARAMS, path)\n",
    "    thermonet_models.append(model)\n",
    "    val_losses.append(result.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c8cd9e3",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T08:12:34.302326Z",
     "iopub.status.busy": "2022-10-13T08:12:34.301964Z",
     "iopub.status.idle": "2022-10-13T08:12:34.572297Z",
     "shell.execute_reply": "2022-10-13T08:12:34.571377Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.635744,
     "end_time": "2022-10-13T08:12:34.574475",
     "exception": false,
     "start_time": "2022-10-13T08:12:32.938731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'CV MSE loss: 2.838')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = 0.\n",
    "for l in val_losses:\n",
    "    plt.plot(l)\n",
    "    cv += np.min(l)\n",
    "\n",
    "plt.title(f\"CV MSE loss: {cv / len(val_losses):.03f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1fbba",
   "metadata": {
    "papermill": {
     "duration": 1.372033,
     "end_time": "2022-10-13T08:12:37.302323",
     "exception": false,
     "start_time": "2022-10-13T08:12:35.930290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission [LB:0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cda8caa",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T08:12:40.254347Z",
     "iopub.status.busy": "2022-10-13T08:12:40.253989Z",
     "iopub.status.idle": "2022-10-13T08:12:40.261628Z",
     "shell.execute_reply": "2022-10-13T08:12:40.260644Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.602896,
     "end_time": "2022-10-13T08:12:40.263702",
     "exception": false,
     "start_time": "2022-10-13T08:12:38.660806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if ROSETTA:\n",
    "    !relax.static.linuxgccrelease -in:file:s $WILDTYPE_PDB -relax:constrain_relax_to_start_coords -out:suffix _relaxed -out:no_nstruct_label -relax:ramp_constraints false\n",
    "    df_test.query('op == \"replace\"')[['name', 'idx', 'wild', 'mutant']].to_csv('wildtypeA_mutations.txt', header=False, sep=' ', index=False)\n",
    "    !python $THERMONET_PATH/rosetta_relax.py --rosetta-bin relax.static.linuxgccrelease -l wildtypeA_mutations.txt --base-dir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10631451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T08:12:43.025238Z",
     "iopub.status.busy": "2022-10-13T08:12:43.024872Z",
     "iopub.status.idle": "2022-10-13T08:12:43.982200Z",
     "shell.execute_reply": "2022-10-13T08:12:43.981271Z"
    },
    "papermill": {
     "duration": 2.370103,
     "end_time": "2022-10-13T08:12:43.985232",
     "exception": false,
     "start_time": "2022-10-13T08:12:41.615129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "thermonet_models = [load_model(f) for f in glob.glob(f'{MODELS_PATH}/model*.h5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "587b7e09",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T08:12:46.685937Z",
     "iopub.status.busy": "2022-10-13T08:12:46.685493Z",
     "iopub.status.idle": "2022-10-13T08:12:46.698231Z",
     "shell.execute_reply": "2022-10-13T08:12:46.697384Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.362245,
     "end_time": "2022-10-13T08:12:46.700062",
     "exception": false,
     "start_time": "2022-10-13T08:12:45.337817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_FEATURES_PATH):    \n",
    "    np.save(thermonet_features(df_test.query('op == \"replace\"')), 'test_features.npy')\n",
    "    TEST_FEATURES_PATH = 'test_features.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24f13bca",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T08:12:49.417598Z",
     "iopub.status.busy": "2022-10-13T08:12:49.417033Z",
     "iopub.status.idle": "2022-10-13T08:12:57.438502Z",
     "shell.execute_reply": "2022-10-13T08:12:57.437373Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 9.33413,
     "end_time": "2022-10-13T08:12:57.440902",
     "exception": false,
     "start_time": "2022-10-13T08:12:48.106772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2335, 16, 16, 16, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = np.load(TEST_FEATURES_PATH)\n",
    "test_features = np.moveaxis(test_features, 1, -1)\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f58fa674",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T08:13:00.353232Z",
     "iopub.status.busy": "2022-10-13T08:13:00.352875Z",
     "iopub.status.idle": "2022-10-13T08:13:18.723554Z",
     "shell.execute_reply": "2022-10-13T08:13:18.722487Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 19.738529,
     "end_time": "2022-10-13T08:13:18.729671",
     "exception": false,
     "start_time": "2022-10-13T08:12:58.991142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73058945, 0.51785916, 1.0026795 , ..., 0.45843714, 0.39649284,\n",
       "       0.46810713], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ddg = np.stack([model.predict(test_features) for model in thermonet_models])\n",
    "test_ddg = np.mean(test_ddg, axis=0).flatten()\n",
    "test_ddg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8fec56c",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T08:13:21.439149Z",
     "iopub.status.busy": "2022-10-13T08:13:21.438751Z",
     "iopub.status.idle": "2022-10-13T08:13:21.448614Z",
     "shell.execute_reply": "2022-10-13T08:13:21.447732Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.374005,
     "end_time": "2022-10-13T08:13:21.451044",
     "exception": false,
     "start_time": "2022-10-13T08:13:20.077039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.loc[df_test.op == 'replace', 'ddg'] = -test_ddg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7881bcdb",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T08:13:24.975049Z",
     "iopub.status.busy": "2022-10-13T08:13:24.974700Z",
     "iopub.status.idle": "2022-10-13T08:13:24.988587Z",
     "shell.execute_reply": "2022-10-13T08:13:24.987438Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.102483,
     "end_time": "2022-10-13T08:13:24.991118",
     "exception": false,
     "start_time": "2022-10-13T08:13:22.888635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.loc[df_test['op'] == \"delete\", 'ddg'] = df_test[df_test[\"op\"]==\"replace\"][\"ddg\"].quantile(q=0.25)\n",
    "df_test.loc[df_test['op'] == \"same\", 'ddg'] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24e374ac",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T08:13:27.771003Z",
     "iopub.status.busy": "2022-10-13T08:13:27.770639Z",
     "iopub.status.idle": "2022-10-13T08:13:27.798056Z",
     "shell.execute_reply": "2022-10-13T08:13:27.797124Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.445452,
     "end_time": "2022-10-13T08:13:27.800198",
     "exception": false,
     "start_time": "2022-10-13T08:13:26.354746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>op</th>\n",
       "      <th>idx</th>\n",
       "      <th>wild</th>\n",
       "      <th>mutant</th>\n",
       "      <th>mut</th>\n",
       "      <th>name</th>\n",
       "      <th>ddg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31390</td>\n",
       "      <td>VPVNPEPDATSVENVAEKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>17</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>L17E</td>\n",
       "      <td>wildtypeA</td>\n",
       "      <td>-0.730589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31391</td>\n",
       "      <td>VPVNPEPDATSVENVAKKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>17</td>\n",
       "      <td>L</td>\n",
       "      <td>K</td>\n",
       "      <td>L17K</td>\n",
       "      <td>wildtypeA</td>\n",
       "      <td>-0.517859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31392</td>\n",
       "      <td>VPVNPEPDATSVENVAKTGSGDSQSDPIKADLEVKGQSALPFDVDC...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>delete</td>\n",
       "      <td>17</td>\n",
       "      <td>L</td>\n",
       "      <td>-</td>\n",
       "      <td>L17-</td>\n",
       "      <td>wildtypeA</td>\n",
       "      <td>-1.225111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31393</td>\n",
       "      <td>VPVNPEPDATSVENVALCTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>18</td>\n",
       "      <td>K</td>\n",
       "      <td>C</td>\n",
       "      <td>K18C</td>\n",
       "      <td>wildtypeA</td>\n",
       "      <td>-1.002679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31394</td>\n",
       "      <td>VPVNPEPDATSVENVALFTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>18</td>\n",
       "      <td>K</td>\n",
       "      <td>F</td>\n",
       "      <td>K18F</td>\n",
       "      <td>wildtypeA</td>\n",
       "      <td>-0.987945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>33798</td>\n",
       "      <td>VPVNPEPDATSVENVILKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A16I</td>\n",
       "      <td>wildtypeA</td>\n",
       "      <td>-0.409812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>33799</td>\n",
       "      <td>VPVNPEPDATSVENVLLKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>A16L</td>\n",
       "      <td>wildtypeA</td>\n",
       "      <td>-0.421951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>33800</td>\n",
       "      <td>VPVNPEPDATSVENVNLKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>A16N</td>\n",
       "      <td>wildtypeA</td>\n",
       "      <td>-0.458437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>33801</td>\n",
       "      <td>VPVNPEPDATSVENVPLKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>A16P</td>\n",
       "      <td>wildtypeA</td>\n",
       "      <td>-0.396493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>33802</td>\n",
       "      <td>VPVNPEPDATSVENVWLKTGSGDSQSDPIKADLEVKGQSALPFDVD...</td>\n",
       "      <td>8</td>\n",
       "      <td>Novozymes</td>\n",
       "      <td>replace</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>A16W</td>\n",
       "      <td>wildtypeA</td>\n",
       "      <td>-0.468107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2413 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seq_id                                   protein_sequence  pH  \\\n",
       "0      31390  VPVNPEPDATSVENVAEKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "1      31391  VPVNPEPDATSVENVAKKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "2      31392  VPVNPEPDATSVENVAKTGSGDSQSDPIKADLEVKGQSALPFDVDC...   8   \n",
       "3      31393  VPVNPEPDATSVENVALCTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "4      31394  VPVNPEPDATSVENVALFTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "...      ...                                                ...  ..   \n",
       "2408   33798  VPVNPEPDATSVENVILKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "2409   33799  VPVNPEPDATSVENVLLKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "2410   33800  VPVNPEPDATSVENVNLKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "2411   33801  VPVNPEPDATSVENVPLKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "2412   33802  VPVNPEPDATSVENVWLKTGSGDSQSDPIKADLEVKGQSALPFDVD...   8   \n",
       "\n",
       "     data_source       op  idx wild mutant   mut       name       ddg  \n",
       "0      Novozymes  replace   17    L      E  L17E  wildtypeA -0.730589  \n",
       "1      Novozymes  replace   17    L      K  L17K  wildtypeA -0.517859  \n",
       "2      Novozymes   delete   17    L      -  L17-  wildtypeA -1.225111  \n",
       "3      Novozymes  replace   18    K      C  K18C  wildtypeA -1.002679  \n",
       "4      Novozymes  replace   18    K      F  K18F  wildtypeA -0.987945  \n",
       "...          ...      ...  ...  ...    ...   ...        ...       ...  \n",
       "2408   Novozymes  replace   16    A      I  A16I  wildtypeA -0.409812  \n",
       "2409   Novozymes  replace   16    A      L  A16L  wildtypeA -0.421951  \n",
       "2410   Novozymes  replace   16    A      N  A16N  wildtypeA -0.458437  \n",
       "2411   Novozymes  replace   16    A      P  A16P  wildtypeA -0.396493  \n",
       "2412   Novozymes  replace   16    A      W  A16W  wildtypeA -0.468107  \n",
       "\n",
       "[2413 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a18c9c67",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T08:13:30.444122Z",
     "iopub.status.busy": "2022-10-13T08:13:30.443546Z",
     "iopub.status.idle": "2022-10-13T08:13:30.460184Z",
     "shell.execute_reply": "2022-10-13T08:13:30.459291Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.371848,
     "end_time": "2022-10-13T08:13:30.462476",
     "exception": false,
     "start_time": "2022-10-13T08:13:29.090628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.rename(columns={'ddg': 'tm'})[['seq_id', 'tm']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6f07231",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T08:13:33.163613Z",
     "iopub.status.busy": "2022-10-13T08:13:33.163229Z",
     "iopub.status.idle": "2022-10-13T08:13:34.459944Z",
     "shell.execute_reply": "2022-10-13T08:13:34.458711Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.648027,
     "end_time": "2022-10-13T08:13:34.463209",
     "exception": false,
     "start_time": "2022-10-13T08:13:31.815182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_id,tm\r\n",
      "31390,-0.73058945\r\n",
      "31391,-0.51785916\r\n",
      "31392,-1.2251108\r\n",
      "31393,-1.0026795\r\n",
      "31394,-0.9879446\r\n",
      "31395,-1.4168255\r\n",
      "31396,-0.90551263\r\n",
      "31397,-0.7190269\r\n",
      "31398,-0.5244844\r\n"
     ]
    }
   ],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a30b5",
   "metadata": {
    "papermill": {
     "duration": 1.304016,
     "end_time": "2022-10-13T08:13:37.227676",
     "exception": false,
     "start_time": "2022-10-13T08:13:35.923660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensemble LB:0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "005709ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T08:13:39.991149Z",
     "iopub.status.busy": "2022-10-13T08:13:39.990760Z",
     "iopub.status.idle": "2022-10-13T08:13:41.172785Z",
     "shell.execute_reply": "2022-10-13T08:13:41.171619Z"
    },
    "papermill": {
     "duration": 2.567325,
     "end_time": "2022-10-13T08:13:41.175511",
     "exception": false,
     "start_time": "2022-10-13T08:13:38.608186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_id,tm\r\n",
      "31390,8820.0\r\n",
      "31391,9706.0\r\n",
      "31392,6081.0\r\n",
      "31393,6846.5\r\n",
      "31394,7139.5\r\n",
      "31395,7332.0\r\n",
      "31396,8277.0\r\n",
      "31397,8617.5\r\n",
      "31398,10404.5\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "sub1 = pd.read_csv('../input/plldt-ddg-demask-sasa/deepddg-ddg.csv')\n",
    "sub2 = pd.read_csv('../input/novozymes-in-r-blosum-deepddg-demask/submission.csv')\n",
    "sub3 = pd.read_csv('../input/novo-esp-eli5-performant-approaches-lb-0-451/submission.csv')\n",
    "sub4 = pd.read_csv('../input/nesp-alphafold-getarea-exploration/submission.csv')\n",
    "sub5 = pd.read_csv('submission.csv')\n",
    "\n",
    "sub1['tm'] = rankdata(sub1['tm'].values) + rankdata(sub2['tm'].values) + rankdata(sub3['tm'].values) + rankdata(sub4['tm'].values)  + rankdata(sub5['tm'].values)\n",
    "sub1.to_csv('submission_ensemble.csv',index=False)\n",
    "!head submission_ensemble.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bf6d52e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T08:13:43.993287Z",
     "iopub.status.busy": "2022-10-13T08:13:43.992910Z",
     "iopub.status.idle": "2022-10-13T08:13:46.133310Z",
     "shell.execute_reply": "2022-10-13T08:13:46.131913Z"
    },
    "papermill": {
     "duration": 3.569841,
     "end_time": "2022-10-13T08:13:46.136233",
     "exception": false,
     "start_time": "2022-10-13T08:13:42.566392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CLEAN_OUTPUT:\n",
    "    !rm -rf ThermoNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226dadaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T17:06:17.775445Z",
     "iopub.status.busy": "2022-10-11T17:06:17.775059Z",
     "iopub.status.idle": "2022-10-11T17:06:17.783045Z",
     "shell.execute_reply": "2022-10-11T17:06:17.781635Z",
     "shell.execute_reply.started": "2022-10-11T17:06:17.775413Z"
    },
    "papermill": {
     "duration": 1.385608,
     "end_time": "2022-10-13T08:13:48.869269",
     "exception": false,
     "start_time": "2022-10-13T08:13:47.483661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-danger\" style=\"text-align:center; font-size:20px;\">\n",
    "    ‚ù§Ô∏è Dont forget to ‚ñ≤upvote‚ñ≤ if you find this notebook usefull!  ‚ù§Ô∏è\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1679.264179,
   "end_time": "2022-10-13T08:13:53.642812",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-13T07:45:54.378633",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
